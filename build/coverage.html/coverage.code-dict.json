{"/home/travis/build/npmtest/node-npmtest-natural/test.js":"/* istanbul instrument in package npmtest_natural */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireExampleJsFromReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        local.testCase_browser_nullCase = local.testCase_browser_nullCase || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test browsers's null-case handling-behavior-behavior\n         */\n            onError(null, options);\n        };\n\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-natural/lib.npmtest_natural.js":"/* istanbul instrument in package npmtest_natural */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_natural = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_natural = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-natural/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-natural && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_natural */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_natural\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_natural.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        // bug-workaround - long $npm_package_buildCustomOrg\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.npmtest_natural.rollup.js'] =\n            local.assetsDict['/assets.npmtest_natural.rollup.js'] ||\n            local.fs.readFileSync(\n                local.npmtest_natural.__dirname + '/lib.npmtest_natural.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        /* jslint-ignore-end */\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/index.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nexports.SoundEx = require('./phonetics/soundex');\nexports.Metaphone = require('./phonetics/metaphone');\nexports.DoubleMetaphone = require('./phonetics/double_metaphone');\nexports.SoundExDM = require('./phonetics/dm_soundex');\nexports.PorterStemmer = require('./stemmers/porter_stemmer');\nexports.PorterStemmerFa = require('./stemmers/porter_stemmer_fa');\nexports.PorterStemmerFr = require('./stemmers/porter_stemmer_fr');\nexports.PorterStemmerRu = require('./stemmers/porter_stemmer_ru');\nexports.PorterStemmerEs = require('./stemmers/porter_stemmer_es');\nexports.PorterStemmerIt = require('./stemmers/porter_stemmer_it');\nexports.PorterStemmerNo = require('./stemmers/porter_stemmer_no');\nexports.PorterStemmerPt = require('./stemmers/porter_stemmer_pt');\nexports.LancasterStemmer = require('./stemmers/lancaster_stemmer');\nexports.StemmerFr = require('./stemmers/stemmer_fr');\nexports.StemmerPl = require('./stemmers/stemmer_pl');\nexports.StemmerJa = require('./stemmers/stemmer_ja');\nexports.AggressiveTokenizerNl = require('./tokenizers/aggressive_tokenizer_nl');\nexports.AggressiveTokenizerFa = require('./tokenizers/aggressive_tokenizer_fa');\nexports.AggressiveTokenizerFr = require('./tokenizers/aggressive_tokenizer_fr');\nexports.AggressiveTokenizerRu = require('./tokenizers/aggressive_tokenizer_ru');\nexports.AggressiveTokenizerEs = require('./tokenizers/aggressive_tokenizer_es');\nexports.AggressiveTokenizerIt = require('./tokenizers/aggressive_tokenizer_it');\nexports.AggressiveTokenizerPl = require('./tokenizers/aggressive_tokenizer_pl');\nexports.AggressiveTokenizerPt = require('./tokenizers/aggressive_tokenizer_pt');\nexports.AggressiveTokenizerNo = require('./tokenizers/aggressive_tokenizer_no');\nexports.AggressiveTokenizer = require('./tokenizers/aggressive_tokenizer');\nexports.CaseTokenizer = require('./tokenizers/tokenizer_case');\nexports.RegexpTokenizer = require('./tokenizers/regexp_tokenizer').RegexpTokenizer;\nexports.WordTokenizer = require('./tokenizers/regexp_tokenizer').WordTokenizer;\nexports.WordPunctTokenizer = require('./tokenizers/regexp_tokenizer').WordPunctTokenizer;\nexports.TreebankWordTokenizer = require('./tokenizers/treebank_word_tokenizer');\nexports.TokenizerJa = require('./tokenizers/tokenizer_ja');\nexports.SentenceTokenizer = require('./tokenizers/sentence_tokenizer');\nexports.BayesClassifier = require('./classifiers/bayes_classifier');\nexports.LogisticRegressionClassifier = require('./classifiers/logistic_regression_classifier');\nexports.NounInflector = require('./inflectors/noun_inflector');\nexports.NounInflectorFr = require('./inflectors/fr/noun_inflector');\nexports.NounInflectorJa = require('./inflectors/ja/noun_inflector');\nexports.PresentVerbInflector = require('./inflectors/present_verb_inflector');\nexports.CountInflector = require('./inflectors/count_inflector');\nexports.WordNet = require('./wordnet/wordnet');\nexports.TfIdf = require('./tfidf/tfidf');\nexports.Trie = require('./trie/trie');\nexports.SentenceAnalyzer = require('./analyzers/sentence_analyzer');\nexports.stopwords = require('./util/stopwords').words;\nexports.ShortestPathTree = require('./util/shortest_path_tree');\nexports.Spellcheck = require('./spellcheck/spellcheck');\nexports.LongestPathTree = require('./util/longest_path_tree');\nexports.EdgeWeightedDigraph = require('./util/edge_weighted_digraph');\nexports.NGrams = require('./ngrams/ngrams');\nexports.NGramsZH = require('./ngrams/ngrams_zh');\nexports.JaroWinklerDistance = require('./distance/jaro-winkler_distance');\nexports.LevenshteinDistance = require('./distance/levenshtein_distance');\nexports.DiceCoefficient = require('./distance/dice_coefficient');\nexports.normalize = require('./normalizers/normalizer').normalize_tokens;\nexports.normalize_ja = require('./normalizers/normalizer_ja').normalize_ja;\nexports.removeDiacritics = require('./normalizers/remove_diacritics');\nexports.transliterate_ja = require('./transliterators/ja');\nexports.BrillPOSTagger = require('./brill_pos_tagger/lib/Brill_POS_Tagger');\nexports.Lexicon = require('./brill_pos_tagger/lib/Lexicon');\nexports.RuleSet = require('./brill_pos_tagger/lib/RuleSet');\n\n\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/phonetics/soundex.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Phonetic = require('./phonetic');\n\nfunction transformLipps(token) {\n    return token.replace(/[bfpv]/g, '1');\n}\n\nfunction transformThroats(token) {\n    return token.replace(/[cgjkqsxz]/g, '2');\n}\n\nfunction transformToungue(token) {\n    return token.replace(/[dt]/g, '3');\n}\n\nfunction transformL(token) {\n    return token.replace(/l/g, '4');\n}\n\nfunction transformHum(token) {\n    return token.replace(/[mn]/g, '5');\n}\n\nfunction transformR(token) {\n    return token.replace(/r/g, '6');\n}\n\nfunction condense(token) {\n    return token.replace(/(\\d)?\\1+/g, '$1');\n}\n\nfunction padRight0(token) {\n    if(token.length < 4)\n        return token + Array(4 - token.length).join('0');\n    else\n        return token;\n}\n\nfunction transform(token) {\n    return transformLipps(transformThroats(\n        transformToungue(transformL(transformHum(transformR(token))))));\n}\n\nvar SoundEx = new Phonetic();\nmodule.exports = SoundEx;\n\nSoundEx.process = function(token, maxLength) {\n    token = token.toLowerCase();    \n    var transformed = condense(transform(token.substr(1, token.length - 1))); // anything that isn't a digit goes\n    // deal with duplicate INITIAL consonant SOUNDS\n    transformed = transformed.replace(new RegExp(\"^\" + transform(token.charAt(0))), '');\n    return token.charAt(0).toUpperCase() + padRight0(transformed.replace(/\\D/g, '')).substr(0, (maxLength && maxLength - 1) || 3);\n};\n\n// export for tests;\nSoundEx.transformLipps = transformLipps;\nSoundEx.transformThroats = transformThroats;\nSoundEx.transformToungue = transformToungue;\nSoundEx.transformL = transformL;\nSoundEx.transformHum = transformHum;\nSoundEx.transformR = transformR;\nSoundEx.condense = condense;\nSoundEx.padRight0 = padRight0;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/phonetics/phonetic.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar stopwords = require('../util/stopwords');\nvar Tokenizer = require('../tokenizers/aggressive_tokenizer'),\n    tokenizer = new Tokenizer();\n\nmodule.exports = function() {\n    this.compare = function(stringA, stringB) {\n        return this.process(stringA) == this.process(stringB);\n    };\n\n    this.attach = function() {\n\tvar phonetic = this;\n\n        String.prototype.soundsLike = function(compareTo) {\n            return phonetic.compare(this, compareTo);\n        }\n        \n        String.prototype.phonetics = function() {\n            return phonetic.process(this);\n        }\n\t\n        String.prototype.tokenizeAndPhoneticize = function(keepStops) {\n            var phoneticizedTokens = [];\n            \n            tokenizer.tokenize(this).forEach(function(token) {\n                if(keepStops || stopwords.words.indexOf(token) < 0)\n                    phoneticizedTokens.push(token.phonetics());\n            });\n            \n            return phoneticizedTokens;\n        }\n    };\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/stopwords.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n// a list of commonly used words that have little meaning and can be excluded\n// from analysis.\nvar words = [\n    'about', 'above', 'after', 'again', 'all', 'also', 'am', 'an', 'and', 'another',\n    'any', 'are', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below',\n    'between', 'both', 'but', 'by', 'came', 'can', 'cannot', 'come', 'could', 'did',\n    'do', 'does', 'doing', 'during', 'each', 'few', 'for', 'from', 'further', 'get',\n    'got', 'has', 'had', 'he', 'have', 'her', 'here', 'him', 'himself', 'his', 'how',\n    'if', 'in', 'into', 'is', 'it', 'its', 'itself', 'like', 'make', 'many', 'me',\n    'might', 'more', 'most', 'much', 'must', 'my', 'myself', 'never', 'now', 'of', 'on',\n    'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own',\n    'said', 'same', 'see', 'should', 'since', 'so', 'some', 'still', 'such', 'take', 'than',\n    'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they',\n    'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was',\n    'way', 'we', 'well', 'were', 'what', 'where', 'when', 'which', 'while', 'who',\n    'whom', 'with', 'would', 'why', 'you', 'your', 'yours', 'yourself',\n    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n',\n    'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '$', '1',\n    '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];\n\n// tell the world about the noise words.\nexports.words = words;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Tokenizer = require('./tokenizer'),\n    util = require('util');\n\nvar AggressiveTokenizer = function() {\n    Tokenizer.call(this);    \n};\nutil.inherits(AggressiveTokenizer, Tokenizer);\n\nmodule.exports = AggressiveTokenizer;\n\nAggressiveTokenizer.prototype.tokenize = function(text) {\n    // break a string up into an array of tokens by anything non-word\n    return this.trim(text.split(/\\W+/));\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/tokenizer.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n/**\n * \\@todo Use .bind() in Tokenizer.prototype.attach().\n */\n\nvar Tokenizer = function() {\n};\n\nTokenizer.prototype.trim = function(array) {\n  while (array[array.length - 1] == '')\n    array.pop();\n\n  while (array[0] == '')\n    array.shift();\n\n  return array;\n};\n\n// Expose an attach function that will patch String with new methods.\nTokenizer.prototype.attach = function() {\n  var self = this;\n\n  String.prototype.tokenize = function() {\n    return self.tokenize(this);\n  }\n};\n\nTokenizer.prototype.tokenize = function() {};\n\nmodule.exports = Tokenizer;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/phonetics/metaphone.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Phonetic = require('./phonetic');\n\nfunction dedup(token) {\n    return token.replace(/([^c])\\1/g, '$1');\n}\n\nfunction dropInitialLetters(token) {\n    if(token.match(/^(kn|gn|pn|ae|wr)/))\n        return token.substr(1, token.length - 1);\n        \n    return token;\n}\n\nfunction dropBafterMAtEnd(token) {\n    return token.replace(/mb$/, 'm');\n}\n\nfunction cTransform(token) {\n    \n\n    token = token.replace(/([^s]|^)(c)(h)/g, '$1x$3').trim();\n\n\n    token = token.replace(/cia/g, 'xia');\n    token = token.replace(/c(i|e|y)/g, 's$1');\n    token = token.replace(/c/g, 'k'); \n    \n    return token;\n}\n\nfunction dTransform(token) {\n    token = token.replace(/d(ge|gy|gi)/g, 'j$1');\n    token = token.replace(/d/g, 't');\n    \n    return token;\n}\n\nfunction dropG(token) {\n    token = token.replace(/gh(^$|[^aeiou])/g, 'h$1');\n    token = token.replace(/g(n|ned)$/g, '$1');    \n    \n    return token;\n}\n\nfunction transformG(token) {\n    token = token.replace(/gh/g, 'f'); \n    token = token.replace(/([^g]|^)(g)(i|e|y)/g, '$1j$3');\n    token = token.replace(/gg/g, 'g');\n    token = token.replace(/g/g, 'k');    \n    \n    return token;\n}\n\nfunction dropH(token) {\n    return token.replace(/([aeiou])h([^aeiou]|$)/g, '$1$2');\n}\n\nfunction transformCK(token) {\n    return token.replace(/ck/g, 'k');\n}\nfunction transformPH(token) {\n    return token.replace(/ph/g, 'f');\n}\n\nfunction transformQ(token) {\n    return token.replace(/q/g, 'k');\n}\n\nfunction transformS(token) {\n    return token.replace(/s(h|io|ia)/g, 'x$1');\n}\n\nfunction transformT(token) {\n    token = token.replace(/t(ia|io)/g, 'x$1');\n    token = token.replace(/th/, '0');\n    \n    return token;\n}\n\nfunction dropT(token) {\n    return token.replace(/tch/g, 'ch');\n}\n\nfunction transformV(token) {\n    return token.replace(/v/g, 'f');\n}\n\nfunction transformWH(token) {\n    return token.replace(/^wh/, 'w');\n}\n\nfunction dropW(token) {\n    return token.replace(/w([^aeiou]|$)/g, '$1');\n}\n\nfunction transformX(token) {\n    token = token.replace(/^x/, 's');\n    token = token.replace(/x/g, 'ks');\n    return token;\n}\n\nfunction dropY(token) {\n    return token.replace(/y([^aeiou]|$)/g, '$1');\n}\n\nfunction transformZ(token) {\n    return token.replace(/z/, 's');\n}\n\nfunction dropVowels(token) {\n    return token.charAt(0) + token.substr(1, token.length).replace(/[aeiou]/g, '');\n}\n\nvar Metaphone = new Phonetic();\nmodule.exports = Metaphone;\n\nMetaphone.process = function(token, maxLength) {\n    maxLength == maxLength || 32;\n    token = token.toLowerCase();\n    token = dedup(token);\n    token = dropInitialLetters(token);\n    token = dropBafterMAtEnd(token);\n    token = transformCK(token);\n    token = cTransform(token);\n    token = dTransform(token);\n    token = dropG(token);\n    token = transformG(token);\n    token = dropH(token);\n    token = transformPH(token);\n    token = transformQ(token);\n    token = transformS(token);\n    token = transformX(token);    \n    token = transformT(token);\n    token = dropT(token);\n    token = transformV(token);\n    token = transformWH(token);\n    token = dropW(token);\n    token = dropY(token);\n    token = transformZ(token);\n    token = dropVowels(token);\n    \n    token.toUpperCase();\n    if(token.length >= maxLength)\n        token = token.substring(0, maxLength);        \n\n    return token.toUpperCase();\n};\n\n// expose functions for testing    \nMetaphone.dedup = dedup;\nMetaphone.dropInitialLetters = dropInitialLetters;\nMetaphone.dropBafterMAtEnd = dropBafterMAtEnd;\nMetaphone.cTransform = cTransform;\nMetaphone.dTransform = dTransform;\nMetaphone.dropG = dropG;\nMetaphone.transformG = transformG;\nMetaphone.dropH = dropH;\nMetaphone.transformCK = transformCK;\nMetaphone.transformPH = transformPH;\nMetaphone.transformQ = transformQ;\nMetaphone.transformS = transformS;\nMetaphone.transformT = transformT;\nMetaphone.dropT = dropT;\nMetaphone.transformV = transformV;\nMetaphone.transformWH = transformWH;\nMetaphone.dropW = dropW;\nMetaphone.transformX = transformX;\nMetaphone.dropY = dropY;\nMetaphone.transformZ = transformZ;\nMetaphone.dropVowels = dropVowels;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/phonetics/double_metaphone.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Phonetic = require('./phonetic');\n\nvar DoubleMetaphone = new Phonetic();\nmodule.exports = DoubleMetaphone;\n\nfunction isVowel(c) {\n\treturn c && c.match(/[aeiouy]/i);\n}\n\nfunction truncate(string, length) {\n    if(string.length >= length)\n        string = string.substring(0, length);\n\n    return string;\n}\n\nfunction process(token, maxLength) {\n\ttoken = token.toUpperCase();\n\tvar primary = '', secondary = '';\n    var pos = 0;\n    maxLength == maxLength || 32;\n\n    function subMatch(startOffset, stopOffset, terms) {\n        return subMatchAbsolute(pos + startOffset, pos + stopOffset, terms);\n    }\n\n    function subMatchAbsolute(startOffset, stopOffset, terms) {\n        return terms.indexOf(token.substring(startOffset, stopOffset)) > -1;\n    }\n\n    function addSecondary(primaryAppendage, secondaryAppendage) {\n    \tprimary += primaryAppendage;\n    \tsecondary += secondaryAppendage;\n    }\n\n    function add(primaryAppendage) {\n    \taddSecondary(primaryAppendage, primaryAppendage);\n    }\n\n    function addCompressedDouble(c, encoded) {\n    \tif(token[pos + 1] == c)\n    \t\tpos++;\n    \tadd(encoded || c);\n    }\n\n    function handleC() {\n\n        if(pos >= 1 && !isVowel(token[pos - 2])\n                && token[pos - 1] == 'A' && token[pos + 1] == 'H'\n                    && token[pos + 2] != 'I'\n                        || subMatch(-2, 4, ['BACHER', 'MACHER'])) {\n            add('K');\n            pos++;\n        } else if(pos == 0 && token.substring(1, 6) == 'EASAR') {\n            add('S');\n            add('S');\n            add('R');\n            pos += 6;\n        } else if(token.substring(pos + 1, pos + 4) == 'HIA') {\n            add('K');\n            pos++;\n        } else if(token[pos + 1] == 'H') {\n            if(pos > 0 && token.substring(pos + 2, pos + 4) == 'AE') {\n                addSecondary('K', 'X');\n                pos++;\n            } else if(pos == 0\n                        && (subMatch(1, 6, ['HARAC', 'HARIS'])\n                            || subMatch(1, 4, ['HOR', 'HUM', 'HIA', 'HEM']))\n                        && token.substring(pos + 1, pos + 5) != 'HORE') {\n                add('K');\n                pos++;\n            } else {\n                if((subMatchAbsolute(0, 3, ['VAN', 'VON']) || token.substring(0,  3) == 'SCH')\n                    || subMatch(-2, 4, ['ORCHES', 'ARCHIT', 'ORCHID'])\n                    || subMatch(2, 3, ['T', 'S'])\n                    || ((subMatch(-1, 0, ['A', 'O', 'U', 'E']) || pos == 0)\n                        && subMatch(2, 3, ['B', 'F', 'H', 'L', 'M', 'N', 'R', 'V', 'W']))) {\n                    add('K');\n                } else if(pos > 0) {\n\n                    if(token.substring(0, 2) == 'MC') {\n                        add('K');\n                    } else {\n                        addSecondary('X', 'K');\n                    }\n                } else {\n                    add('X');\n                }\n\n                pos++;\n            }\n        } else if(token.substring(pos, pos + 2) == 'CZ'\n                && token.substring(pos - 2, pos + 1) != 'WICZ') {\n            addSecondary('S', 'X');\n            pos++;\n        } else if(token.substring(pos, pos + 3) == 'CIA') {\n            add('X');\n            pos += 2;\n        } else if(token[pos + 1] == 'C' && pos != 1 && token[0] != 'M') {\n            if(['I', 'E', 'H'].indexOf(token[pos + 2]) > -1\n                    && token.substring(pos + 2, pos + 4) != 'HU') {\n                if(pos == 1 && token[pos - 1] == 'A'\n                        || subMatch(-1, 4, ['UCCEE', 'UCCES'])) {\n                    add('KS');\n                } else {\n                   add('X');\n                }\n\n               pos +=2;\n            } else {\n                add('K');\n                pos++;\n            }\n        } else if(['K', 'G', 'Q'].indexOf(token[pos + 1]) > -1) {\n            add('K');\n            pos++;\n        } else if(['E', 'I', 'Y'].indexOf(token[pos + 1]) > -1) {\n            if(subMatch(1, 3, ['IA', 'IE', 'IO'])) {\n                addSecondary('S', 'X');\n            } else {\n                add('S');\n            }\n            pos++;\n        } else {\n            add('K');\n            if(token[pos + 1] == ' ' && ['C', 'Q', 'G'].indexOf(token[pos + 2])) {\n                pos += 2;\n            } else if(['C', 'K', 'Q'].indexOf(token[pos + 1]) > -1\n                    && !subMatch(1, 3, ['CE', 'CI'])) {\n                pos++;\n            }\n        }\n    }\n\n    function handleD() {\n    \tif(token[pos + 1] == 'G') {\n    \t\tif(['I', 'E', 'Y'].indexOf(token[pos + 2]) > -1)  {\n    \t\t\tadd('J');\n    \t\t\tpos += 2;\n    \t\t} else {\n    \t\t\tadd('TK');\n    \t\t\tpos++;\n    \t\t}\n\t    } else if(token[pos + 1] == 'T') {\n    \t\tadd('T');\n\t    \tpos++;\n    \t} else\n    \t\taddCompressedDouble('D', 'T');\n    }\n\n    function handleG() {\n        if(token[pos + 1] == 'H') {\n            if(pos > 0 && !isVowel(token[pos - 1])) {\n                add('K');\n                pos++;\n            } else if(pos == 0) {\n                if(token[pos + 2] == 'I') {\n                    add('J');\n                } else {\n                    add('K');\n                }\n                pos++;\n            } else if(pos > 1\n                && (['B', 'H', 'D'].indexOf(token[pos - 2]) > -1\n                    || ['B', 'H', 'D'].indexOf(token[pos - 3]) > -1\n                    || ['B', 'H'].indexOf(token[pos - 4]) > -1)) {\n                pos++;\n            } else {\n                if(pos > 2\n                        && token[pos - 1] == 'U'\n                        && ['C', 'G', 'L', 'R', 'T'].indexOf(token[pos - 3]) > -1) {\n                    add('F');\n                } else if(token[pos - 1] != 'I') {\n                    add('K');\n                }\n\n                pos++;\n            }\n        } else if(token[pos + 1] == 'N') {\n            if(pos == 1 && startsWithVowel && !slavoGermanic) {\n                addSecondary('KN', 'N');\n            } else {\n                if(token.substring(pos + 2, pos + 4) != 'EY'\n                        && (token[pos + 1] != 'Y'\n                            && !slavoGermanic)) {\n                    addSecondary('N', 'KN');\n                } else\n                    add('KN');\n            }\n            pos++;\n        } else if(token.substring(pos + 1, pos + 3) == 'LI' && !slavoGermanic) {\n            addSecondary('KL', 'L');\n            pos++;\n        } else if(pos == 0 && (token[pos + 1] == 'Y'\n                || subMatch(1, 3, ['ES', 'EP', 'EB', 'EL', 'EY', 'IB', 'IL', 'IN', 'IE', 'EI', 'ER']))) {\n            addSecondary('K', 'J')\n        } else {\n            addCompressedDouble('G', 'K');\n        }\n    }\n\n    function handleH() {\n\t\t// keep if starts a word or is surrounded by vowels\n\t\tif((pos == 0 || isVowel(token[pos - 1])) && isVowel(token[pos + 1])) {\n\t\t\tadd('H');\n\t\t\tpos++;\n\t\t}\n    }\n\n    function handleJ() {\n        var jose = (token.substring(pos + 1, pos + 4) == 'OSE');\n\n        if(san || jose) {\n            if((pos == 0 && token[pos + 4] == ' ')\n                    || san) {\n                add('H');\n            } else\n                add('J', 'H');\n        } else {\n            if(pos == 0/* && !jose*/) {\n                addSecondary('J', 'A');\n            } else if(isVowel(token[pos - 1]) && !slavoGermanic\n                    && (token[pos + 1] == 'A' || token[pos + 1] == 'O')) {\n                addSecondary('J', 'H');\n            } else if(pos == token.length - 1) {\n                addSecondary('J', ' ');\n            } else\n                addCompressedDouble('J');\n        }\n    }\n\n    function handleL() {\n    \tif(token[pos + 1] == 'L') {\n    \t\tif(pos == token.length - 3 && (\n    \t\t\t\t\tsubMatch(-1, 3, ['ILLO', 'ILLA', 'ALLE']) || (\n    \t\t\t\t\t\ttoken.substring(pos - 1, pos + 3) == 'ALLE' &&\n    \t\t\t\t\t\t(subMatch(-2, -1, ['AS', 'OS']) > -1 ||\n    \t\t\t\t\t\t['A', 'O'].indexOf(token[token.length - 1]) > -1)))) {\n    \t\t\taddSecondary('L', '');\n    \t\t\tpos++;\n    \t\t\treturn;\n    \t\t}\n    \t\tpos++;\n    \t}\n    \tadd('L');\n    }\n\n    function handleM() {\n    \taddCompressedDouble('M');\n    \tif(token[pos - 1] == 'U' && token[pos + 1] == 'B' &&\n    \t\t\t((pos == token.length - 2  || token.substring(pos + 2, pos + 4) == 'ER')))\n    \t\tpos++;\n    }\n\n    function handleP() {\n    \tif(token[pos + 1] == 'H') {\n    \t\tadd('F');\n    \t\tpos++;\n    \t} else {\n    \t\taddCompressedDouble('P');\n\n\t\t\tif(token[pos + 1] == 'B')\n    \t\t\tpos++;\n    \t}\n    }\n\n    function handleR() {\n    \tif(pos == token.length - 1 && !slavoGermanic\n    \t\t\t&& token.substring(pos - 2, pos) == 'IE'\n    \t\t\t&& !subMatch(-4, -3, ['ME', 'MA'])) {\n    \t\taddSecondary('', 'R');\n    \t} else\n\t    \taddCompressedDouble('R');\n    }\n\n    function handleS() {\n        if(pos == 0 && token.substring(0, 5) == 'SUGAR') {\n            addSecondary('X', 'S');\n        } else if(token[pos + 1] == 'H') {\n            if(subMatch(2, 5, ['EIM', 'OEK', 'OLM', 'OLZ'])) {\n                add('S');\n            } else {\n                add('X');\n            }\n            pos++;\n        } else if(subMatch(1, 3, ['IO', 'IA'])) {\n            if(slavoGermanic) {\n                add('S');\n            } else {\n                addSecondary('S', 'X');\n            }\n            pos++;\n        } else if((pos == 0 && ['M', 'N', 'L', 'W'].indexOf(token[pos + 1]) > -1)\n                || token[pos + 1] == 'Z') {\n            addSecondary('S', 'X');\n            if(token[pos + 1] == 'Z')\n                pos++;\n        } else if(token.substring(pos, pos + 2) == 'SC') {\n            if(token[pos + 2] == 'H') {\n                if(subMatch(3, 5, ['ER', 'EN'])) {\n                    addSecondary('X', 'SK');\n                } else if(subMatch(3, 5, ['OO', 'UY', 'ED', 'EM'])) {\n                    add('SK');\n                } else if(pos == 0 && !isVowel(token[3]) && token[3] != 'W') {\n                    addSecondary('X', 'S');\n                } else {\n                    add('X');\n                }\n            } else if(['I', 'E', 'Y'].indexOf(token[pos + 2]) > -1) {\n                add('S');\n            } else {\n                add('SK');\n            }\n\n            pos += 2;\n        } else if(pos == token.length - 1\n                && subMatch(-2, 0, ['AI', 'OI'])) {\n            addSecondary('', 'S');\n        } else if(token[pos + 1] != 'L' && (\n                token[pos - 1] != 'A' && token[pos - 1] != 'I')) {\n            addCompressedDouble('S');\n            if(token[pos + 1] == 'Z')\n                pos++;\n        }\n    }\n\n    function handleT() {\n        if(token.substring(pos + 1, pos + 4) == 'ION') {\n            add('XN');\n            pos += 3;\n        } else if(subMatch(1, 3, ['IA', 'CH'])) {\n            add('X');\n            pos += 2;\n        } else if(token[pos + 1] == 'H'\n                || token.substring(1, 2) == 'TH') {\n            if(subMatch(2, 4, ['OM', 'AM'])\n                    || ['VAN ', 'VON '].indexOf(token.substring(0, 4)) > -1\n                    || token.substring(0, 3) == 'SCH') {\n                add('T');\n            } else\n                addSecondary('0', 'T');\n            pos++;\n        } else {\n            addCompressedDouble('T');\n\n            if(token[pos + 1] == 'D')\n                pos++;\n        }\n    }\n\n    function handleX() {\n    \tif(pos == 0) {\n    \t\tadd('S');\n    \t} else if(!(pos == token.length - 1\n\t    \t\t&& (['IAU', 'EAU', 'IEU'].indexOf(token.substring(pos - 3, pos)) > -1\n\t    \t\t\t|| ['AU', 'OU'].indexOf(token.substring(pos - 2, pos)) > -1))) {\n    \t\tadd('KS');\n    \t}\n    }\n\n    function handleW() {\n        if(pos == 0) {\n            if(token[1] == 'H') {\n                add('A');\n            } else if (isVowel(token[1])) {\n                addSecondary('A', 'F');\n            }\n        } else if((pos == token.length - 1 && isVowel(token[pos - 1])\n                    || subMatch(-1, 4, ['EWSKI', 'EWSKY', 'OWSKI', 'OWSKY'])\n                    || token.substring(0, 3) == 'SCH')) {\n                addSecondary('', 'F');\n                pos++;\n        } else if(['ICZ', 'ITZ'].indexOf(token.substring(pos + 1, pos + 4)) > -1) {\n            addSecondary('TS', 'FX');\n            pos += 3;\n        }\n    }\n\n    function handleZ() {\n        if(token[pos + 1] == 'H') {\n            add('J');\n            pos++;\n        } else if(subMatch(1, 3, ['ZO', 'ZI', 'ZA'])\n                || (slavoGermanic && pos > 0 && token[pos - 1] != 'T')) {\n            addSecondary('S', 'TS');\n            pos++;\n        } else\n            addCompressedDouble('Z', 'S');\n    }\n\n    var san = (token.substring(0, 3) == 'SAN');\n    var startsWithVowel = isVowel(token[0]);\n    var slavoGermanic = token.match(/(W|K|CZ|WITZ)/);\n\n    if(subMatch(0, 2, ['GN', 'KN', 'PN', 'WR', 'PS'])) {\n    \tpos++;\n    }\n\n    while(pos < token.length) {\n\n    \tswitch(token[pos]) {\n\t        case 'A': case 'E': case 'I': case 'O': case 'U': case 'Y':\n\t        case 'Ê': case 'É': case 'É': case'À':\n\t\t        if(pos == 0)\n\t\t        \tadd('A');\n\t\t        break;\n\t\t    case 'B':\n\t\t    \taddCompressedDouble('B', 'P');\n\t\t    \tbreak;\n            case 'C':\n                handleC();\n                break;\n\t        case 'Ç':\n\t            add(\"S\");\n\t            break;\n\t        case 'D':\n\t        \thandleD();\n\t        \tbreak;\n\t        case 'F': case 'K': case 'N':\n\t        \taddCompressedDouble(token[pos]);\n\t        \tbreak;\n            case 'G':\n                handleG();\n                break;\n\t        case 'H':\n\t        \thandleH();\n\t        \tbreak;\n            case 'J':\n                handleJ();\n                break;\n\t        case 'L':\n\t        \thandleL();\n\t        \tbreak;\n\t        case 'M':\n\t        \thandleM();\n\t        \tbreak;\n\t        case 'Ñ':\n\t        \tadd('N');\n\t        \tbreak;\n\t        case 'P':\n\t        \thandleP();\n\t        \tbreak;\n\t        case 'Q':\n\t        \taddCompressedDouble('Q', 'K');\n\t        \tbreak;\n\t        case 'R':\n\t        \thandleR();\n\t        \tbreak;\n            case 'S':\n                handleS();\n                break;\n            case 'T':\n                handleT();\n                break;\n\t        case 'V':\n\t        \taddCompressedDouble('V', 'F');\n\t        \tbreak;\n            case 'W':\n                handleW();\n                break;\n\t        case 'X':\n\t        \thandleX();\n\t        \tbreak;\n\t        case 'Z':\n\t        \thandleZ();\n\t        \tbreak;\n    \t}\n\n        if(primary.length >= maxLength && secondary.length >= maxLength) {\n            break;\n        }\n\n    \tpos++;\n    }\n\n    return [truncate(primary, maxLength), truncate(secondary, maxLength)];\n}\n\nfunction compare(stringA, stringB) {\n    var encodingsA = process(stringA),\n        encodingsB = process(stringB);\n\n    return encodingsA[0] == encodingsB[0] ||\n        encodingsA[1] == encodingsB[1];\n};\n\nDoubleMetaphone.compare = compare\nDoubleMetaphone.process = process;\nDoubleMetaphone.isVowel = isVowel;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/phonetics/dm_soundex.js":"/*\nCopyright (c) 2012, Alexy Maslenninkov\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n/*\n * Daitch-Mokotoff Soundex Coding\n *\n * The Daitch-Mokotoff Soundex System was created by Randy Daitch and Gary\n * Mokotoff of the Jewish Genealogical Society because they concluded the system\n * developed by Robert Russell in 1918, and in use today by the U.S. National\n * Archives and Records Administration (NARA) does not apply well to many Slavic\n * and Yiddish surnames.  It also includes refinements that are independent of\n * ethnic considerations.\n *\n * The rules for converting surnames into D-M Code numbers are listed below.\n * They are followed by the coding chart.\n *\n * 1. Names are coded to six digits, each digit representing a sound listed in\n * the coding chart (below).\n *\n * 2. When a name lacks enough coded sounds for six digits, use zeros to fill to\n * six digits. GOLDEN which has only four coded sounds [G-L-D-N] is coded as\n * 583600.\n *\n * 3. The letters A, E, I, O, U, J, and Y are always coded at the beginning of a\n * name as in Alpert 087930. In any other situation, they are ignored except\n * when two of them form a pair and the pair comes before a vowel, as in Breuer\n * 791900 but not Freud.\n *\n * 4. The letter H is coded at the beginning of a name, as in Haber 579000, or\n * preceding a vowel, as in Manheim 665600, otherwise it is not coded.\n *\n * 5. When adjacent sounds can combine to form a larger sound, they are given\n * the code number of the larger sound.  Mintz which is not coded MIN-T-Z but\n * MIN-TZ 664000.\n *\n * 6. When adjacent letters have the same code number, they are coded as one\n * sound, as in TOPF, which is not coded TO-P-F 377000 but TO-PF 370000.\n * Exceptions to this rule are the letter combinations MN and NM, whose letters\n * are coded separately, as in Kleinman, which is coded 586660 not 586600.\n *\n * 7. When a surname consists or more than one word, it is coded as if one word,\n * such as Ben Aron which is treated as Benaron.\n *\n * 8. Several letter and letter combinations pose the problem that they may\n * sound in one of two ways.  The letter and letter combinations CH, CK, C, J,\n * and RS are assigned two possible code numbers.\n *\n * For more info, see http://www.jewishgen.org/InfoFiles/soundex.html\n */\n\n/**\n * D-M transformation table in the form of finite-state machine.\n * Every element of the table having member with zero index represents\n * legal FSM state; every non-zero key is the transition rule.\n *\n * Every legal state comprises tree values chosen according to the position\n * of the letter combination in the word:\n *   0: start of a word;\n *   1: before a vowel;\n *   2: any other situation.\n */\nvar codes = {\n    A: {\n        0: [0, -1, -1],\n        I: [[0, 1, -1]],\n        J: [[0, 1, -1]],\n        Y: [[0, 1, -1]],\n        U: [[0, 7, -1]]},\n    B: [[7, 7, 7]],\n    C: {\n        0: [5, 5, 5],\n        Z: {0: [4, 4, 4], S: [[4, 4, 4]]},\n        S: {0: [4, 4, 4], Z: [[4, 4, 4]]},\n        K: [[5, 5, 5], [45, 45, 45]],\n        H: {0: [5, 5, 5], S: [[5, 54, 54]]}},\n    D: {\n        0: [3, 3, 3],\n        T: [[3, 3, 3]],\n        Z: {0: [4, 4, 4], H: [[4, 4, 4]], S: [[4, 4, 4]]},\n        S: {0: [4, 4, 4], H: [[4, 4, 4]], Z: [[4, 4, 4]]},\n        R: {S: [[4, 4, 4]], Z: [[4, 4, 4]]}},\n    E: {\n        0: [0, -1, -1],\n        I: [[0, 1, -1]],\n        J: [[0, 1, -1]],\n        Y: [[0, 1, -1]],\n        U: [[1, 1, -1]],\n        W: [[1, 1, -1]]},\n    F: {\n        0: [7, 7, 7],\n        B: [[7, 7, 7]]},\n    G: [[5, 5, 5]],\n    H: [[5, 5, -1]],\n    I: {\n        0: [0, -1, -1],\n        A: [[1, -1, -1]],\n        E: [[1, -1, -1]],\n        O: [[1, -1, -1]],\n        U: [[1, -1, -1]]},\n    J: [[4, 4, 4]],\n    K: {\n        0: [5, 5, 5],\n        H: [[5, 5, 5]],\n        S: [[5, 54, 54]]},\n    L: [[8, 8, 8]],\n    M: {\n        0: [6, 6, 6],\n        N: [[66, 66, 66]]},\n    N: {\n        0: [6, 6, 6],\n        M: [[66, 66, 66]]},\n    O: {\n        0: [0, -1, -1],\n        I: [[0, 1, -1]],\n        J: [[0, 1, -1]],\n        Y: [[0, 1, -1]]},\n    P: {\n        0: [7, 7, 7],\n        F: [[7, 7, 7]],\n        H: [[7, 7, 7]]},\n    Q: [[5, 5, 5]],\n    R: {\n        0: [9, 9, 9],\n        Z: [[94, 94, 94], [94, 94, 94]],\n        S: [[94, 94, 94], [94, 94, 94]]},\n    S: {\n        0: [4, 4, 4],\n        Z: {0: [4, 4, 4], T: [[2, 43, 43]], C: {Z: [[2, 4, 4]], S: [[2, 4, 4]]}, D: [[2, 43, 43]]},\n        D: [[2, 43, 43]],\n        T: {0: [2, 43, 43], R: {Z: [[2, 4, 4]], S: [[2, 4, 4]]}, C: {H: [[2, 4, 4]]}, S: {H: [[2, 4, 4]], C: {H: [[2, 4, 4]]}}},\n        C: {0: [2, 4, 4], H: {0: [4, 4, 4], T: {0: [2, 43, 43], S: {C: {H: [[2, 4, 4]]}, H: [[2, 4, 4]]}, C: {H: [[2, 4, 4]]}}, D: [[2, 43, 43]]}},\n        H: {0: [4, 4, 4], T: {0: [2, 43, 43], C: {H: [[2, 4, 4]]}, S: {H: [[2, 4, 4]]}}, C: {H: [[2, 4, 4]]}, D: [[2, 43, 43]]}},\n    T: {\n        0: [3, 3, 3],\n        C: {0: [4, 4, 4], H: [[4, 4, 4]]},\n        Z: {0: [4, 4, 4], S: [[4, 4, 4]]},\n        S: {0: [4, 4, 4], Z: [[4, 4, 4]], H: [[4, 4, 4]], C: {H: [[4, 4, 4]]}},\n        T: {S: {0: [4, 4, 4], Z: [[4, 4, 4]], C: {H: [[4, 4, 4]]}}, C: {H: [[4, 4, 4]]}, Z: [[4, 4, 4]]},\n        H: [[3, 3, 3]],\n        R: {Z: [[4, 4, 4]], S: [[4, 4, 4]]}},\n    U: {\n        0: [0, -1, -1],\n        E: [[0, -1, -1]],\n        I: [[0, 1, -1]],\n        J: [[0, 1, -1]],\n        Y: [[0, 1, -1]]},\n    V: [[7, 7, 7]],\n    W: [[7, 7, 7]],\n    X: [[5, 54, 54]],\n    Y: [[1, -1, -1]],\n    Z: {\n        0: [4, 4, 4],\n        D: {0: [2, 43, 43], Z: {0: [2, 4, 4], H: [[2, 4, 4]]}},\n        H: {0: [4, 4, 4], D: {0: [2, 43, 43], Z: {H: [[2, 4, 4]]}}},\n        S: {0: [4, 4, 4], H: [[4, 4, 4]], C: {H: [[4, 4, 4]]}}}\n};\n\n\nfunction process(word, codeLength) {\n\tcodeLength = codeLength || 6;\n    word = word.toUpperCase();\n    var output = '';\n\n    var pos = 0, lastCode = -1;\n    while (pos < word.length) {\n        var substr = word.slice(pos);\n        var rules = findRules(substr);\n\n        var code;\n        if (pos == 0) {\n            // at the beginning of the word\n            code = rules.mapping[0];\n        } else if (substr[rules.length] && findRules(substr[rules.length]).mapping[0] == 0) {\n            // before a vowel\n            code = rules.mapping[1];\n        } else {\n            // any other situation\n            code = rules.mapping[2];\n        }\n\n        if ((code != -1) && (code != lastCode)) output += code;\n        lastCode = code;\n        pos += rules.length;\n\n    }\n\n    return normalizeLength(output, codeLength);\n}\n\n\nfunction findRules(str) {\n    var state = codes[str[0]];\n    var legalState = state || [[-1,-1,-1]],\n        charsInvolved = 1;\n\n    for (var offs = 1; offs < str.length; offs++) {\n        if (!state || !state[str[offs]]) break;\n\n        state = state[str[offs]];\n        if (state[0]) {\n            legalState = state;\n            charsInvolved = offs + 1;\n        }\n    }\n\n    return {\n        length: charsInvolved,\n        mapping: legalState[0]\n    };\n}\n\n\n/**\n * Pad right with zeroes or cut excess symbols to fit length\n */\nfunction normalizeLength(token, length) {\n\tlength = length || 6;\n\tif (token.length < length) {\n\t\ttoken += (new Array(length - token.length + 1)).join('0');\n\t}\n    return token.slice(0, length);\n}\n\nvar Phonetic = require('./phonetic');\nvar soundex = new Phonetic();\nsoundex.process = process;\nmodule.exports = soundex;\n\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/porter_stemmer.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Stemmer = require('./stemmer');\n\n// denote groups of consecutive consonants with a C and consecutive vowels\n// with a V.\nfunction categorizeGroups(token) {\n    return token.replace(/[^aeiouy]+y/g, 'CV').replace(/[aeiou]+/g, 'V').replace(/[^V]+/g, 'C');\n}\n\n// denote single consonants with a C and single vowels with a V\nfunction categorizeChars(token) {\n    return token.replace(/[^aeiouy]y/g, 'CV').replace(/[aeiou]/g, 'V').replace(/[^V]/g, 'C');\n}\n\n// calculate the \"measure\" M of a word. M is the count of VC sequences dropping\n// an initial C if it exists and a trailing V if it exists.\nfunction measure(token) {\n    if(!token)\n    \treturn -1;\n\n    return categorizeGroups(token).replace(/^C/, '').replace(/V$/, '').length / 2;\n}\n\n// determine if a token end with a double consonant i.e. happ\nfunction endsWithDoublCons(token) {\n    return token.match(/([^aeiou])\\1$/);\n}\n\n// replace a pattern in a word. if a replacement occurs an optional callback\n// can be called to post-process the result. if no match is made NULL is\n// returned.\nfunction attemptReplace(token, pattern, replacement, callback) {\n    var result = null;\n    \n    if((typeof pattern == 'string') && token.substr(0 - pattern.length) == pattern)\n        result = token.replace(new RegExp(pattern + '$'), replacement);\n    else if((pattern instanceof RegExp) && token.match(pattern))\n        result = token.replace(pattern, replacement);\n        \n    if(result && callback)\n        return callback(result);\n    else\n        return result;\n}\n\n// attempt to replace a list of patterns/replacements on a token for a minimum\n// measure M.\nfunction attemptReplacePatterns(token, replacements, measureThreshold) {\n    var replacement = token;\n\n    for(var i = 0; i < replacements.length; i++) {   \n    \tif(measureThreshold == null || measure(attemptReplace(token, replacements[i][0], replacements[i][1])) > measureThreshold) {\n    \t    replacement = attemptReplace(replacement, replacements[i][0], replacements[i][2]) || replacement;\n        }\n    }\n    \n    return replacement;\n}\n\n// replace a list of patterns/replacements on a word. if no match is made return\n// the original token.\nfunction replacePatterns(token, replacements, measureThreshold) {\n    return attemptReplacePatterns(token, replacements, measureThreshold) || token;\n}\n\n// TODO: this should replace all of the messy replacement stuff above\nfunction replaceRegex(token, regex, includeParts, minimumMeasure) {\n    var parts;\n    var result = '';\n\n    if(regex.test(token)) {\n        parts = regex.exec(token);\n\n        includeParts.forEach(function(i) {\n            result += parts[i];\n        });\n    }\n\n    if(measure(result) > minimumMeasure) {\n        return result;\n    }\n\n    return null;\n}\n\n// step 1a as defined for the porter stemmer algorithm. \nfunction step1a(token) {    \n    if(token.match(/(ss|i)es$/)) {\n        return token.replace(/(ss|i)es$/, '$1');\n    }\n\n    if(token.substr(-1) == 's' && token.substr(-2, 1) != 's' && token.length > 2) {\n        return token.replace(/s?$/, '');\n    }\n\n    return token;\n}\n\n// step 1b as defined for the porter stemmer algorithm. \nfunction step1b(token) {   \n    if(token.substr(-3) == 'eed') {\n        if(measure(token.substr(0, token.length - 3)) > 0)\n            return token.replace(/eed$/, 'ee');\n    } else {\n        var result = attemptReplace(token, /(ed|ing)$/, '', function(token) {\n            if(categorizeGroups(token).indexOf('V') >= 0) {\n                result = attemptReplacePatterns(token, [['at', '', 'ate'],  ['bl', '', 'ble'], ['iz', '', 'ize']]);\n\n                if(result != token) {\n        \t\t    return result;\n        \t\t} else {\n        \t\t  if(endsWithDoublCons(token) && token.match(/[^lsz]$/)) {\n        \t\t\t return token.replace(/([^aeiou])\\1$/, '$1');\n                    }\n\n        \t\t  if(measure(token) == 1 && categorizeChars(token).substr(-3) == 'CVC' && token.match(/[^wxy]$/)) {\n        \t\t\t return token + 'e';\n                    }\n        \t\t}                \n\n        \t\treturn token;\n    \t    }\n    \t    \n    \t    return null;\n    \t});\n    \t\n    \tif(result) {\n    \t    return result;\n        }\n    }\n\n    return token;   \n}\n\n// step 1c as defined for the porter stemmer algorithm. \nfunction step1c(token) {\n    var categorizedGroups = categorizeGroups(token);\n\n    if(token.substr(-1) == 'y' && categorizedGroups.substr(0, categorizedGroups.length - 1).indexOf('V') > -1) {\n        return token.replace(/y$/, 'i');\n    }\n\n    return token;\n}\n\n// step 2 as defined for the porter stemmer algorithm. \nfunction step2(token) {\n    token = replacePatterns(token, [['ational', '', 'ate'], ['tional', '', 'tion'], ['enci', '', 'ence'], ['anci', '', 'ance'],\n        ['izer', '', 'ize'], ['abli', '', 'able'], ['bli', '', 'ble'], ['alli', '', 'al'], ['entli', '', 'ent'], ['eli', '', 'e'],\n        ['ousli', '', 'ous'], ['ization', '', 'ize'], ['ation', '', 'ate'], ['ator', '', 'ate'],['alism', '', 'al'],\n        ['iveness', '', 'ive'], ['fulness', '', 'ful'], ['ousness', '', 'ous'], ['aliti', '', 'al'],\n        ['iviti', '', 'ive'], ['biliti', '', 'ble'], ['logi', '', 'log']], 0);\n\n    return token;\n}\n\n// step 3 as defined for the porter stemmer algorithm. \nfunction step3(token) {\n    return replacePatterns(token, [['icate', '', 'ic'], ['ative', '', ''], ['alize', '', 'al'],\n\t\t\t\t   ['iciti', '', 'ic'], ['ical', '', 'ic'], ['ful', '', ''], ['ness', '', '']], 0);\n}\n\n// step 4 as defined for the porter stemmer algorithm. \nfunction step4(token) {\n    return replaceRegex(token, /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/, [1], 1) || \n        replaceRegex(token, /^(.+?)(s|t)(ion)$/, [1, 2], 1) ||\n        token; \n}\n\n// step 5a as defined for the porter stemmer algorithm. \nfunction step5a(token) {\n    var m = measure(token.replace(/e$/, ''));\n\n\n\n    if(m > 1 || (m == 1 && !(categorizeChars(token).substr(-4, 3) == 'CVC' && token.match(/[^wxy].$/)))) {\n        token = token.replace(/e$/, '');\n    }\n\n    return token;\n}\n\n// step 5b as defined for the porter stemmer algorithm. \nfunction step5b(token) {\n    if(measure(token) > 1) {\n       return token.replace(/ll$/, 'l'); \n    }\n    \n    return token;\n}\n\nvar PorterStemmer = new Stemmer();\nmodule.exports = PorterStemmer;\n\n\n// perform full stemming algorithm on a single word\nPorterStemmer.stem = function(token) {\n    if(token.length < 3) return token;\n    return step5b(step5a(step4(step3(step2(step1c(step1b(step1a(token.toLowerCase())))))))).toString();\n};\n\n//exports for tests\nPorterStemmer.categorizeGroups = categorizeGroups;\nPorterStemmer.measure = measure;\nPorterStemmer.step1a = step1a;\nPorterStemmer.step1b = step1b;\nPorterStemmer.step1c = step1c;\nPorterStemmer.step2 = step2;\nPorterStemmer.step3 = step3;\nPorterStemmer.step4 = step4;\nPorterStemmer.step5a = step5a;\nPorterStemmer.step5b = step5b;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/stemmer.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar stopwords = require('../util/stopwords');\nvar Tokenizer = require('../tokenizers/aggressive_tokenizer');\n\nmodule.exports = function() {\n    var stemmer = this;\n\n    stemmer.stem = function(token) {\n        return token;\n    };\n\n    stemmer.addStopWord = function(stopWord) {\n        stopwords.words.push(stopWord);\n    };\n\n    stemmer.addStopWords = function(moreStopWords) {\n        stopwords.words = stopwords.words.concat(moreStopWords);\n    };\n\n    stemmer.removeStopWord = function(stopWord) {\n        this.removeStopWords([stopWord])\n    };\n\n    stemmer.removeStopWords = function(moreStopWords) {\n        moreStopWords.forEach(function(stopWord){\n            var idx = stopwords.words.indexOf(stopWord);\n            if (idx >= 0) {\n                stopwords.words.splice(idx, 1);\n            }\n        });\n\n    };\n\n\n    stemmer.tokenizeAndStem = function(text, keepStops) {\n        var stemmedTokens = [];\n        var lowercaseText = text.toLowerCase();\n        var tokens = new Tokenizer().tokenize(lowercaseText);\n\n        if (keepStops) {\n            tokens.forEach(function(token) {\n                stemmedTokens.push(stemmer.stem(token));\n            });\n        }\n\n        else {\n            tokens.forEach(function(token) {\n                if (stopwords.words.indexOf(token) == -1)\n                    stemmedTokens.push(stemmer.stem(token));\n            });\n        }\n\n        return stemmedTokens;\n    };\n\n    stemmer.attach = function() {\n        String.prototype.stem = function() {\n            return stemmer.stem(this);\n        };\n\n        String.prototype.tokenizeAndStem = function(keepStops) {\n            return stemmer.tokenizeAndStem(this, keepStops);\n        };\n    };\n}\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/porter_stemmer_fa.js":"/*\r\nCopyright (c) 2011, Chris Umbel\r\nFarsi Porter Stemmer by Fardin Koochaki <me@fardinak.com>\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in\r\nall copies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\r\nTHE SOFTWARE.\r\n*/\r\n\r\nvar Stemmer = require('./stemmer_fa');\r\n\r\nvar PorterStemmer = new Stemmer();\r\nmodule.exports = PorterStemmer;\r\n\r\n// disabled stemming for Farsi\r\n// Farsi stemming will be supported soon\r\nPorterStemmer.stem = function(token) {\r\n    return token;\r\n};","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/stemmer_fa.js":"/*\r\nCopyright (c) 2011, Chris Umbel\r\nFarsi Stemmer by Fardin Koochaki <me@fardinak.com>\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in\r\nall copies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\r\nTHE SOFTWARE.\r\n*/\r\n\r\nvar stopwords = require('../util/stopwords_fa');\r\nvar Tokenizer = require('../tokenizers/aggressive_tokenizer_fa');\r\n\r\nmodule.exports = function() {\r\n    var stemmer = this;\r\n\r\n    stemmer.stem = function(token) {\r\n        return token;\r\n    };\r\n\r\n    stemmer.tokenizeAndStem = function(text, keepStops) {\r\n        var stemmedTokens = [];\r\n        \r\n        new Tokenizer().tokenize(text).forEach(function(token) {\r\n            if(keepStops || stopwords.words.indexOf(token) == -1)\r\n                stemmedTokens.push(stemmer.stem(token));\r\n        });\r\n        \r\n        return stemmedTokens;\r\n    };\r\n\r\n    stemmer.attach = function() {\r\n        String.prototype.stem = function() {\r\n            return stemmer.stem(this);\r\n        };\r\n        \r\n        String.prototype.tokenizeAndStem = function(keepStops) {\r\n            return stemmer.tokenizeAndStem(this, keepStops);\r\n        };\r\n    };\r\n}\r\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/stopwords_fa.js":"/*\r\nCopyright (c) 2011, Chris Umbel\r\nFarsi Stop Words by Fardin Koochaki <me@fardinak.com>\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in\r\nall copies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\r\nTHE SOFTWARE.\r\n*/\r\n\r\n// a list of commonly used words that have little meaning and can be excluded\r\n// from analysis.\r\nvar words = [\r\n    // Words\r\n    'از', 'با', 'یه', 'برای', 'و', 'باید', 'شاید',\r\n\r\n    // Symbols\r\n    '؟', '!', '٪', '.', '،', '؛', ':', ';', ',',\r\n    \r\n    // Numbers\r\n    '۱', '۲', '۳', '۴', '۵', '۶', '۷', '۸', '۹', '۰'\r\n];\r\n    \r\n// tell the world about the noise words.    \r\nexports.words = words;\r\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_fa.js":"/*\r\nCopyright (c) 2011, Chris Umbel\r\nFarsi Aggressive Tokenizer by Fardin Koochaki <me@fardinak.com>\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in\r\nall copies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\r\nTHE SOFTWARE.\r\n*/\r\n\r\nvar Tokenizer = require('./tokenizer'),\r\n    util = require('util');\r\n\r\nvar AggressiveTokenizer = function() {\r\n    Tokenizer.call(this);    \r\n};\r\nutil.inherits(AggressiveTokenizer, Tokenizer);\r\n\r\nmodule.exports = AggressiveTokenizer;\r\n\r\nAggressiveTokenizer.prototype.clearEmptyString = function(array) {\r\n\treturn array.filter(function(a) {\r\n\t\treturn a != '';\r\n\t});\r\n};\r\n\r\nAggressiveTokenizer.prototype.clearText = function(text) {\r\n\treturn text.replace(new RegExp('\\.\\:\\+\\-\\=\\(\\)\\\"\\'\\!\\?\\،\\,\\؛\\;', 'g'), ' ');\r\n};\r\n\r\nAggressiveTokenizer.prototype.tokenize = function(text) {\r\n    // break a string up into an array of tokens by anything non-word\r\n    text = this.clearText(text);\r\n    return this.clearEmptyString(text.split(/\\s+/));\r\n};\r\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/porter_stemmer_fr.js":"'use strict';\n\n/*\nCopyright (c) 2014, Ismaël Héry\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n/*\n * Spec for the French Porter Stemmer can be found at:\n * http://snowball.tartarus.org/algorithms/french/stemmer.html\n */\n\nvar Stemmer = require('./stemmer_fr');\n\nvar PorterStemmer = new Stemmer();\nmodule.exports = PorterStemmer;\n\n// Export\nPorterStemmer.stem = stem;\n\n// Exports for test purpose\nPorterStemmer.prelude = prelude;\nPorterStemmer.regions = regions;\nPorterStemmer.endsinArr = endsinArr;\n\n/**\n * Stem a word thanks to Porter Stemmer rules\n * @param  {String} token Word to be stemmed\n * @return {String}       Stemmed word\n */\nfunction stem(token) {\n  token = prelude(token.toLowerCase());\n\n  if (token.length == 1)\n    return token;\n\n  var regs = regions(token);\n\n  var r1_txt, r2_txt, rv_txt;\n  r1_txt = token.substring(regs.r1);\n  r2_txt = token.substring(regs.r2);\n  rv_txt = token.substring(regs.rv);\n\n  // Step 1\n  var beforeStep1 = token;\n  var suf, pref2, pref3, letterBefore, letter2Before, i;\n  var doStep2a = false;\n\n  if ((suf = endsinArr(r2_txt, ['ance', 'iqUe', 'isme', 'able', 'iste', 'eux', 'ances', 'iqUes', 'ismes', 'ables', 'istes'])) != '') {\n    token = token.slice(0, -suf.length); // delete\n  } else if ((suf = endsinArr(token, ['icatrice', 'icateur', 'ication', 'icatrices', 'icateurs', 'ications'])) != '') {\n    if (endsinArr(r2_txt, ['icatrice', 'icateur', 'ication', 'icatrices', 'icateurs', 'ications']) != '') {\n      token = token.slice(0, -suf.length); // delete\n    } else {\n      token = token.slice(0, -suf.length) + 'iqU'; // replace by iqU\n    }\n  } else if ((suf = endsinArr(r2_txt, ['atrice', 'ateur', 'ation', 'atrices', 'ateurs', 'ations'])) != '') {\n    token = token.slice(0, -suf.length); // delete\n  } else if ((suf = endsinArr(r2_txt, ['logie', 'logies'])) != '') {\n    token = token.slice(0, -suf.length) + 'log'; // replace with log\n  } else if ((suf = endsinArr(r2_txt, ['usion', 'ution', 'usions', 'utions'])) != '') {\n    token = token.slice(0, -suf.length) + 'u'; // replace with u\n  } else if ((suf = endsinArr(r2_txt, ['ence', 'ences'])) != '') {\n    token = token.slice(0, -suf.length) + 'ent'; // replace with ent\n  }\n  // ement(s)\n  else if ((suf = endsinArr(r1_txt, ['issement', 'issements'])) != '') {\n    if (!isVowel(token[token.length - suf.length - 1])) {\n      token = token.slice(0, -suf.length); // delete\n      r1_txt = token.substring(regs.r1);\n      r2_txt = token.substring(regs.r2);\n      rv_txt = token.substring(regs.rv);\n    }\n  } else if ((suf = endsinArr(r2_txt, ['ativement', 'ativements'])) != '') {\n    token = token.slice(0, -suf.length); // delete\n  } else if ((suf = endsinArr(r2_txt, ['ivement', 'ivements'])) != '') {\n    token = token.slice(0, -suf.length); // delete\n  } else if ((suf = endsinArr(token, ['eusement', 'eusements'])) != '') {\n    if ((suf = endsinArr(r2_txt, ['eusement', 'eusements'])) != '')\n      token = token.slice(0, -suf.length); // delete\n    else if ((suf = endsinArr(r1_txt, ['eusement', 'eusements'])) != '')\n      token = token.slice(0, -suf.length) + 'eux'; // replace by eux\n    else if ((suf = endsinArr(rv_txt, ['ement', 'ements'])) != '')\n      token = token.slice(0, -suf.length); // delete\n  } else if ((suf = endsinArr(r2_txt, ['ablement', 'ablements', 'iqUement', 'iqUements'])) != '') {\n    token = token.slice(0, -suf.length); // delete\n  } else if ((suf = endsinArr(rv_txt, ['ièrement', 'ièrements', 'Ièrement', 'Ièrements'])) != '') {\n    token = token.slice(0, -suf.length) + 'i'; // replace by i\n  } else if ((suf = endsinArr(rv_txt, ['ement', 'ements'])) != '') {\n    token = token.slice(0, -suf.length); // delete\n  }\n  // ité(s)\n  else if ((suf = endsinArr(token, ['icité', 'icités'])) != '') {\n    if (endsinArr(r2_txt, ['icité', 'icités']) != '')\n      token = token.slice(0, -suf.length); // delete\n    else\n      token = token.slice(0, -suf.length) + 'iqU'; // replace by iqU\n  } else if ((suf = endsinArr(token, ['abilité', 'abilités'])) != '') {\n    if (endsinArr(r2_txt, ['abilité', 'abilités']) != '')\n      token = token.slice(0, -suf.length); // delete\n    else\n      token = token.slice(0, -suf.length) + 'abl'; // replace by abl\n  } else if ((suf = endsinArr(r2_txt, ['ité', 'ités'])) != '') {\n    token = token.slice(0, -suf.length); // delete if in R2\n  } else if ((suf = endsinArr(token, ['icatif', 'icative', 'icatifs', 'icatives'])) != '') {\n    if ((suf = endsinArr(r2_txt, ['icatif', 'icative', 'icatifs', 'icatives'])) != '') {\n      token = token.slice(0, -suf.length); // delete\n      r2_txt = token.substring(regs.r2);\n      rv_txt = token.substring(regs.rv);\n    }\n    if ((suf = endsinArr(r2_txt, ['atif', 'ative', 'atifs', 'atives'])) != '') {\n      token = token.slice(0, -suf.length - 2) + 'iqU'; // replace with iqU\n      r2_txt = token.substring(regs.r2);\n      rv_txt = token.substring(regs.rv);\n    }\n  } else if ((suf = endsinArr(r2_txt, ['atif', 'ative', 'atifs', 'atives'])) != '') {\n    token = token.slice(0, -suf.length); // delete\n  } else if ((suf = endsinArr(r2_txt, ['if', 'ive', 'ifs', 'ives'])) != '') {\n    token = token.slice(0, -suf.length); // delete\n  } else if ((suf = endsinArr(token, ['eaux'])) != '') {\n    token = token.slice(0, -suf.length) + 'eau'; // replace by eau\n  } else if ((suf = endsinArr(r1_txt, ['aux'])) != '') {\n    token = token.slice(0, -suf.length) + 'al'; // replace by al\n  } else if ((suf = endsinArr(r2_txt, ['euse', 'euses'])) != '') {\n    token = token.slice(0, -suf.length); // delete\n  } else if ((suf = endsinArr(r1_txt, ['euse', 'euses'])) != '') {\n    token = token.slice(0, -suf.length) + 'eux'; // replace by eux\n  } else if ((suf = endsinArr(rv_txt, ['amment'])) != '') {\n    token = token.slice(0, -suf.length) + 'ant'; // replace by ant\n    doStep2a = true;\n  } else if ((suf = endsinArr(rv_txt, ['emment'])) != '') {\n    token = token.slice(0, -suf.length) + 'ent'; // replace by ent\n    doStep2a = true;\n  } else if ((suf = endsinArr(rv_txt, ['ment', 'ments'])) != '') {\n    // letter before must be a vowel in RV\n    letterBefore = token[token.length - suf.length - 1];\n    if (isVowel(letterBefore) && endsin(rv_txt, letterBefore + suf)) {\n      token = token.slice(0, -suf.length); // delete\n      doStep2a = true;\n    }\n  }\n\n  // re compute regions\n  r1_txt = token.substring(regs.r1);\n  r2_txt = token.substring(regs.r2);\n  rv_txt = token.substring(regs.rv);\n\n  // Step 2a\n  var beforeStep2a = token;\n  var step2aDone = false;\n  if (beforeStep1 === token || doStep2a) {\n    step2aDone = true;\n    if ((suf = endsinArr(rv_txt, ['îmes', 'ît', 'îtes', 'i', 'ie', 'Ie', 'ies', 'ir', 'ira', 'irai', 'iraIent', 'irais', 'irait', 'iras', 'irent', 'irez', 'iriez', 'irions', 'irons', 'iront', 'is', 'issaIent', 'issais', 'issait', 'issant', 'issante', 'issantes', 'issants', 'isse', 'issent', 'isses', 'issez', 'issiez', 'issions', 'issons', 'it'])) != '') {\n      letterBefore = token[token.length - suf.length - 1];\n      if (!isVowel(letterBefore) && endsin(rv_txt, letterBefore + suf))\n        token = token.slice(0, -suf.length); // delete\n    }\n  }\n\n  // Step 2b\n  if (step2aDone && token === beforeStep2a) {\n    if ((suf = endsinArr(rv_txt, ['é', 'ée', 'ées', 'és', 'èrent', 'er', 'era', 'erai', 'eraIent', 'erais', 'erait', 'eras', 'erez', 'eriez', 'erions', 'erons', 'eront', 'ez', 'iez', 'Iez'])) != '') {\n      token = token.slice(0, -suf.length); // delete\n      r2_txt = token.substring(regs.r2);\n      rv_txt = token.substring(regs.rv);\n    } else if ((suf = endsinArr(rv_txt, ['ions'])) != '' && endsinArr(r2_txt, ['ions'])) {\n      token = token.slice(0, -suf.length); // delete\n      r2_txt = token.substring(regs.r2);\n      rv_txt = token.substring(regs.rv);\n    }\n    // add 'Ie' suffix to pass test for 'évanouie'\n    else if ((suf = endsinArr(rv_txt, ['âmes', 'ât', 'âtes', 'a', 'ai', 'aIent', 'ais', 'ait', 'ant', 'ante', 'antes', 'ants', 'as', 'asse', 'assent', 'asses', 'assiez', 'assions'])) != '') {\n      token = token.slice(0, -suf.length); // delete\n\n      letterBefore = token[token.length - 1];\n      if (letterBefore === 'e' && endsin(rv_txt, 'e' + suf))\n        token = token.slice(0, -1);\n\n      r2_txt = token.substring(regs.r2);\n      rv_txt = token.substring(regs.rv);\n    }\n  }\n\n  // Step 3\n  if (!(token === beforeStep1)) {\n    if (token[token.length - 1] === 'Y')\n      token = token.slice(0, -1) + 'i';\n    if (token[token.length - 1] === 'ç')\n      token = token.slice(0, -1) + 'c';\n  } // Step 4\n  else {\n    letterBefore = token[token.length - 1];\n    letter2Before = token[token.length - 2];\n\n    if (letterBefore === 's' && ['a', 'i', 'o', 'u', 'è', 's'].indexOf(letter2Before) == -1) {\n      token = token.slice(0, -1);\n      r1_txt = token.substring(regs.r1);\n      r2_txt = token.substring(regs.r2);\n      rv_txt = token.substring(regs.rv);\n    }\n\n    if ((suf = endsinArr(r2_txt, ['ion'])) != '') {\n      letterBefore = token[token.length - suf.length - 1];\n      if (letterBefore === 's' || letterBefore === 't') {\n        token = token.slice(0, -suf.length); // delete\n        r1_txt = token.substring(regs.r1);\n        r2_txt = token.substring(regs.r2);\n        rv_txt = token.substring(regs.rv);\n      }\n    }\n\n    if ((suf = endsinArr(rv_txt, ['ier', 'ière', 'Ier', 'Ière'])) != '') {\n      token = token.slice(0, -suf.length) + 'i'; // replace by i\n      r1_txt = token.substring(regs.r1);\n      r2_txt = token.substring(regs.r2);\n      rv_txt = token.substring(regs.rv);\n    }\n    if ((suf = endsinArr(rv_txt, 'e')) != '') {\n      token = token.slice(0, -suf.length); // delete\n      r1_txt = token.substring(regs.r1);\n      r2_txt = token.substring(regs.r2);\n      rv_txt = token.substring(regs.rv);\n    }\n    if ((suf = endsinArr(rv_txt, 'ë')) != '') {\n      if (token.slice(token.length - 3, -1) === 'gu')\n        token = token.slice(0, -suf.length); // delete\n    }\n  }\n\n  // Step 5\n  if ((suf = endsinArr(token, ['enn', 'onn', 'ett', 'ell', 'eill'])) != '') {\n    token = token.slice(0, -1); // delete last letter\n  }\n\n  // Step 6\n  i = token.length - 1;\n  while (i > 0) {\n    if (!isVowel(token[i])) {\n      i--;\n    } else if (i !== token.length - 1 && (token[i] === 'é' || token[i] === 'è')) {\n      token = token.substring(0, i) + 'e' + token.substring(i + 1, token.length);\n      break;\n    } else {\n      break;\n    }\n  }\n\n  return token.toLowerCase();\n\n};\n\n/**\n * Compute r1, r2, rv regions as required by french porter stemmer algorithm\n * @param  {String} token Word to compute regions on\n * @return {Object}       Regions r1, r2, rv as offsets from the begining of the word\n */\nfunction regions(token) {\n  var r1, r2, rv, len;\n  var i;\n\n  r1 = r2 = rv = len = token.length;\n\n  // R1 is the region after the first non-vowel following a vowel,\n  for (var i = 0; i < len - 1 && r1 == len; i++) {\n    if (isVowel(token[i]) && !isVowel(token[i + 1])) {\n      r1 = i + 2;\n    }\n  }\n  // Or is the null region at the end of the word if there is no such non-vowel.\n\n  // R2 is the region after the first non-vowel following a vowel in R1\n  for (i = r1; i < len - 1 && r2 == len; i++) {\n    if (isVowel(token[i]) && !isVowel(token[i + 1])) {\n      r2 = i + 2;\n    }\n  }\n  // Or is the null region at the end of the word if there is no such non-vowel.\n\n  // RV region\n  var three = token.slice(0, 3);\n  if (isVowel(token[0]) && isVowel(token[1])) {\n    rv = 3;\n  }\n  if (three === 'par' || three == 'col' || three === 'tap')\n    rv = 3;\n  // the region after the first vowel not at the beginning of the word or null\n  else {\n    for (i = 1; i < len - 1 && rv == len; i++) {\n      if (isVowel(token[i])) {\n        rv = i + 1;\n      }\n    }\n  }\n\n  return {\n    r1: r1,\n    r2: r2,\n    rv: rv\n  };\n};\n\n/**\n * Pre-process/prepare words as required by french porter stemmer algorithm\n * @param  {String} token Word to be prepared\n * @return {String}       Prepared word\n */\nfunction prelude(token) {\n  token = token.toLowerCase();\n\n  var result = '';\n  var i = 0;\n\n  // special case for i = 0 to avoid '-1' index\n  if (token[i] === 'y' && isVowel(token[i + 1])) {\n    result += token[i].toUpperCase();\n  } else {\n    result += token[i];\n  }\n\n  for (i = 1; i < token.length; i++) {\n    if ((token[i] === 'u' || token[i] === 'i') && isVowel(token[i - 1]) && isVowel(token[i + 1])) {\n      result += token[i].toUpperCase();\n    } else if (token[i] === 'y' && (isVowel(token[i - 1]) || isVowel(token[i + 1]))) {\n      result += token[i].toUpperCase();\n    } else if (token[i] === 'u' && token[i - 1] === 'q') {\n      result += token[i].toUpperCase();\n    } else {\n      result += token[i];\n    }\n  }\n\n  return result;\n};\n\n/**\n * Return longest matching suffixes for a token or '' if no suffix match\n * @param  {String} token    Word to find matching suffix\n * @param  {Array} suffixes  Array of suffixes to test matching\n * @return {String}          Longest found matching suffix or ''\n */\nfunction endsinArr(token, suffixes) {\n  var i, longest = '';\n  for (i = 0; i < suffixes.length; i++) {\n    if (endsin(token, suffixes[i]) && suffixes[i].length > longest.length)\n      longest = suffixes[i];\n  }\n\n  return longest;\n};\n\n\nfunction isVowel(letter) {\n  return (letter == 'a' || letter == 'e' || letter == 'i' || letter == 'o' || letter == 'u' || letter == 'y' || letter == 'â' || letter == 'à' || letter == 'ë' ||\n    letter == 'é' || letter == 'ê' || letter == 'è' || letter == 'ï' || letter == 'î' || letter == 'ô' || letter == 'û' || letter == 'ù');\n};\n\nfunction endsin(token, suffix) {\n  if (token.length < suffix.length) return false;\n  return (token.slice(-suffix.length) == suffix);\n};","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/stemmer_fr.js":"/*\nCopyright (c) 2014, Ismaël Héry\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar stopwords = require('../util/stopwords_fr');\nvar Tokenizer = require('../tokenizers/aggressive_tokenizer_fr');\n\nmodule.exports = function() {\n   var stemmer = this;\n\n   stemmer.stem = function(token) {\n      return token;\n   };\n\n   stemmer.tokenizeAndStem = function(text, keepStops) {\n      var stemmedTokens = [];\n\n      new Tokenizer().tokenize(text).forEach(function(token) {\n         if (keepStops || stopwords.words.indexOf(token) == -1) {\n            var resultToken = token.toLowerCase();\n            if (resultToken.match(/[a-zâàëéêèïîôûùç0-9]/gi)) {\n               resultToken = stemmer.stem(resultToken);\n            }\n            stemmedTokens.push(resultToken);\n         }\n      });\n\n      return stemmedTokens;\n   };\n\n   stemmer.attach = function() {\n      String.prototype.stem = function() {\n         return stemmer.stem(this);\n      };\n\n      String.prototype.tokenizeAndStem = function(keepStops) {\n         return stemmer.tokenizeAndStem(this, keepStops);\n      };\n   };\n}\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/stopwords_fr.js":"/*\n Copyright (c) 2014, Ismaël Héry\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n\n// A list of commonly used french words that have little meaning and can be excluded\n// from analysis.\n\nvar words = ['être', 'avoir', 'faire',\n    'a',\n    'au',\n    'aux',\n    'avec',\n    'ce',\n    'ces',\n    'dans',\n    'de',\n    'des',\n    'du',\n    'elle',\n    'en',\n    'et',\n    'eux',\n    'il',\n    'je',\n    'la',\n    'le',\n    'leur',\n    'lui',\n    'ma',\n    'mais',\n    'me',\n    'même',\n    'mes',\n    'moi',\n    'mon',\n    'ne',\n    'nos',\n    'notre',\n    'nous',\n    'on',\n    'ou',\n    'où',\n    'par',\n    'pas',\n    'pour',\n    'qu',\n    'que',\n    'qui',\n    'sa',\n    'se',\n    'ses',\n    'son',\n    'sur',\n    'ta',\n    'te',\n    'tes',\n    'toi',\n    'ton',\n    'tu',\n    'un',\n    'une',\n    'vos',\n    'votre',\n    'vous',\n    'c',\n    'd',\n    'j',\n    'l',\n    'à',\n    'm',\n    'n',\n    's',\n    't',\n    'y',\n    'été',\n    'étée',\n    'étées',\n    'étés',\n    'étant',\n    'suis',\n    'es',\n    'est',\n    'sommes',\n    'êtes',\n    'sont',\n    'serai',\n    'seras',\n    'sera',\n    'serons',\n    'serez',\n    'seront',\n    'serais',\n    'serait',\n    'serions',\n    'seriez',\n    'seraient',\n    'étais',\n    'était',\n    'étions',\n    'étiez',\n    'étaient',\n    'fus',\n    'fut',\n    'fûmes',\n    'fûtes',\n    'furent',\n    'sois',\n    'soit',\n    'soyons',\n    'soyez',\n    'soient',\n    'fusse',\n    'fusses',\n    'fût',\n    'fussions',\n    'fussiez',\n    'fussent',\n    'ayant',\n    'eu',\n    'eue',\n    'eues',\n    'eus',\n    'ai',\n    'as',\n    'avons',\n    'avez',\n    'ont',\n    'aurai',\n    'auras',\n    'aura',\n    'aurons',\n    'aurez',\n    'auront',\n    'aurais',\n    'aurait',\n    'aurions',\n    'auriez',\n    'auraient',\n    'avais',\n    'avait',\n    'avions',\n    'aviez',\n    'avaient',\n    'eut',\n    'eûmes',\n    'eûtes',\n    'eurent',\n    'aie',\n    'aies',\n    'ait',\n    'ayons',\n    'ayez',\n    'aient',\n    'eusse',\n    'eusses',\n    'eût',\n    'eussions',\n    'eussiez',\n    'eussent',\n    'ceci',\n    'cela',\n    'cet',\n    'cette',\n    'ici',\n    'ils',\n    'les',\n    'leurs',\n    'quel',\n    'quels',\n    'quelle',\n    'quelles',\n    'sans',\n    'soi'\n];\n\nexports.words = words;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_fr.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Tokenizer = require('./tokenizer'),\n    util = require('util');\n\nvar AggressiveTokenizer = function() {\n    Tokenizer.call(this);    \n};\nutil.inherits(AggressiveTokenizer, Tokenizer);\n\nmodule.exports = AggressiveTokenizer;\n\nAggressiveTokenizer.prototype.tokenize = function(text) {\n    // break a string up into an array of tokens by anything non-word\n    return this.trim(text.split(/[^a-z0-9äâàéèëêïîöôùüûœç]+/i));\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/porter_stemmer_ru.js":"/*\nCopyright (c) 2012, Polyakov Vladimir, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Stemmer = require('./stemmer_ru');\n\nvar PorterStemmer = new Stemmer();\nmodule.exports = PorterStemmer;\n\nfunction attemptReplacePatterns(token, patterns) {\n\tvar replacement = null;\n\tvar i = 0, isReplaced = false;\n\twhile ((i < patterns.length) && !isReplaced) {\n\t\tif (patterns[i][0].test(token)) {\n\t\t\treplacement = token.replace(patterns[i][0], patterns[i][1]);\n\t\t\tisReplaced = true;\n\t\t}\n\t\ti++;\n\t}\n\treturn replacement;\n};\n\nfunction perfectiveGerund(token) {\n\tvar result = attemptReplacePatterns(token, [\n\t\t\t[/[ая]в(ши|шись)$/g, ''],\n\t\t\t[/(ив|ивши|ившись|ывши|ывшись|ыв)$/g, '']\n\t\t]);\n\treturn result;\n};\n\nfunction adjectival(token) {\n\tvar result = adjective(token);\n\tif (result != null) {\n\t\tvar pariticipleResult = participle(result);\n\t\tresult = pariticipleResult ? pariticipleResult : result;\n\t}\n\treturn result;\n};\n\nfunction adjective(token) {\n\tvar result = attemptReplacePatterns(token, [\n\t\t\t[/(ее|ие|ые|ое|ими|ыми|ей|ий|ый|ой|ем|им|ым|ом|его|ого|ему|ому|их|ых|ую|юю|ая|яя|ою|ею)$/g, '']\n\t\t]);\n\treturn result;\n};\n\nfunction participle(token) {\n\tvar result = attemptReplacePatterns(token, [\n\t\t[/([ая])(ем|нн|вш|ющ|щ)$/g, '$1'],\n\t\t[/(ивш|ывш|ующ)$/g, '']\n\t]);\n\treturn result;\n};\n\nfunction reflexive(token) {\n\tvar result = attemptReplacePatterns(token, [\n\t\t[/(ся|сь)$/g, '']\n\t]);\n\treturn result;\n};\n\nfunction verb(token) {\n\tvar result = attemptReplacePatterns(token, [\n\t\t[/([ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|нно)$/g, '$1'],\n\t\t[/(ила|ыла|ена|ейте|уйте|ите|или|ыли|ей|уй|ил|ыл|им|ым|ен|ило|ыло|ено|ят|ует|ит|ыт|ены|ить|ыть|ишь|ую|ю)$/g, '']\n\t]);\n\treturn result;\n};\n\nfunction noun(token) {\n\tvar result = attemptReplacePatterns(token, [\n\t\t[/(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$/g, '']\n\t]);\n\treturn result;\n};\n\nfunction superlative (token) {\n\tvar result = attemptReplacePatterns(token, [\n\t\t[/(ейш|ейше)$/g, '']\n\t]);\n\treturn result;\n};\n\nfunction derivational (token) {\n\tvar result = attemptReplacePatterns(token, [\n\t\t[/(ост|ость)$/g, '']\n\t]);\n\treturn result;\n};\n\n// perform full stemming algorithm on a single word\nPorterStemmer.stem = function(token) {\n\ttoken = token.toLowerCase().replace(/ё/g, 'е');\n\tvar volwesRegexp = /^(.*?[аеиоюяуыиэ])(.*)$/g;\n\tvar RV = volwesRegexp.exec(token);\n\tif (!RV || RV.length < 3) {\n\t\treturn token;\n\t}\n\tvar head = RV[1];\n\tRV = RV[2];\n\tvolwesRegexp.lastIndex = 0;\n\tvar R2 = volwesRegexp.exec(RV);\n\tvar result = perfectiveGerund(RV);\n\tif (result === null) {\n\t\tvar resultReflexive = reflexive(RV) || RV;\n\t\tresult = adjectival(resultReflexive);\n\t\tif (result === null) {\n\t\t\tresult = verb(resultReflexive);\n\t\t\tif (result === null) {\n\t\t\t\tresult = noun(resultReflexive);\n\t\t\t\tif (result === null) {\n\t\t\t\t\tresult = resultReflexive;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tresult = result.replace(/и$/g, '');\n\tvar derivationalResult = result\n\tif (R2 && R2[2]) {\n\t\tderivationalResult = derivational(R2[2]);\n\t\tif (derivationalResult != null) {\n\t\t\tderivationalResult = derivational(result);\n\t\t} else {\n\t\t\tderivationalResult = result;\n\t\t}\n\t}\n\n\tvar superlativeResult = superlative(derivationalResult) || derivationalResult;\n\n\tsuperlativeResult = superlativeResult.replace(/(н)н/g, '$1');\n\tsuperlativeResult = superlativeResult.replace(/ь$/g, '');\n\treturn head + superlativeResult;\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/stemmer_ru.js":"/*\nCopyright (c) 2012, Polyakov Vladimir, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar stopwords = require('../util/stopwords_ru');\nvar Tokenizer = require('../tokenizers/aggressive_tokenizer_ru');\n\nmodule.exports = function() {\n    var stemmer = this;\n\n    stemmer.stem = function(token) {\n        return token;\n    };\n\n    stemmer.tokenizeAndStem = function(text, keepStops) {\n        var stemmedTokens = [];\n        \n        new Tokenizer().tokenize(text).forEach(function(token) {\n            if (keepStops || stopwords.words.indexOf(token) == -1) {\n                var resultToken = token.toLowerCase();\n                if (resultToken.match(new RegExp('[а-яё0-9]+', 'gi'))) {\n                    resultToken = stemmer.stem(resultToken);\n                }\n                stemmedTokens.push(resultToken);\n            }\n        });\n        \n        return stemmedTokens;\n    };\n\n    stemmer.attach = function() {\n        String.prototype.stem = function() {\n            return stemmer.stem(this);\n        };\n        \n        String.prototype.tokenizeAndStem = function(keepStops) {\n            return stemmer.tokenizeAndStem(this, keepStops);\n        };\n    };\n}\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/stopwords_ru.js":"/*\nCopyright (c) 2011, Polyakov Vladimir, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n// a list of commonly used words that have little meaning and can be excluded\n// from analysis.\nvar words = [\n    'о', 'после', 'все', 'также', 'и', 'другие', 'все', 'как', 'во', 'быть',\n    'потому', 'был', 'до', 'являюсь', 'между', 'все', 'но', 'от', 'иди', 'могу',\n    'подойди', 'мог', 'делал', 'делаю', 'каждый', 'для', 'откуда', 'иметь', 'имел',\n    'он', 'имеет', 'её', 'здесь', 'его', 'как', 'если', 'в', 'оно', 'за',\n    'делать', 'много', 'я', 'может быть', 'более', 'самый', 'должен',\n    'мой', 'никогда', 'сейчас', 'из', 'на', 'только', 'или', 'другой', 'другая',\n    'другое', 'наше', 'вне', 'конец', 'сказал', 'сказала', 'также', 'видел', 'c',\n    'немного', 'все еще', 'так', 'затем', 'тот', 'их', 'там', 'этот', 'они', 'те',\n    'через', 'тоже', 'под', 'над', 'очень', 'был', 'путь', 'мы', 'хорошо',\n    'что', 'где', 'который', 'пока', 'кто', 'с кем', 'хотел бы', 'ты', 'твои',\n    'а', 'б', 'в', 'г', 'д', 'е', 'ё', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н',\n    'o', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь',\n    'э', 'ю', 'я','$', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];\n    \n// tell the world about the noise words.    \nexports.words = words;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_ru.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Tokenizer = require('./tokenizer'),\n    util = require('util');\n\nvar AggressiveTokenizer = function() {\n    Tokenizer.call(this);    \n};\n\nutil.inherits(AggressiveTokenizer, Tokenizer);\n\nmodule.exports = AggressiveTokenizer;\n\nAggressiveTokenizer.prototype.withoutEmpty = function(array) {\n\treturn array.filter(function(a) {return a;});\n};\n\nAggressiveTokenizer.prototype.clearText = function(text) {\n\treturn text.replace(/[^a-zа-яё0-9]/gi, ' ').replace(/[\\s\\n]+/g, ' ').trim();\n};\n\nAggressiveTokenizer.prototype.tokenize = function(text) {\n    // break a string up into an array of tokens by anything non-word\n    return this.withoutEmpty(this.clearText(text).split(' '));\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/porter_stemmer_es.js":"/*\nCopyright (c) 2012, David Przybilla, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Stemmer = require('./stemmer_es');\n\nvar PorterStemmer = new Stemmer();\nmodule.exports = PorterStemmer;\n\n\nfunction isVowel(letter){\n\treturn (letter == 'a' || letter == 'e' || letter == 'i' || letter == 'o' || letter == 'u' || letter == 'á' || letter == 'é' ||\n\t\t\tletter == 'í' || letter == 'ó' || letter == 'ú');\n};\n\nfunction getNextVowelPos(token,start){\n\tlength=token.length\n\t\t\tfor (var i = start; i < length; i++)\n\t\t\t\tif (isVowel(token[i])) return i;\n\t\t\treturn length;\n};\n\nfunction getNextConsonantPos(token,start){\n\tlength=token.length\n\t\t\tfor (var i = start; i < length; i++)\n\t\t\t\tif (!isVowel(token[i])) return i;\n\t\t\treturn length;\n};\n\n\nfunction endsin(token, suffix) {\n\tif (token.length < suffix.length) return false;\n\treturn (token.slice(-suffix.length) == suffix);\n};\n\nfunction endsinArr(token, suffixes) {\n\tfor(var i=0;i<suffixes.length;i++){\n\t\tif (endsin(token, suffixes[i])) return suffixes[i];\n\t}\n\treturn '';\n};\n\nfunction removeAccent(token) {\n\tvar str=token.replace(/á/gi,'a');\n\tstr=str.replace(/é/gi,'e');\n\tstr=str.replace(/í/gi,'i');\n\tstr=str.replace(/ó/gi,'o');\n\tstr=str.replace(/ú/gi,'u');\n\treturn str;\n};\n\n// perform full stemming algorithm on a single word\nPorterStemmer.stem = function(token) {\n\ttoken = token.toLowerCase();\n\n\tif (token.length<3){\n\t\treturn token;\n\t}\n\n\tvar r1,r2,rv,len= token.length;\n\t//looking for regions after vowels\n\n\tfor(var i=0; i< token.length-1 && r1==len;i++){\n \t\tif(isVowel(token[i]) && !isVowel(token[i+1]) ){\n \t\t\tr1=i+2;\n \t\t}\n\n\t}\n\n\tfor(var i=r1; i< token.length-1 && r2==len;i++){\n\t\tif(isVowel(token[i]) && !isVowel(token[i+1])){\n\t\t\tr2=i+2;\n\t\t}\n\t}\n\n\tif (len > 3) {\n\t\t\tif(isVowel(token[1])) {\n\t\t\t\t// If the second letter is a consonant, RV is the region after the next following vowel\n\t\t\t\trv = getNextVowelPos(token, 2) +1;\n\t\t\t} else if (isVowel(token[0]) && isVowel(token[1])) {\n\t\t\t\t// or if the first two letters are vowels, RV is the region after the next consonant\n\t\t\t\trv = getNextConsonantPos(token, 2) + 1;\n\t\t\t} else {\n\t\t\t\t//otherwise (consonant-vowel case) RV is the region after the third letter. But RV is the end of the word if these positions cannot be found.\n\t\t\t\trv = 3;\n\t\t\t}\n\t\t}\n\n\tvar r1_txt = token.substring(r1-1);\n\tvar r2_txt = token.substring(r2-1);\n\tvar rv_txt = token.substring(rv-1);\n\n\n\tvar token_orig = token;\n\n\t// Step 0: Attached pronoun\n\tvar pronoun_suf = new Array('me', 'se', 'sela', 'selo', 'selas', 'selos', 'la', 'le', 'lo', 'las', 'les', 'los', 'nos');\n\tvar pronoun_suf_pre1 = new Array('éndo', 'ándo', 'ár', 'ér', 'ír');\n\tvar pronoun_suf_pre2 = new Array('ando', 'iendo', 'ar', 'er', 'ir');\n\tvar suf = endsinArr(token, pronoun_suf);\n\n\n\tif (suf!='') {\n\n\t\tvar pre_suff = endsinArr(rv_txt.slice(0,-suf.length),pronoun_suf_pre1);\n\n\t\tif (pre_suff != '') {\n\n\t\t\t\ttoken = removeAccent(token.slice(0,-suf.length));\n\t\t} else {\n\t\t\tvar pre_suff = endsinArr(rv_txt.slice(0,-suf.length),pronoun_suf_pre2);\n\n\t\t\tif (pre_suff != '' ||\n\t\t\t\t(endsin(token, 'yendo' ) &&\n\t\t\t\t(token.slice(-suf.length-6,1) == 'u'))) {\n\t\t\t\ttoken = token.slice(0,-suf.length);\n\t\t\t}\n\t\t}\n\t}\n\n\t\tif (token != token_orig) {\n\t\t\tr1_txt = token.substring(r1-1);\n\t\t\tr2_txt = token.substring(r2-1);\n\t\t\trv_txt = token.substring(rv-1);\n\t\t}\n\t\tvar token_after0 = token;\n\n\t\tif ((suf = endsinArr(r2_txt, new Array('anza', 'anzas', 'ico', 'ica', 'icos', 'icas', 'ismo', 'ismos', 'able', 'ables', 'ible', 'ibles', 'ista', 'istas', 'oso', 'osa', 'osos', 'osas', 'amiento', 'amientos', 'imiento', 'imientos'))) != '') {\n\t\t\ttoken = token.slice(0, -suf.length);\n\t\t} else if ((suf = endsinArr(r2_txt, new  Array('icadora', 'icador', 'icación', 'icadoras', 'icadores', 'icaciones', 'icante', 'icantes', 'icancia', 'icancias', 'adora', 'ador', 'ación', 'adoras', 'adores', 'aciones', 'ante', 'antes', 'ancia', 'ancias'))) != '') {\n\t\t\ttoken = token.slice(0,  -suf.length);\n\t\t} else if ((suf = endsinArr(r2_txt, new  Array('logía', 'logías'))) != '') {\n\t\t\ttoken = token.slice(0,  -suf.length)+ 'log';\n\t\t} else if ((suf =endsinArr(r2_txt, new  Array('ución', 'uciones'))) != '') {\n\t\t\ttoken = token.slice(0,  -suf.length) + 'u';\n\t\t} else if ((suf = endsinArr(r2_txt, new  Array('encia', 'encias'))) != '') {\n\t\t\ttoken = token.slice(0,  -suf.length)+ 'ente';\n\t\t} else if ((suf = endsinArr(r2_txt, new  Array('ativamente', 'ivamente', 'osamente', 'icamente', 'adamente'))) != '') {\n\t\t\ttoken = token.slice(0,  -suf.length);\n\t\t} else if ((suf = endsinArr(r1_txt, new  Array('amente'))) != '') {\n\t\t\ttoken = token.slice(0,  -suf.length);\n\t\t} else if ((suf = endsinArr(r2_txt, new  Array('antemente', 'ablemente', 'iblemente', 'mente'))) != '') {\n\t\t\ttoken = token.slice(0,  -suf.length);\n\t\t} else if ((suf = endsinArr(r2_txt, new  Array('abilidad', 'abilidades', 'icidad', 'icidades', 'ividad', 'ividades', 'idad', 'idades'))) != '') {\n\t\t\ttoken = token.slice(0,  -suf.length);\n\t\t} else if ((suf = endsinArr(r2_txt, new  Array('ativa', 'ativo', 'ativas', 'ativos', 'iva', 'ivo', 'ivas', 'ivos'))) != '') {\n\t\t\ttoken = token.slice(0,  -suf.length);\n\t\t}\n\n\t\tif (token != token_after0) {\n\t\t\tr1_txt = token.substring(r1-1);\n\t\t\tr2_txt = token.substring(r2-1);\n\t\t\trv_txt = token.substring(rv-1);\n\t\t}\n\t\tvar token_after1 = token;\n\n\t\tif (token_after0 == token_after1) {\n\t\t\t// Do step 2a if no ending was removed by step 1.\n\t\t\tif ((suf = endsinArr(rv_txt, new Array('ya', 'ye', 'yan', 'yen', 'yeron', 'yendo', 'yo', 'yó', 'yas', 'yes', 'yais', 'yamos'))) != '' && (token.substring(suf.length-1,1) == 'u')) {\n\t\t\t\ttoken = token.slice(0, -suf.length);\n\t\t\t}\n\n\t\t\tif (token != token_after1) {\n\t\t\t\tr1_txt = token.substring(r1-1);\n\t\t\t\tr2_txt = token.substring(r2-1);\n\t\t\t\trv_txt = token.substring(rv-1);\n\t\t\t}\n\t\t\tvar token_after2a = token;\n\n\t\t\t// Do Step 2b if step 2a was done, but failed to remove a suffix.\n\t\t\tif (token_after2a == token_after1) {\n\n\t\t\t\tif ((suf = endsinArr(rv_txt,new Array('en', 'es', 'éis', 'emos'))) != '') {\n\t\t\t\t\ttoken = token.slice(0,-suf.length);\n\t\t\t\t\tif (endsin(token, 'gu')) {\n\t\t\t\t\t\ttoken = token.slice(0,-1);\n\t\t\t\t\t}\n\t\t\t\t} else if ((suf = endsinArr(rv_txt, new Array('arían', 'arías', 'arán', 'arás', 'aríais', 'aría', 'aréis', 'aríamos', 'aremos', 'ará', 'aré', 'erían', 'erías', 'erán', 'erás', 'eríais', 'ería', 'eréis', 'eríamos', 'eremos', 'erá', 'eré', 'irían', 'irías', 'irán', 'irás', 'iríais', 'iría', 'iréis', 'iríamos', 'iremos', 'irá', 'iré', 'aba', 'ada', 'ida', 'ía', 'ara', 'iera', 'ad', 'ed', 'id', 'ase', 'iese', 'aste', 'iste', 'an', 'aban', 'ían', 'aran', 'ieran', 'asen', 'iesen', 'aron', 'ieron', 'ado', 'ido', 'ando', 'iendo', 'ió', 'ar', 'er', 'ir', 'as', 'abas', 'adas', 'idas', 'ías', 'aras', 'ieras', 'ases', 'ieses', 'ís', 'áis', 'abais', 'íais', 'arais', 'ierais', '  aseis', 'ieseis', 'asteis', 'isteis', 'ados', 'idos', 'amos', 'ábamos', 'íamos', 'imos', 'áramos', 'iéramos', 'iésemos', 'ásemos'))) != '') {\n\n\t\t\t\t\ttoken = token.slice(0, -suf.length);\n\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Always do step 3.\n\t\tr1_txt = token.substring(r1-1);\n\t\tr2_txt = token.substring(r2-1);\n\t\trv_txt = token.substring(rv-1);\n\n\t\tif ((suf = endsinArr(rv_txt, new Array('os', 'a', 'o', 'á', 'í', 'ó'))) != '') {\n\t\t\ttoken = token.slice(0, -suf.length);\n\t\t} else if ((suf = endsinArr(rv_txt ,new Array('e','é'))) != '') {\n\t\t\ttoken = token.slice(0,-1);\n\t\t\trv_txt = token.substring(rv-1);\n\t\t\tif (endsin(rv_txt,'u') && endsin(token,'gu')) {\n\t\t\t\ttoken = token.slice(0,-1);\n\t\t\t}\n\t\t}\n\n\t\treturn removeAccent(token);\n\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/stemmer_es.js":"/*\nCopyright (c) 2012, David Przybilla, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar stopwords = require('../util/stopwords_es');\nvar Tokenizer = require('../tokenizers/aggressive_tokenizer_es');\n\nmodule.exports = function() {\n    var stemmer = this;\n\n    stemmer.stem = function(token) {\n        return token;\n    };\n\n    stemmer.tokenizeAndStem = function(text, keepStops) {\n        var stemmedTokens = [];\n        \n        new Tokenizer().tokenize(text).forEach(function(token) {\n            if (keepStops || stopwords.words.indexOf(token) == -1) {\n                var resultToken = token.toLowerCase();\n                if (resultToken.match(new RegExp('[a-záéíóúüñ0-9]+', 'gi'))) {\n                    resultToken = stemmer.stem(resultToken);\n                }\n                stemmedTokens.push(resultToken);\n            }\n        });\n        \n        return stemmedTokens;\n    };\n\n    stemmer.attach = function() {\n        String.prototype.stem = function() {\n            return stemmer.stem(this);\n        };\n        \n        String.prototype.tokenizeAndStem = function(keepStops) {\n            return stemmer.tokenizeAndStem(this, keepStops);\n        };\n    };\n}\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/stopwords_es.js":"/*\nCopyright (c) 2011, David Przybilla, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n// a list of commonly used words that have little meaning and can be excluded\n// from analysis.\nvar words = [\n    'a','un','el','ella','y','sobre','de','la','que','en',\n    'los','del','se','las','por','un','para','con','no',\n    'una','su','al','lo','como','más','pero','sus','le',\n    'ya','o','porque','cuando','muy','sin','sobre','también',\n    'me','hasta','donde','quien','desde','nos','durante','uno',\n    'ni','contra','ese','eso','mí','qué','otro','él','cual',\n    'poco','mi','tú','te','ti','sí',\n     '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];\n    \n// tell the world about the noise words.    \nexports.words = words;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_es.js":"/*\nCopyright (c) 2011, Chris Umbel,David Przybilla\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Tokenizer = require('./tokenizer'),\n    util = require('util');\n\nvar AggressiveTokenizer = function() {\n    Tokenizer.call(this);    \n};\nutil.inherits(AggressiveTokenizer, Tokenizer);\n\nmodule.exports = AggressiveTokenizer;\n\nAggressiveTokenizer.prototype.tokenize = function(text) {\n    // break a string up into an array of tokens by anything non-word\n    return this.trim(text.split(/[^a-zA-Zá-úÁ-ÚñÑüÜ]+/));\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/porter_stemmer_it.js":"/*\r\nCopyright (c) 2012, Leonardo Fenu, Chris Umbel\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in\r\nall copies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\r\nTHE SOFTWARE.\r\n*/\r\n\r\nvar Stemmer = require('./stemmer_it');\r\n\r\nvar PorterStemmer = new Stemmer();\r\nmodule.exports = PorterStemmer;\r\n\r\n\r\nfunction isVowel(letter){\r\n\treturn (letter == 'a' || letter == 'e' || letter == 'i' || letter == 'o' || letter == 'u' || letter == 'à' ||\r\n\t\t\tletter == 'è' || letter == 'ì' || letter == 'ò' || letter == 'ù');\r\n};\r\n\r\nfunction getNextVowelPos(token,start){\r\n\tstart = start + 1;\r\n\tvar length = token.length;\r\n\tfor (var i = start; i < length; i++) {\r\n\t\tif (isVowel(token[i])) {\r\n\t\t\treturn i;\r\n\t\t}\r\n\t}\r\n\treturn length;\r\n};\r\n\r\nfunction getNextConsonantPos(token,start){\r\n\tlength=token.length\r\n\t\t\tfor (var i = start; i < length; i++)\r\n\t\t\t\tif (!isVowel(token[i])) return i;\r\n\t\t\treturn length;\r\n};\r\n\r\n\r\nfunction endsin(token, suffix) {\r\n\tif (token.length < suffix.length) return false;\r\n\treturn (token.slice(-suffix.length) == suffix);\r\n};\r\n\r\nfunction endsinArr(token, suffixes) {\r\n\tfor(var i=0;i<suffixes.length;i++){\r\n\t\tif (endsin(token, suffixes[i])) return suffixes[i];\r\n\t}\r\n\treturn '';\r\n};\r\n\r\nfunction replaceAcute(token) {\r\n\tvar str=token.replace(/á/gi,'à');\r\n\tstr=str.replace(/é/gi,'è');\r\n\tstr=str.replace(/í/gi,'ì');\r\n\tstr=str.replace(/ó/gi,'ò');\r\n\tstr=str.replace(/ú/gi,'ù');\r\n\treturn str;\r\n};\r\n\r\nfunction vowelMarking(token) {\r\n\tfunction replacer(match, p1, p2, p3){\r\n  \t\treturn p1+p2.toUpperCase()+p3;\r\n\t};\t\r\n\tstr=token.replace(/([aeiou])(i|u)([aeiou])/g, replacer);\t\r\n\treturn str;\r\n}\r\n\r\n\r\n// perform full stemming algorithm on a single word\r\nPorterStemmer.stem = function(token) {\r\n\t\r\n\ttoken = token.toLowerCase();\r\n\ttoken = replaceAcute(token);\r\n\ttoken = token.replace(/qu/g,'qU');\t\r\n\ttoken = vowelMarking(token);\r\n\t\r\n\tif (token.length<3){\r\n\t\treturn token;\r\n\t}\r\n\r\n\tvar r1 = r2 = rv = len = token.length;\r\n\t// R1 is the region after the first non-vowel following a vowel, \r\n\tfor(var i=0; i < token.length-1 && r1==len;i++){\r\n \t\tif(isVowel(token[i]) && !isVowel(token[i+1]) ){\r\n \t\t\tr1=i+2;\r\n \t\t}\r\n\t}\r\n\t// Or is the null region at the end of the word if there is no such non-vowel.  \r\n\r\n\t// R2 is the region after the first non-vowel following a vowel in R1\r\n\tfor(var i=r1; i< token.length-1 && r2==len;i++){\r\n\t\tif(isVowel(token[i]) && !isVowel(token[i+1])){\r\n\t\t\tr2=i+2;\r\n\t\t}\r\n\t}\r\n\r\n\t// Or is the null region at the end of the word if there is no such non-vowel. \r\n\r\n\t// If the second letter is a consonant, RV is the region after the next following vowel, \r\n\t\r\n\t// RV as follow\r\n\r\n\tif (len > 3) {\r\n\t\tif(!isVowel(token[1])) {\r\n\t\t\t// If the second letter is a consonant, RV is the region after the next following vowel\r\n\t\t\trv = getNextVowelPos(token, 1) +1;\r\n\t\t} else if (isVowel(token[0]) && isVowel(token[1])) { \r\n\t\t\t// or if the first two letters are vowels, RV is the region after the next consonant\r\n\t\t\trv = getNextConsonantPos(token, 2) + 1;\r\n\t\t} else {\r\n\t\t\t//otherwise (consonant-vowel case) RV is the region after the third letter. But RV is the end of the word if these positions cannot be found.\r\n\t\t\trv = 3;\r\n\t\t}\r\n\t}\r\n\r\n\tvar r1_txt = token.substring(r1);\r\n\tvar r2_txt = token.substring(r2);\r\n\tvar rv_txt = token.substring(rv);\r\n\r\n\tvar token_orig = token;\r\n\r\n\t// Step 0: Attached pronoun\r\n\r\n\tvar pronoun_suf = new Array('glieli','glielo','gliene','gliela','gliele','sene','tene','cela','cele','celi','celo','cene','vela','vele','veli','velo','vene','mela','mele','meli','melo','mene','tela','tele','teli','telo','gli','ci', 'la','le','li','lo','mi','ne','si','ti','vi');\t\r\n\tvar pronoun_suf_pre1 = new Array('ando','endo');\t\r\n\tvar pronoun_suf_pre2 = new Array('ar', 'er', 'ir');\r\n\tvar suf = endsinArr(token, pronoun_suf);\r\n\r\n\tif (suf!='') {\r\n\t\tvar pre_suff1 = endsinArr(rv_txt.slice(0,-suf.length),pronoun_suf_pre1);\r\n\t\tvar pre_suff2 = endsinArr(rv_txt.slice(0,-suf.length),pronoun_suf_pre2);\t\r\n\t\t\r\n\t\tif (pre_suff1 != '') {\r\n\t\t\ttoken = token.slice(0,-suf.length);\r\n\t\t}\r\n\t\tif (pre_suff2 != '') {\r\n\t\t\ttoken = token.slice(0,  -suf.length)+ 'e';\r\n\t\t}\r\n\t}\r\n\r\n\tif (token != token_orig) {\r\n\t\tr1_txt = token.substring(r1);\r\n\t\tr2_txt = token.substring(r2);\r\n\t\trv_txt = token.substring(rv);\r\n\t}\r\n\r\n\tvar token_after0 = token;\r\n\r\n\t// Step 1:  Standard suffix removal\r\n\t\r\n\tif ((suf = endsinArr(r2_txt, new  Array('ativamente','abilamente','ivamente','osamente','icamente'))) != '') {\r\n\t\ttoken = token.slice(0, -suf.length);\t// delete\r\n\t} else if ((suf = endsinArr(r2_txt, new  Array('icazione','icazioni','icatore','icatori','azione','azioni','atore','atori'))) != '') {\r\n\t\ttoken = token.slice(0,  -suf.length);\t// delete\r\n\t} else if ((suf = endsinArr(r2_txt, new  Array('logia','logie'))) != '') {\r\n\t\ttoken = token.slice(0,  -suf.length)+ 'log'; // replace with log\r\n\t} else if ((suf =endsinArr(r2_txt, new  Array('uzione','uzioni','usione','usioni'))) != '') {\r\n\t\ttoken = token.slice(0,  -suf.length) + 'u'; // replace with u\r\n\t} else if ((suf = endsinArr(r2_txt, new  Array('enza','enze'))) != '') {\r\n\t\ttoken = token.slice(0,  -suf.length)+ 'ente'; // replace with ente\r\n\t} else if ((suf = endsinArr(rv_txt, new  Array('amento', 'amenti', 'imento', 'imenti'))) != '') {\r\n\t\ttoken = token.slice(0,  -suf.length);\t// delete\r\n\t} else if ((suf = endsinArr(r1_txt, new  Array('amente'))) != '') {\r\n\t\ttoken = token.slice(0,  -suf.length); // delete\r\n\t} else if ((suf = endsinArr(r2_txt, new Array('atrice','atrici','abile','abili','ibile','ibili','mente','ante','anti','anza','anze','iche','ichi','ismo','ismi','ista','iste','isti','istà','istè','istì','ico','ici','ica','ice','oso','osi','osa','ose'))) != '') {\r\n\t\ttoken = token.slice(0,  -suf.length); // delete\r\n\t} else if ((suf = endsinArr(r2_txt, new  Array('abilità', 'icità', 'ività', 'ità'))) != '') {\r\n\t\ttoken = token.slice(0,  -suf.length); // delete\r\n\t} else if ((suf = endsinArr(r2_txt, new  Array('icativa','icativo','icativi','icative','ativa','ativo','ativi','ative','iva','ivo','ivi','ive'))) != '') {\r\n\t\ttoken = token.slice(0,  -suf.length);\r\n\t}\r\n\t\r\n\t\r\n\tif (token != token_after0) {\r\n\t\tr1_txt = token.substring(r1);\r\n\t\tr2_txt = token.substring(r2);\r\n\t\trv_txt = token.substring(rv);\r\n\t}\r\n\t\r\n\r\n\tvar token_after1 = token;\r\n\t\r\n\t// Step 2:  Verb suffixes\r\n\r\n\tif (token_after0 == token_after1) {\r\n\t\tif ((suf = endsinArr(rv_txt, new Array('erebbero','irebbero','assero','assimo','eranno','erebbe','eremmo','ereste','eresti','essero','iranno','irebbe','iremmo','ireste','iresti','iscano','iscono','issero','arono','avamo','avano','avate','eremo','erete','erono','evamo','evano','evate','iremo','irete','irono','ivamo','ivano','ivate','ammo','ando','asse','assi','emmo','enda','ende','endi','endo','erai','Yamo','iamo','immo','irai','irei','isca','isce','isci','isco','erei','uti','uto','ita','ite','iti','ito','iva','ivi','ivo','ono','uta','ute','ano','are','ata','ate','ati','ato','ava','avi','avo','erà','ere','erò','ete','eva','evi','evo','irà','ire','irò','ar','ir'))) != '') {\r\n\t\t\ttoken = token.slice(0, -suf.length);\r\n\t\t}\r\n\t}\r\n\r\n\t\r\n\tr1_txt = token.substring(r1);\r\n\tr2_txt = token.substring(r2);\r\n\trv_txt = token.substring(rv);\r\n\r\n\t// Always do step 3. \r\n\r\n\tif ((suf = endsinArr(rv_txt, new Array('ia', 'ie', 'ii', 'io', 'ià', 'iè','iì', 'iò','a','e','i','o','à','è','ì','ò'))) != '') {\r\n\t\ttoken = token.slice(0, -suf.length);\r\n\t} \r\n\r\n\tr1_txt = token.substring(r1);\r\n\tr2_txt = token.substring(r2);\r\n\trv_txt = token.substring(rv);\r\n\t\r\n\tif ((suf =endsinArr(rv_txt, new  Array('ch'))) != '') {\r\n\t\ttoken = token.slice(0,  -suf.length) + 'c'; // replace with c\r\n\t} else if ((suf =endsinArr(rv_txt, new  Array('gh'))) != '') {\r\n\t\ttoken = token.slice(0,  -suf.length) + 'g'; // replace with g\r\n\t}\r\n\r\n\t\r\n\tr1_txt = token.substring(r1);\r\n\tr2_txt = token.substring(r2);\r\n\trv_txt = token.substring(rv);\r\n\r\n\treturn token.toLowerCase();\r\n\r\n};","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/stemmer_it.js":"var stopwords = require('../util/stopwords_it');\r\nvar Tokenizer = require('../tokenizers/aggressive_tokenizer_it');\r\n\r\nmodule.exports = function() {\r\n    var stemmer = this;\r\n\r\n    stemmer.stem = function(token) {\r\n        return token;\r\n    };\r\n\r\n    stemmer.tokenizeAndStem = function(text, keepStops) {\r\n        var stemmedTokens = [];\r\n        \r\n        new Tokenizer().tokenize(text).forEach(function(token) {\r\n            if (keepStops || stopwords.words.indexOf(token) == -1) {\r\n                var resultToken = token.toLowerCase();\r\n                if (resultToken.match(/[a-zàèìòù0-9]/gi)) {\r\n                    resultToken = stemmer.stem(resultToken);\r\n                }\r\n                stemmedTokens.push(resultToken);\r\n            }\r\n        });\r\n        \r\n        return stemmedTokens;\r\n    };\r\n\r\n    stemmer.attach = function() {\r\n        String.prototype.stem = function() {\r\n            return stemmer.stem(this);\r\n        };\r\n        \r\n        String.prototype.tokenizeAndStem = function(keepStops) {\r\n            return stemmer.tokenizeAndStem(this, keepStops);\r\n        };\r\n    };\r\n}","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/stopwords_it.js":"/*\r\nCopyright (c) 2011, David Przybilla, Chris Umbel\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in\r\nall copies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\r\nTHE SOFTWARE.\r\n*/\r\n\r\n// a list of commonly used words that have little meaning and can be excluded\r\n// from analysis.\r\nvar words = [\r\n    'ad','al','allo','ai','agli','all','agl','alla','alle','con','col','coi','da','dal','dallo',\r\n    'dai','dagli','dall','dagl','dalla','dalle','di','del','dello','dei','degli','dell','degl',\r\n    'della','delle','in','nel','nello','nei','negli','nell','negl','nella','nelle','su','sul',\r\n    'sullo','sui','sugli','sull','sugl','sulla','sulle','per','tra','contro','io','tu','lui',\r\n    'lei','noi','voi','loro','mio','mia','miei','mie','tuo','tua','tuoi','tue','suo','sua','suoi',\r\n    'sue','nostro','nostra','nostri','nostre','vostro','vostra','vostri','vostre','mi','ti','ci',\r\n    'vi','lo','la','li','le','gli','ne','il','un','uno','una','ma','ed','se','perché','anche','come',\r\n    'dov','dove','che','chi','cui','non','più','quale','quanto','quanti','quanta','quante','quello',\r\n    'quelli','quella','quelle','questo','questi','questa','queste','si','tutto','tutti','a','c','e',\r\n    'i','l','o','ho','hai','ha','abbiamo','avete','hanno','abbia','abbiate','abbiano','avrò','avrai',\r\n    'avrà','avremo','avrete','avranno','avrei','avresti','avrebbe','avremmo','avreste','avrebbero',\r\n    'avevo','avevi','aveva','avevamo','avevate','avevano','ebbi','avesti','ebbe','avemmo','aveste',\r\n    'ebbero','avessi','avesse','avessimo','avessero','avendo','avuto','avuta','avuti','avute','sono',\r\n    'sei','è','siamo','siete','sia','siate','siano','sarò','sarai','sarà','saremo','sarete','saranno',\r\n    'sarei','saresti','sarebbe','saremmo','sareste','sarebbero','ero','eri','era','eravamo','eravate',\r\n    'erano','fui','fosti','fu','fummo','foste','furono','fossi','fosse','fossimo','fossero','essendo',\r\n    'faccio','fai','facciamo','fanno','faccia','facciate','facciano','farò','farai','farà','faremo',\r\n    'farete','faranno','farei','faresti','farebbe','faremmo','fareste','farebbero','facevo','facevi',\r\n    'faceva','facevamo','facevate','facevano','feci','facesti','fece','facemmo','faceste','fecero',\r\n    'facessi','facesse','facessimo','facessero','facendo','sto','stai','sta','stiamo','stanno','stia',\r\n    'stiate','stiano','starò','starai','starà','staremo','starete','staranno','starei','staresti',\r\n    'starebbe','staremmo','stareste','starebbero','stavo','stavi','stava','stavamo','stavate','stavano',\r\n    'stetti','stesti','stette','stemmo','steste','stettero','stessi','stesse','stessimo','stessero','stando',\r\n     '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];\r\n    \r\n// tell the world about the noise words.    \r\nexports.words = words;\r\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_it.js":"/*\r\nCopyright (c) 2011, Chris Umbel,David Przybilla\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in\r\nall copies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\r\nTHE SOFTWARE.\r\n*/\r\n\r\nvar Tokenizer = require('./tokenizer'),\r\n    util = require('util');\r\n\r\nvar AggressiveTokenizer = function() {\r\n    Tokenizer.call(this);    \r\n};\r\nutil.inherits(AggressiveTokenizer, Tokenizer);\r\n\r\nmodule.exports = AggressiveTokenizer;\r\n\r\nAggressiveTokenizer.prototype.tokenize = function(text) {\r\n    // break a string up into an array of tokens by anything non-word\r\n    return this.trim(text.split(/\\W+/));\r\n};\r\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/porter_stemmer_no.js":"/*\nCopyright (c) 2014, Kristoffer Brabrand\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Stemmer = require('./stemmer_no');\n\n// Get the part of the token after the first non-vowel following a vowel\nfunction getR1(token) {\n    var match = token.match(/[aeiouyæåø]{1}[^aeiouyæåø]([A-Za-z0-9_æøåÆØÅäÄöÖüÜ]+)/);\n\n    if (match) {\n        var preR1Length = match.index + 2;\n\n        if (preR1Length < 3 && preR1Length > 0) {\n            return token.slice(3);\n        } else if (preR1Length >= 3) {\n            return match[1];\n        } else {\n            return token;\n        }\n    }\n\n    return null;\n}\n\nfunction step1(token) {\n    // Perform step 1a-c\n    var step1aResult = step1a(token),\n        step1bResult = step1b(token),\n        step1cResult = step1c(token);\n\n    // Returne the shortest result string (from 1a, 1b and 1c)\n    if (step1aResult.length < step1bResult.length) {\n        return (step1aResult.length < step1cResult.length) ? step1aResult : step1cResult;\n    } else {\n        return (step1bResult.length < step1cResult.length) ? step1bResult : step1cResult;\n    }\n}\n\n// step 1a as defined for the porter stemmer algorithm.\nfunction step1a(token) {\n    var r1 = getR1(token);\n\n    if (!r1) {\n        return token;\n    }\n\n    var r1Match = r1.match(/(a|e|ede|ande|ende|ane|ene|hetene|en|heten|ar|er|heter|as|es|edes|endes|enes|hetenes|ens|hetens|ers|ets|et|het|ast)$/);\n\n    if (r1Match) {\n        return token.replace(new RegExp(r1Match[1] + '$'), '');\n    }\n\n    return token;\n}\n\n// step 1b as defined for the porter stemmer algorithm.\nfunction step1b(token) {\n    var r1 = getR1(token);\n\n    if (!r1) {\n        return token;\n    }\n\n    if (token.match(/(b|c|d|f|g|h|j|l|m|n|o|p|r|t|v|y|z)s$/)) {\n        return token.slice(0, -1);\n    }\n\n    if (token.match(/([^aeiouyæåø]k)s$/)) {\n        return token.slice(0, -1);\n    }\n\n    return token;\n}\n\n// step 1c as defined for the porter stemmer algorithm.\nfunction step1c(token) {\n    var r1 = getR1(token);\n\n    if (!r1) {\n        return token;\n    }\n\n    if (r1.match(/(erte|ert)$/)) {\n        return token.replace(/(erte|ert)$/, 'er');\n    }\n\n    return token;\n}\n\n// step 2 as defined for the porter stemmer algorithm.\nfunction step2(token) {\n    var r1 = getR1(token);\n\n    if (!r1) {\n        return token;\n    }\n\n    if (r1.match(/(d|v)t$/)) {\n        return token.slice(0, -1);\n    }\n\n    return token;\n}\n\n// step 3 as defined for the porter stemmer algorithm.\nfunction step3(token) {\n    var r1 = getR1(token);\n\n    if (!r1)\n        return token;\n\n    var r1Match = r1.match(/(leg|eleg|ig|eig|lig|elig|els|lov|elov|slov|hetslov)$/);\n\n    if (r1Match) {\n        return token.replace(new RegExp(r1Match[1] + '$'), '');\n    }\n\n    return token;\n}\n\nvar PorterStemmer = new Stemmer();\nmodule.exports = PorterStemmer;\n\n// perform full stemming algorithm on a single word\nPorterStemmer.stem = function(token) {\n    return step3(step2(step1(token.toLowerCase()))).toString();\n};\n\n//exports for tests\nPorterStemmer.getR1  = getR1;\nPorterStemmer.step1  = step1;\nPorterStemmer.step1a = step1a;\nPorterStemmer.step1b = step1b;\nPorterStemmer.step1c = step1c;\nPorterStemmer.step2  = step2;\nPorterStemmer.step3  = step3;","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/stemmer_no.js":"/*\nCopyright (c) 2014, Kristoffer Brabrand\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar stopwords = require('../util/stopwords_no');\nvar Tokenizer = require('../tokenizers/aggressive_tokenizer_no');\n\nmodule.exports = function() {\n    var stemmer = this;\n\n    stemmer.stem = function(token) {\n        return token;\n    };\n\n    stemmer.addStopWord = function(stopWord) {\n        stopwords.words.push(stopWord);\n    };\n\n    stemmer.addStopWords = function(moreStopWords) {\n        stopwords.words = stopwords.words.concat(moreStopWords);\n    };\n\n    stemmer.tokenizeAndStem = function(text, keepStops) {\n        var stemmedTokens = [];\n\n        new Tokenizer().tokenize(text).forEach(function(token) {\n            if(keepStops || stopwords.words.indexOf(token.toLowerCase()) == -1)\n                stemmedTokens.push(stemmer.stem(token));\n        });\n\n        return stemmedTokens;\n    };\n\n    stemmer.attach = function() {\n        String.prototype.stem = function() {\n            return stemmer.stem(this);\n        };\n\n        String.prototype.tokenizeAndStem = function(keepStops) {\n            return stemmer.tokenizeAndStem(this, keepStops);\n        };\n    };\n}\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/stopwords_no.js":"/*\nCopyright (c) 2014, Kristoffer Brabrand\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n// a list of commonly used words that have little meaning and can be excluded\n// from analysis.\nvar words = [\n    'og','i','jeg','det','at','en','et','den','til','er','som',\n    'på','de','med','han','av','ikke','der','så','var','meg',\n    'seg','men','ett','har','om','vi','min','mitt','ha','hadde',\n    'hun','nå','over','da','ved','fra','du','ut','sin','dem',\n    'oss','opp','man','kan','hans','hvor','eller','hva','skal',\n    'selv','sjøl','her','alle','vil','bli','ble','blitt','kunne',\n    'inn','når','være','kom','noen','noe','ville','dere','som',\n    'deres','kun','ja','etter','ned','skulle','denne','for','deg',\n    'si','sine','sitt','mot','å','meget','hvorfor','dette','disse',\n    'uten','hvordan','ingen','din','ditt','blir','samme','hvilken',\n    'hvilke','sånn','inni','mellom','vår','hver','hvem','vors',\n    'hvis','både','bare','enn','fordi','før','mange','også','slik',\n    'vært','være','begge','siden','henne','hennar','hennes',\n    '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];\n\n// tell the world about the noise words.\nexports.words = words;","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_no.js":"/*\nCopyright (c) 2014, Kristoffer Brabrand\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Tokenizer = require('./tokenizer'),\n    normalizer = require('../normalizers/normalizer_no'),\n    util = require('util');\n\nvar AggressiveTokenizer = function() {\n    Tokenizer.call(this);\n};\nutil.inherits(AggressiveTokenizer, Tokenizer);\n\nmodule.exports = AggressiveTokenizer;\n\nAggressiveTokenizer.prototype.tokenize = function(text) {\n    text = normalizer.remove_diacritics(text);\n\n    // break a string up into an array of tokens by anything non-word\n    return this.trim(text.split(/[^A-Za-z0-9_æøåÆØÅäÄöÖüÜ]+/));\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/normalizers/normalizer_no.js":"/*\n Copyright (c) 2014, Kristoffer Brabrand\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n\n/**\n * Remove commonly used diacritic marks from a string as these\n * are not used in a consistent manner. Leave only ä, ö, ü.\n */\nvar remove_diacritics = function(text) {\n    text = text.replace('à', 'a');\n    text = text.replace('À', 'A');\n    text = text.replace('á', 'a');\n    text = text.replace('Á', 'A');\n    text = text.replace('â', 'a');\n    text = text.replace('Â', 'A');\n    text = text.replace('ç', 'c');\n    text = text.replace('Ç', 'C');\n    text = text.replace('è', 'e');\n    text = text.replace('È', 'E');\n    text = text.replace('é', 'e');\n    text = text.replace('É', 'E');\n    text = text.replace('ê', 'e');\n    text = text.replace('Ê', 'E');\n    text = text.replace('î', 'i');\n    text = text.replace('Î', 'I');\n    text = text.replace('ñ', 'n');\n    text = text.replace('Ñ', 'N');\n    text = text.replace('ó', 'o');\n    text = text.replace('Ó', 'O');\n    text = text.replace('ô', 'o');\n    text = text.replace('Ô', 'O');\n    text = text.replace('û', 'u');\n    text = text.replace('Û', 'U');\n    text = text.replace('š', 's');\n    text = text.replace('Š', 'S');\n\n    return text;\n};\n\n// export the relevant stuff.\nexports.remove_diacritics = remove_diacritics;","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/porter_stemmer_pt.js":"/*\nCopyright (c) 2015, Luís Rodrigues\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nmodule.exports = (function () {\n  'use strict';\n\n  var Stemmer     = require('./stemmer_pt'),\n    Token         = require('./token'),\n    PorterStemmer = new Stemmer();\n\n  /**\n   * Marks a region after the first non-vowel following a vowel, or the\n   * null region at the end of the word if there is no such non-vowel.\n   *\n   * @param {Object} token Token to stem.\n   * @param {Number} start Start index (defaults to 0).\n   * @param {Number}       Region start index.\n   */\n   var markRegionN = function (start) {\n    var index = start || 0,\n      length = this.string.length,\n      region = length;\n\n    while (index < length - 1 && region === length) {\n      if (this.hasVowelAtIndex(index) && !this.hasVowelAtIndex(index + 1)) {\n        region = index + 2;\n      }\n      index++;\n    }\n\n    return region;\n  };\n\n  /**\n   * Mark RV.\n   *\n   * @param  {Object} token Token to stem.\n   * @return {Number}       Region start index.\n   */\n  var markRegionV = function () {\n    var rv = this.string.length;\n\n    if (rv > 3) {\n      if (!this.hasVowelAtIndex(1)) {\n        rv = this.nextVowelIndex(2) + 1;\n\n      } else if (this.hasVowelAtIndex(0) && this.hasVowelAtIndex(1)) {\n        rv = this.nextConsonantIndex(2) + 1;\n\n      } else {\n        rv = 3;\n      }\n    }\n\n    return rv;\n  };\n\n  /**\n   * Prelude.\n   *\n   * Nasalised vowel forms should be treated as a vowel followed by a consonant.\n   *\n   * @param  {String} token Word to stem.\n   * @return {String}       Stemmed token.\n   */\n  function prelude (token) {\n    return token\n    .replaceAll('ã', 'a~')\n    .replaceAll('õ', 'o~');\n  }\n\n  /**\n   * Step 1: Standard suffix removal.\n   *\n   * This step should always be performed.\n   *\n   * @param  {Token} token Word to stem.\n   * @return {Token}       Stemmed token.\n   */\n  function standardSuffix (token) {\n\n    token.replaceSuffixInRegion([\n      'amentos', 'imentos', 'aço~es', 'adoras', 'adores', 'amento', 'imento',\n\n      'aça~o', 'adora', 'ância', 'antes', 'ismos', 'istas',\n\n      'ador', 'ante', 'ável', 'ezas', 'icas', 'icos', 'ismo', 'ista', 'ível',\n      'osas', 'osos',\n\n      'eza', 'ica', 'ico', 'osa', 'oso'\n\n      ], '', 'r2');\n\n    token.replaceSuffixInRegion(['logias', 'logia'], 'log', 'r2');\n\n    // token.replaceSuffixInRegion(['uço~es', 'uça~o'], 'u', 'r1');\n\n    token.replaceSuffixInRegion(['ências', 'ência'], 'ente', 'r2');\n\n    token.replaceSuffixInRegion([\n      'ativamente', 'icamente', 'ivamente', 'osamente', 'adamente'\n    ], '', 'r2');\n\n    token.replaceSuffixInRegion('amente', '', 'r1');\n\n    token.replaceSuffixInRegion([\n      'antemente', 'avelmente', 'ivelmente', 'mente'\n    ], '', 'r2');\n\n    token.replaceSuffixInRegion([\n      'abilidades', 'abilidade',\n      'icidades', 'icidade',\n      'ividades', 'ividade',\n      'idades', 'idade'\n    ], '', 'r2');\n\n    token.replaceSuffixInRegion([\n      'ativas', 'ativos', 'ativa', 'ativo',\n      'ivas', 'ivos', 'iva', 'ivo'\n    ], '', 'r2');\n\n    if (token.hasSuffix('eiras') || token.hasSuffix('eira')) {\n      token.replaceSuffixInRegion(['iras', 'ira'], 'ir', 'rv');\n    }\n\n    return token;\n  }\n\n  /**\n   * Step 2: Verb suffix removal.\n   *\n   * Perform this step if no ending was removed in step 1.\n   *\n   * @param  {Token} token   Token to stem.\n   * @return {Token}         Stemmed token.\n   */\n  function verbSuffix (token) {\n\n    token.replaceSuffixInRegion([\n      'aríamos', 'ássemos', 'eríamos', 'êssemos', 'iríamos', 'íssemos',\n\n      'áramos', 'aremos', 'aríeis', 'ásseis', 'ávamos', 'éramos', 'eremos',\n      'eríeis', 'ésseis', 'íramos', 'iremos', 'iríeis', 'ísseis',\n\n      'ara~o', 'ardes', 'areis', 'áreis', 'ariam', 'arias', 'armos', 'assem',\n      'asses', 'astes', 'áveis', 'era~o', 'erdes', 'ereis', 'éreis', 'eriam',\n      'erias', 'ermos', 'essem', 'esses', 'estes', 'íamos', 'ira~o', 'irdes',\n      'ireis', 'íreis', 'iriam', 'irias', 'irmos', 'issem', 'isses', 'istes',\n\n      'adas', 'ados', 'amos', 'ámos', 'ando', 'aram', 'aras', 'arás', 'arei',\n      'arem', 'ares', 'aria', 'asse', 'aste', 'avam', 'avas', 'emos', 'endo',\n      'eram', 'eras', 'erás', 'erei', 'erem', 'eres', 'eria', 'esse', 'este',\n      'idas', 'idos', 'íeis', 'imos', 'indo', 'iram', 'iras', 'irás', 'irei',\n      'irem', 'ires', 'iria', 'isse', 'iste',\n\n      'ada', 'ado', 'ais', 'ara', 'ará', 'ava', 'eis', 'era', 'erá', 'iam',\n      'ias', 'ida', 'ido', 'ira', 'irá',\n\n      'am', 'ar', 'as', 'ei', 'em', 'er', 'es', 'eu', 'ia', 'ir', 'is', 'iu', 'ou'\n\n    ], '', 'rv');\n\n    return token;\n  }\n\n  /**\n   * Step 3: Delete suffix i.\n   *\n   * Perform this step if the word was changed, in RV and preceded by c.\n   *\n   * @param  {Token} token   Token to stem.\n   * @return {Token}         Stemmed token.\n   */\n  function iPrecededByCSuffix (token) {\n\n    if (token.hasSuffix('ci')) {\n      token.replaceSuffixInRegion('i', '', 'rv');\n    }\n\n    return token;\n  }\n\n  /**\n   * Step 4: Residual suffix.\n   *\n   * Perform this step if steps 1 and 2 did not alter the word.\n   *\n   * @param  {Token} token Token to stem.\n   * @return {Token}       Stemmed token.\n   */\n  function residualSuffix (token) {\n\n    token.replaceSuffixInRegion(['os', 'a', 'i', 'o', 'á', 'í', 'ó'], '', 'rv');\n\n    return token;\n  }\n\n  /**\n   * Step 5: Residual form.\n   *\n   * This step should always be performed.\n   *\n   * @param  {Token} token Token to stem.\n   * @return {Token}       Stemmed token.\n   */\n  function residualForm (token) {\n\n    var tokenString = token.string;\n\n    if (token.hasSuffix('gue') || token.hasSuffix('gué') || token.hasSuffix('guê')) {\n      token.replaceSuffixInRegion(['ue', 'ué', 'uê'], '', 'rv');\n    }\n\n    if (token.hasSuffix('cie') || token.hasSuffix('cié') || token.hasSuffix('ciê')) {\n      token.replaceSuffixInRegion(['ie', 'ié', 'iê'], '', 'rv');\n    }\n\n    if (tokenString === token.string) {\n      token.replaceSuffixInRegion(['e', 'é', 'ê'], '', 'rv');\n    }\n\n    token.replaceSuffixInRegion('ç', 'c', 'all');\n\n    return token;\n  }\n\n  /**\n   * Postlude.\n   *\n   * Turns a~, o~ back into ã, õ.\n   *\n   * @param  {String} token Word to stem.\n   * @return {String}       Stemmed token.\n   */\n  function postlude (token) {\n    return token\n      .replaceAll('a~', 'ã')\n      .replaceAll('o~', 'õ');\n  }\n\n  /**\n   * Stems a word using a Porter stemmer algorithm.\n   *\n   * @param  {String} word Word to stem.\n   * @return {String}      Stemmed token.\n   */\n  PorterStemmer.stem = function (word) {\n    var token = new Token(word.toLowerCase()),\n      original;\n\n    token = prelude(token);\n\n    token.usingVowels('aeiouáéíóúâêôàãõ')\n      .markRegion('all', 0)\n      .markRegion('r1', null, markRegionN)\n      .markRegion('r2', token.regions.r1, markRegionN)\n      .markRegion('rv', null, markRegionV);\n\n    original = token.string;\n\n    // Always do step 1.\n    token = standardSuffix(token);\n\n    // Do step 2 if no ending was removed by step 1.\n    if (token.string === original) {\n      token = verbSuffix(token);\n    }\n\n    // If the last step to be obeyed — either step 1 or 2 — altered the word,\n    // do step 3. Alternatively, if neither steps 1 nor 2 altered the word, do\n    // step 4.\n    token = token.string !== original ? iPrecededByCSuffix(token) : residualSuffix(token);\n\n    // Always do step 5.\n    token = residualForm(token);\n\n    token = postlude(token);\n\n    return token.string;\n  };\n\n  return PorterStemmer;\n})();\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/stemmer_pt.js":"/*\nCopyright (c) 2014, Ismaël Héry\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nmodule.exports = function () {\n  'use strict';\n\n  var Stemmer = this,\n    stopwords = require('../util/stopwords_pt'),\n    Tokenizer = require('../tokenizers/aggressive_tokenizer_pt');\n\n  Stemmer.stem = function (token) {\n    return token;\n  };\n\n  Stemmer.addStopWords = function (word) {\n    stopwords.words.push(word);\n  };\n\n  Stemmer.addStopWords = function (words) {\n    stopwords.words = stopwords.words.concat(words);\n  };\n\n  Stemmer.tokenizeAndStem = function(text, keepStops) {\n    var stemmedTokens = [];\n\n    var tokenStemmer = function (token) {\n      if (keepStops || stopwords.words.indexOf(token.toLowerCase()) === -1) {\n        stemmedTokens.push(Stemmer.stem(token));\n      }\n    };\n\n    new Tokenizer().tokenize(text).forEach(tokenStemmer);\n\n    return stemmedTokens;\n  };\n\n  Stemmer.attach = function () {\n    String.prototype.stem = function () {\n      return Stemmer.stem(this);\n    };\n\n    String.prototype.tokenizeAndStem = function (keepStops) {\n      return Stemmer.tokenizeAndStem(this, keepStops);\n    };\n  };\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/token.js":"/*\nCopyright (c) 2015, Luís Rodrigues\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nmodule.exports = (function () {\n  'use strict';\n\n  /**\n   * Stemmer token constructor.\n   *\n   * @param {String} string Token string.\n   */\n  var Token = function (string) {\n    this.vowels   = '';\n    this.regions  = {};\n    this.string   = string;\n    this.original = string;\n  }\n\n  /**\n   * Set vowels.\n   *\n   * @param  {String|Array} vowels List of vowels.\n   * @return {Token}               Token instance.\n   */\n  Token.prototype.usingVowels = function (vowels) {\n    this.vowels = vowels;\n    return this;\n  };\n\n  /**\n   * Marks a region by defining its starting index or providing a callback\n   * function that does.\n   *\n   * @param  {String}       region   Region name.\n   * @param  {Array|Number} args     Callback arguments or region start index.\n   * @param  {Function}     callback Function that determines the start index (optional).\n   * @param  {Object}       context  Callback context (optional, defaults to this).\n   * @return {Token}                 Token instance.\n   */\n  Token.prototype.markRegion = function (region, args, callback, context) {\n    if (typeof callback === 'function') {\n      this.regions[region] = callback.apply(context || this, [].concat(args));\n\n    } else if (!isNaN(args)) {\n      this.regions[region] = args;\n    }\n\n    return this;\n  };\n\n  /**\n   * Replaces all instances of a string with another.\n   *\n   * @param  {String} find    String to be replaced.\n   * @param  {String} replace Replacement string.\n   * @return {Token}          Token instance.\n   */\n  Token.prototype.replaceAll = function (find, replace) {\n    this.string = this.string.split(find).join(replace);\n    return this;\n  };\n\n  /**\n   * Replaces the token suffix if in a region.\n   *\n   * @param  {String} suffix  Suffix to replace.\n   * @param  {String} replace Replacement string.\n   * @param  {String} region  Region name.\n   * @return {Token}          Token instance.\n   */\n  Token.prototype.replaceSuffixInRegion = function (suffix, replace, region) {\n    var suffixes = [].concat(suffix);\n    for (var i = 0; i < suffixes.length; i++) {\n      if (this.hasSuffixInRegion(suffixes[i], region)) {\n        this.string = this.string.slice(0, -suffixes[i].length) + replace;\n        return this;\n      }\n    }\n    return this;\n  };\n\n  /**\n   * Determines whether the token has a vowel at the provided index.\n   *\n   * @param  {Integer} index Character index.\n   * @return {Boolean}       Whether the token has a vowel at the provided index.\n   */\n  Token.prototype.hasVowelAtIndex = function (index) {\n    return this.vowels.indexOf(this.string[index]) !== -1;\n  };\n\n  /**\n   * Finds the next vowel in the token.\n   *\n   * @param  {Integer} start Starting index offset.\n   * @return {Integer}       Vowel index, or the end of the string.\n   */\n  Token.prototype.nextVowelIndex = function (start) {\n    var index = (start >= 0 && start < this.string.length) ? start : this.string.length;\n    while (index < this.string.length && !this.hasVowelAtIndex(index)) {\n      index++;\n    }\n    return index;\n  };\n\n  /**\n   * Finds the next consonant in the token.\n   *\n   * @param  {Integer} start Starting index offset.\n   * @return {Integer}       Consonant index, or the end of the string.\n   */\n  Token.prototype.nextConsonantIndex = function (start) {\n    var index = (start >= 0 && start < this.string.length) ? start : this.string.length;\n    while (index < this.string.length && this.hasVowelAtIndex(index)) {\n      index++;\n    }\n    return index;\n  };\n\n  /**\n   * Determines whether the token has the provided suffix.\n   * @param  {String}  suffix Suffix to match.\n   * @return {Boolean}        Whether the token string ends in suffix.\n   */\n  Token.prototype.hasSuffix = function (suffix) {\n    return this.string.slice(-suffix.length) === suffix;\n  };\n\n  /**\n   * Determines whether the token has the provided suffix within the specified\n   * region.\n   *\n   * @param  {String}  suffix Suffix to match.\n   * @param  {String}  region Region name.\n   * @return {Boolean}        Whether the token string ends in suffix.\n   */\n  Token.prototype.hasSuffixInRegion = function (suffix, region) {\n    var regionStart = this.regions[region] || 0,\n      suffixStart   = this.string.length - suffix.length;\n    return this.hasSuffix(suffix) && suffixStart >= regionStart;\n  };\n\n  return Token;\n})();\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/stopwords_pt.js":"/*\nCopyright (c) 2011, Luís Rodrigues\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n// a list of commonly used words that have little meaning and can be excluded\n// from analysis.\nvar words = [\n  'a',\n  'à',\n  'ao',\n  'aos',\n  'aquela',\n  'aquelas',\n  'aquele',\n  'aqueles',\n  'aquilo',\n  'as',\n  'às',\n  'até',\n  'com',\n  'como',\n  'da',\n  'das',\n  'de',\n  'dela',\n  'delas',\n  'dele',\n  'deles',\n  'depois',\n  'do',\n  'dos',\n  'e',\n  'ela',\n  'elas',\n  'ele',\n  'eles',\n  'em',\n  'entre',\n  'essa',\n  'essas',\n  'esse',\n  'esses',\n  'esta',\n  'estas',\n  'este',\n  'estes',\n  'eu',\n  'isso',\n  'isto',\n  'já',\n  'lhe',\n  'lhes',\n  'mais',\n  'mas',\n  'me',\n  'mesmo',\n  'meu',\n  'meus',\n  'minha',\n  'minhas',\n  'muito',\n  'muitos',\n  'na',\n  'não',\n  'nas',\n  'nem',\n  'no',\n  'nos',\n  'nós',\n  'nossa',\n  'nossas',\n  'nosso',\n  'nossos',\n  'num',\n  'nuns',\n  'numa',\n  'numas',\n  'o',\n  'os',\n  'ou',\n  'para',\n  'pela',\n  'pelas',\n  'pelo',\n  'pelos',\n  'por',\n  'quais',\n  'qual',\n  'quando',\n  'que',\n  'quem',\n  'se',\n  'sem',\n  'seu',\n  'seus',\n  'só',\n  'sua',\n  'suas',\n  'também',\n  'te',\n  'teu',\n  'teus',\n  'tu',\n  'tua',\n  'tuas',\n  'um',\n  'uma',\n  'umas',\n  'você',\n  'vocês',\n  'vos',\n  'vosso',\n  'vossos',\n  '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'\n];\n\n// tell the world about the noise words.\nexports.words = words;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_pt.js":"/*\nCopyright (c) 2011, Chris Umbel,David Przybilla\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Tokenizer = require('./tokenizer'),\n    util = require('util');\n\nvar AggressiveTokenizer = function() {\n    Tokenizer.call(this);\n};\nutil.inherits(AggressiveTokenizer, Tokenizer);\n\nmodule.exports = AggressiveTokenizer;\n\nAggressiveTokenizer.prototype.withoutEmpty = function(array) {\n\treturn array.filter(function(a) {return a;});\n};\n\nAggressiveTokenizer.prototype.tokenize = function(text) {\n    // break a string up into an array of tokens by anything non-word\n    return this.withoutEmpty(this.trim(text.split(/[^a-zA-Zà-úÀ-Ú]/)));\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/lancaster_stemmer.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Stemmer = require('./stemmer');\nvar ruleTable = require('./lancaster_rules').rules;\n\nfunction acceptable(candidate) {\n    if (candidate.match(/^[aeiou]/))\n        return (candidate.length > 1);\n    else\n        return (candidate.length > 2 && candidate.match(/[aeiouy]/));\n}\n\n// take a token, look up the applicatble rule section and attempt some stemming!\nfunction applyRuleSection(token, intact) {\n    var section = token.substr( - 1);\n    var rules = ruleTable[section];\n\n    if (rules) {\n        for (var i = 0; i < rules.length; i++) {\n            if ((intact || !rules[i].intact)\n            // only apply intact rules to intact tokens\n            && token.substr(0 - rules[i].pattern.length) == rules[i].pattern) {\n                // hack off only as much as the rule indicates\n                var result = token.substr(0, token.length - rules[i].size);\n\n                // if the rules wants us to apply an appendage do so\n                if (rules[i].appendage)\n                    result += rules[i].appendage;\n\n                if (acceptable(result)) {\n                    token = result;\n\n                    // see what the rules wants to do next\n                    if (rules[i].continuation) {\n                        // this rule thinks there still might be stem left. keep at it.\n                        // since we've applied a change we'll pass false in for intact\n                        return applyRuleSection(result, false);\n                    } else {\n                        // the rule thinks we're done stemming. drop out.\n                        return result;\n                    }\n                }\n            }\n        }\n    }\n\n    return token;\n}\n\nvar LancasterStemmer = new Stemmer();\nmodule.exports = LancasterStemmer;\n\nLancasterStemmer.stem = function(token) {\n    return applyRuleSection(token.toLowerCase(), true);\n}","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/lancaster_rules.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nexports.rules = {\n    \"a\": [\n        {\n            \"continuation\": false, \n            \"intact\": true, \n            \"pattern\": \"ia\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": true, \n            \"pattern\": \"a\", \n            \"size\": \"1\"\n        }\n    ], \n    \"b\": [\n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"bb\", \n            \"size\": \"1\"\n        }\n    ], \n    \"c\": [\n        {\n            \"appendage\": \"s\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ytic\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ic\", \n            \"size\": \"2\"\n       }, \n        {\n            \"appendage\": \"t\", \n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"nc\", \n            \"size\": \"1\"\n        }\n    ], \n    \"d\": [\n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"dd\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"y\", \n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ied\", \n            \"size\": \"3\"\n        }, \n        {\n            \"appendage\": \"ss\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ceed\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"eed\", \n            \"size\": \"1\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ed\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"hood\", \n            \"size\": \"4\"\n        }\n    ], \n    \"e\": [\n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"e\", \n            \"size\": \"1\"\n        }\n    ], \n    \"f\": [\n        {\n            \"appendage\": \"v\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"lief\", \n            \"size\": \"1\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"if\", \n            \"size\": \"2\"\n        }\n    ], \n    \"g\": [\n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ing\", \n            \"size\": \"3\"\n        }, \n        {\n            \"appendage\": \"y\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"iag\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ag\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"gg\", \n            \"size\": \"1\"\n        }\n    ], \n    \"h\": [\n        {\n            \"continuation\": false, \n            \"intact\": true, \n            \"pattern\": \"th\", \n            \"size\": \"2\"\n        }, \n        {\n            \"appendage\": \"ct\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"guish\", \n            \"size\": \"5\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ish\", \n            \"size\": \"3\"\n        }\n    ], \n    \"i\": [\n        {\n            \"continuation\": false, \n            \"intact\": true, \n            \"pattern\": \"i\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"y\", \n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"i\", \n            \"size\": \"1\"\n        }\n    ], \n    \"j\": [\n        {\n            \"appendage\": \"d\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ij\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"s\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"fuj\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"d\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"uj\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"d\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"oj\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"r\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"hej\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"t\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"verj\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"t\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"misj\", \n            \"size\": \"2\"\n        }, \n        {\n            \"appendage\": \"d\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"nj\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"s\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"j\", \n            \"size\": \"1\"\n        }\n    ], \n    \"l\": [\n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ifiabl\", \n            \"size\": \"6\"\n        }, \n        {\n            \"appendage\": \"y\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"iabl\", \n            \"size\": \"4\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"abl\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ibl\", \n            \"size\": \"3\"\n        }, \n        {\n            \"appendage\": \"l\", \n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"bil\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"cl\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"y\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"iful\", \n            \"size\": \"4\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ful\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ul\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ial\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ual\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"al\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ll\", \n            \"size\": \"1\"\n        }\n    ], \n    \"m\": [\n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ium\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": true, \n            \"pattern\": \"um\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ism\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"mm\", \n            \"size\": \"1\"\n        }\n    ], \n    \"n\": [\n        {\n            \"appendage\": \"j\", \n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"sion\", \n            \"size\": \"4\"\n        }, \n        {\n            \"appendage\": \"ct\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"xion\", \n            \"size\": \"4\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ion\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ian\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"an\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"een\", \n            \"size\": \"0\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"en\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"nn\", \n            \"size\": \"1\"\n        }\n    ], \n    \"p\": [\n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ship\", \n            \"size\": \"4\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"pp\", \n            \"size\": \"1\"\n        }\n    ], \n    \"r\": [\n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"er\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ear\", \n            \"size\": \"0\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ar\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"or\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ur\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"rr\", \n            \"size\": \"1\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"tr\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"y\", \n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ier\", \n            \"size\": \"3\"\n        }\n    ], \n    \"s\": [\n        {\n            \"appendage\": \"y\", \n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ies\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"sis\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"is\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ness\", \n            \"size\": \"4\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ss\", \n            \"size\": \"0\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ous\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": true, \n            \"pattern\": \"us\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": true, \n            \"pattern\": \"s\", \n            \"size\": \"1\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"s\", \n            \"size\": \"0\"\n        }\n    ], \n    \"t\": [\n        {\n            \"appendage\": \"y\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"plicat\", \n            \"size\": \"4\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"at\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ment\", \n            \"size\": \"4\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ent\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ant\", \n            \"size\": \"3\"\n        }, \n        {\n            \"appendage\": \"b\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ript\", \n            \"size\": \"2\"\n        }, \n        {\n            \"appendage\": \"b\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"orpt\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"duct\", \n            \"size\": \"1\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"sumpt\", \n            \"size\": \"2\"\n        }, \n        {\n            \"appendage\": \"iv\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"cept\", \n            \"size\": \"2\"\n        }, \n        {\n            \"appendage\": \"v\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"olut\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"sist\", \n            \"size\": \"0\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ist\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"tt\", \n            \"size\": \"1\"\n        }\n    ], \n    \"u\": [\n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"iqu\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ogu\", \n            \"size\": \"1\"\n        }\n    ], \n    \"v\": [\n        {\n            \"appendage\": \"j\", \n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"siv\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"eiv\", \n            \"size\": \"0\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"iv\", \n            \"size\": \"2\"\n        }\n    ], \n    \"y\": [\n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"bly\", \n            \"size\": \"1\"\n        }, \n        {\n            \"appendage\": \"y\", \n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ily\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ply\", \n            \"size\": \"0\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ly\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ogy\", \n            \"size\": \"1\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"phy\", \n            \"size\": \"1\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"omy\", \n            \"size\": \"1\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"opy\", \n            \"size\": \"1\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ity\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ety\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"lty\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"istry\", \n            \"size\": \"5\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ary\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ory\", \n            \"size\": \"3\"\n        }, \n        {\n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"ify\", \n            \"size\": \"3\"\n        }, \n        {\n            \"appendage\": \"t\", \n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"ncy\", \n            \"size\": \"2\"\n        }, \n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"acy\", \n            \"size\": \"3\"\n        }\n    ], \n    \"z\": [\n        {\n            \"continuation\": true, \n            \"intact\": false, \n            \"pattern\": \"iz\", \n            \"size\": \"2\"\n        }, \n        {\n            \"appendage\": \"s\", \n            \"continuation\": false, \n            \"intact\": false, \n            \"pattern\": \"yz\", \n            \"size\": \"1\"\n        }\n    ]\n};\n\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/stemmer_pl.js":"/*\nCopyright (c) 2013, Paweł Łaskarzewski\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar stopwords = require('../util/stopwords_pl');\nvar Tokenizer = require('../tokenizers/aggressive_tokenizer_pl');\n\nmodule.exports = function() {\n    var stemmer = this;\n\n    stemmer.stem = function(token) {\n        return token;\n    };\n\n    stemmer.tokenizeAndStem = function(text, keepStops) {\n        var stemmedTokens = [];\n\n        new Tokenizer().tokenize(text).forEach(function(token) {\n            if (keepStops || stopwords.words.indexOf(token) == -1) {\n                var resultToken = token.toLowerCase();\n                if (resultToken.match(new RegExp('[a-zążśźęćńół0-9]+', 'gi'))) {\n                    resultToken = stemmer.stem(resultToken);\n                }\n                stemmedTokens.push(resultToken);\n            }\n        });\n\n        return stemmedTokens;\n    };\n\n    stemmer.attach = function() {\n        String.prototype.stem = function() {\n            return stemmer.stem(this);\n        };\n\n        String.prototype.tokenizeAndStem = function(keepStops) {\n            return stemmer.tokenizeAndStem(this, keepStops);\n        };\n    };\n}\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/stopwords_pl.js":"/*\nCopyright (c) 2013, Paweł Łaskarzewski\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n// a list of commonly used words that have little meaning and can be excluded\n// from analysis.\n// list based on: http://pl.wikipedia.org/wiki/Wikipedia:Stopwords\nvar words = [\n    'a', 'aby', 'ach', 'acz', 'aczkolwiek', 'aj', 'albo', 'ale', 'ależ', 'ani',\n    'aż', 'bardziej', 'bardzo', 'bo', 'bowiem', 'by', 'byli', 'bynajmniej',\n    'być', 'był', 'była', 'było', 'były', 'będzie', 'będą', 'cali', 'cała',\n    'cały', 'ci', 'cię', 'ciebie', 'co', 'cokolwiek', 'coś', 'czasami',\n    'czasem', 'czemu', 'czy', 'czyli', 'daleko', 'dla', 'dlaczego', 'dlatego',\n    'do', 'dobrze', 'dokąd', 'dość', 'dużo', 'dwa', 'dwaj', 'dwie', 'dwoje',\n    'dziś', 'dzisiaj', 'gdy', 'gdyby', 'gdyż', 'gdzie', 'gdziekolwiek',\n    'gdzieś', 'i', 'ich', 'ile', 'im', 'inna', 'inne', 'inny', 'innych', 'iż',\n    'ja', 'ją', 'jak', 'jakaś', 'jakby', 'jaki', 'jakichś', 'jakie', 'jakiś',\n    'jakiż', 'jakkolwiek', 'jako', 'jakoś', 'je', 'jeden', 'jedna', 'jedno',\n    'jednak', 'jednakże', 'jego', 'jej', 'jemu', 'jest', 'jestem', 'jeszcze',\n    'jeśli', 'jeżeli', 'już', 'ją', 'każdy', 'kiedy', 'kilka', 'kimś', 'kto',\n    'ktokolwiek', 'ktoś', 'która', 'które', 'którego', 'której', 'który',\n    'których', 'którym', 'którzy', 'ku', 'lat', 'lecz', 'lub', 'ma', 'mają',\n    'mało', 'mam', 'mi', 'mimo', 'między', 'mną', 'mnie', 'mogą', 'moi', 'moim',\n    'moja', 'moje', 'może', 'możliwe', 'można', 'mój', 'mu', 'musi', 'my', 'na',\n    'nad', 'nam', 'nami', 'nas', 'nasi', 'nasz', 'nasza', 'nasze', 'naszego',\n    'naszych', 'natomiast', 'natychmiast', 'nawet', 'nią', 'nic', 'nich', 'nie',\n    'niech', 'niego', 'niej', 'niemu', 'nigdy', 'nim', 'nimi', 'niż', 'no', 'o',\n    'obok', 'od', 'około', 'on', 'ona', 'one', 'oni', 'ono', 'oraz', 'oto',\n    'owszem', 'pan', 'pana', 'pani', 'po', 'pod', 'podczas', 'pomimo', 'ponad',\n    'ponieważ', 'powinien', 'powinna', 'powinni', 'powinno', 'poza', 'prawie',\n    'przecież', 'przed', 'przede', 'przedtem', 'przez', 'przy', 'roku',\n    'również', 'sam', 'sama', 'są', 'się', 'skąd', 'sobie', 'sobą', 'sposób',\n    'swoje', 'ta', 'tak', 'taka', 'taki', 'takie', 'także', 'tam', 'te', 'tego',\n    'tej', 'temu', 'ten', 'teraz', 'też', 'to', 'tobą', 'tobie', 'toteż',\n    'trzeba', 'tu', 'tutaj', 'twoi', 'twoim', 'twoja', 'twoje', 'twym', 'twój',\n    'ty', 'tych', 'tylko', 'tym', 'u', 'w', 'wam', 'wami', 'was', 'wasz', 'zaś',\n    'wasza', 'wasze', 'we', 'według', 'wiele', 'wielu', 'więc', 'więcej', 'tę',\n    'wszyscy', 'wszystkich', 'wszystkie', 'wszystkim', 'wszystko', 'wtedy',\n    'wy', 'właśnie', 'z', 'za', 'zapewne', 'zawsze', 'ze', 'zł', 'znowu',\n    'znów', 'został', 'żaden', 'żadna', 'żadne', 'żadnych', 'że', 'żeby',\n    '$', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'];\n\n// tell the world about the noise words.\nexports.words = words;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_pl.js":"/*\nCopyright (c) 2013, Paweł Łaskarzewski\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Tokenizer = require('./tokenizer'),\n    util = require('util');\n\nvar AggressiveTokenizer = function() {\n    Tokenizer.call(this);\n};\n\nutil.inherits(AggressiveTokenizer, Tokenizer);\n\nmodule.exports = AggressiveTokenizer;\n\nAggressiveTokenizer.prototype.withoutEmpty = function(array) {\n\treturn array.filter(function(a) {return a;});\n};\n\nAggressiveTokenizer.prototype.clearText = function(text) {\n\treturn text.replace(/[^a-zążśźęćńół0-9]/gi, ' ').replace(/[\\s\\n]+/g, ' ').trim();\n};\n\nAggressiveTokenizer.prototype.tokenize = function(text) {\n    // break a string up into an array of tokens by anything non-word\n    return this.withoutEmpty(this.clearText(text).split(' '));\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/stemmers/stemmer_ja.js":"/*\n Copyright (c) 2012, Guillaume Marty\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n\n/**\n * A very basic stemmer that performs the following steps:\n * * Stem katakana.\n * Inspired by:\n * http://svn.apache.org/repos/asf/lucene/dev/trunk/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilter.java\n *\n * This script assumes input is normalized using normalizer_ja().\n *\n * \\@todo Use .bind() in StemmerJa.prototype.attach().\n */\n\nvar Tokenizer = require('../tokenizers/tokenizer_ja');\nvar stopwords = require('../util/stopwords_ja');\n\n\n\n/**\n * @constructor\n */\nvar StemmerJa = function() {\n};\n\n\n/**\n * Tokenize and stem a text.\n * Stop words are excluded except if the second argument is true.\n *\n * @param {string} text\n * @param {boolean} keepStops Whether to keep stop words from the output or not.\n * @return {Array.<string>}\n */\nStemmerJa.prototype.tokenizeAndStem = function(text, keepStops) {\n  var self = this;\n  var stemmedTokens = [];\n  var tokens = new Tokenizer().tokenize(text);\n\n  // This is probably faster than an if at each iteration.\n  if (keepStops) {\n    tokens.forEach(function(token) {\n      var resultToken = token.toLowerCase();\n      resultToken = self.stem(resultToken);\n      stemmedTokens.push(resultToken);\n    });\n  } else {\n    tokens.forEach(function(token) {\n      if (stopwords.indexOf(token) == -1) {\n        var resultToken = token.toLowerCase();\n        resultToken = self.stem(resultToken);\n        stemmedTokens.push(resultToken);\n      }\n    });\n  }\n\n  return stemmedTokens;\n};\n\n\n/**\n * Stem a term.\n *\n * @param {string} token\n * @return {string}\n */\nStemmerJa.prototype.stem = function(token) {\n  token = this.stemKatakana(token);\n\n  return token;\n};\n\n\n/**\n * Remove the final prolonged sound mark on katakana if length is superior to\n * a threshold.\n *\n * @param {string} token A katakana string to stem.\n * @return {string} A katakana string stemmed.\n */\nStemmerJa.prototype.stemKatakana = function(token) {\n  var HIRAGANA_KATAKANA_PROLONGED_SOUND_MARK = 'ー';\n  var DEFAULT_MINIMUM_LENGTH = 4;\n\n  if (token.length >= DEFAULT_MINIMUM_LENGTH\n      && token.slice(-1) === HIRAGANA_KATAKANA_PROLONGED_SOUND_MARK\n      && this.isKatakana(token)) {\n    token = token.slice(0, token.length - 1);\n  }\n  return token;\n};\n\n\n/**\n * Is a string made of fullwidth katakana only?\n * This implementation is the fastest I know:\n * http://jsperf.com/string-contain-katakana-only/2\n *\n * @param {string} str A string.\n * @return {boolean} True if the string has katakana only.\n */\nStemmerJa.prototype.isKatakana = function(str) {\n  return !!str.match(/^[゠-ヿ]+$/);\n};\n\n// Expose an attach function that will patch String with new methods.\nStemmerJa.prototype.attach = function() {\n  var self = this;\n\n  String.prototype.stem = function() {\n    return self.stem(this);\n  };\n\n  String.prototype.tokenizeAndStem = function(keepStops) {\n    return self.tokenizeAndStem(this, keepStops);\n  };\n};\n\nmodule.exports = StemmerJa;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/tokenizer_ja.js":"// Original copyright:\n/*\n Copyright (c) 2008, Taku Kudo\n\n All rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are met:\n\n * Redistributions of source code must retain the above copyright notice,\n this list of conditions and the following disclaimer.\n * Redistributions in binary form must reproduce the above copyright\n notice, this list of conditions and the following disclaimer in the\n documentation and/or other materials provided with the distribution.\n * Neither the name of the <ORGANIZATION> nor the names of its\n contributors may be used to endorse or promote products derived from this\n software without specific prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR\n CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n// This version:\n/*\n Copyright (c) 2012, Guillaume Marty\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n\n// TinySegmenter 0.1 -- Super compact Japanese tokenizer in Javascript\n// (c) 2008 Taku Kudo <taku@chasen.org>\n// TinySegmenter is freely distributable under the terms of a new BSD licence.\n// For details, see http://chasen.org/~taku/software/TinySegmenter/LICENCE.txt\n\nvar Tokenizer = require('./tokenizer'),\n    normalize = require('../normalizers/normalizer_ja').normalize_ja,\n    util = require('util');\n\n\n\n/**\n * @constructor\n */\nvar TokenizerJa = function() {\n  this.chartype_ = [\n    [/[〇一二三四五六七八九十百千万億兆]/, 'M'],\n    [/[一-鿌〆]/, 'H'],\n    [/[ぁ-ゟ]/, 'I'],\n    [/[゠-ヿ]/, 'K'],\n    [/[a-zA-Z]/, 'A'],\n    [/[0-9]/, 'N']\n  ];\n\n  this.BIAS__ = -332;\n  this.BC1__ = {'HH': 6, 'II': 2461, 'KH': 406, 'OH': -1378};\n  this.BC2__ = {'AA': -3267, 'AI': 2744, 'AN': -878, 'HH': -4070, 'HM': -1711, 'HN': 4012, 'HO': 3761, 'IA': 1327, 'IH': -1184, 'II': -1332, 'IK': 1721, 'IO': 5492, 'KI': 3831, 'KK': -8741, 'MH': -3132, 'MK': 3334, 'OO': -2920};\n  this.BC3__ = {'HH': 996, 'HI': 626, 'HK': -721, 'HN': -1307, 'HO': -836, 'IH': -301, 'KK': 2762, 'MK': 1079, 'MM': 4034, 'OA': -1652, 'OH': 266};\n  this.BP1__ = {'BB': 295, 'OB': 304, 'OO': -125, 'UB': 352};\n  this.BP2__ = {'BO': 60, 'OO': -1762};\n  this.BQ1__ = {'BHH': 1150, 'BHM': 1521, 'BII': -1158, 'BIM': 886, 'BMH': 1208, 'BNH': 449, 'BOH': -91, 'BOO': -2597, 'OHI': 451, 'OIH': -296, 'OKA': 1851, 'OKH': -1020, 'OKK': 904, 'OOO': 2965};\n  this.BQ2__ = {'BHH': 118, 'BHI': -1159, 'BHM': 466, 'BIH': -919, 'BKK': -1720, 'BKO': 864, 'OHH': -1139, 'OHM': -181, 'OIH': 153, 'UHI': -1146};\n  this.BQ3__ = {'BHH': -792, 'BHI': 2664, 'BII': -299, 'BKI': 419, 'BMH': 937, 'BMM': 8335, 'BNN': 998, 'BOH': 775, 'OHH': 2174, 'OHM': 439, 'OII': 280, 'OKH': 1798, 'OKI': -793, 'OKO': -2242, 'OMH': -2402, 'OOO': 11699};\n  this.BQ4__ = {'BHH': -3895, 'BIH': 3761, 'BII': -4654, 'BIK': 1348, 'BKK': -1806, 'BMI': -3385, 'BOO': -12396, 'OAH': 926, 'OHH': 266, 'OHK': -2036, 'ONN': -973};\n  this.BW1__ = {'，と': 660, '，同': 727, 'B1あ': 1404, 'B1同': 542, '、と': 660, '、同': 727, '｣と': 1682, 'あっ': 1505, 'いう': 1743, 'いっ': -2055, 'いる': 672, 'うし': -4817, 'うん': 665, 'から': 3472, 'がら': 600, 'こう': -790, 'こと': 2083, 'こん': -1262, 'さら': -4143, 'さん': 4573, 'した': 2641, 'して': 1104, 'すで': -3399, 'そこ': 1977, 'それ': -871, 'たち': 1122, 'ため': 601, 'った': 3463, 'つい': -802, 'てい': 805, 'てき': 1249, 'でき': 1127, 'です': 3445, 'では': 844, 'とい': -4915, 'とみ': 1922, 'どこ': 3887, 'ない': 5713, 'なっ': 3015, 'など': 7379, 'なん': -1113, 'にし': 2468, 'には': 1498, 'にも': 1671, 'に対': -912, 'の一': -501, 'の中': 741, 'ませ': 2448, 'まで': 1711, 'まま': 2600, 'まる': -2155, 'やむ': -1947, 'よっ': -2565, 'れた': 2369, 'れで': -913, 'をし': 1860, 'を見': 731, '亡く': -1886, '京都': 2558, '取り': -2784, '大き': -2604, '大阪': 1497, '平方': -2314, '引き': -1336, '日本': -195, '本当': -2423, '毎日': -2113, '目指': -724};\n  this.BW2__ = {'11': -669, '．．': -11822, '――': -5730, '−−': -13175, 'いう': -1609, 'うか': 2490, 'かし': -1350, 'かも': -602, 'から': -7194, 'かれ': 4612, 'がい': 853, 'がら': -3198, 'きた': 1941, 'くな': -1597, 'こと': -8392, 'この': -4193, 'させ': 4533, 'され': 13168, 'さん': -3977, 'しい': -1819, 'しか': -545, 'した': 5078, 'して': 972, 'しな': 939, 'その': -3744, 'たい': -1253, 'たた': -662, 'ただ': -3857, 'たち': -786, 'たと': 1224, 'たは': -939, 'った': 4589, 'って': 1647, 'っと': -2094, 'てい': 6144, 'てき': 3640, 'てく': 2551, 'ては': -3110, 'ても': -3065, 'でい': 2666, 'でき': -1528, 'でし': -3828, 'です': -4761, 'でも': -4203, 'とい': 1890, 'とこ': -1746, 'とと': -2279, 'との': 720, 'とみ': 5168, 'とも': -3941, 'ない': -2488, 'なが': -1313, 'など': -6509, 'なの': 2614, 'なん': 3099, 'にお': -1615, 'にし': 2748, 'にな': 2454, 'によ': -7236, 'に対': -14943, 'に従': -4688, 'に関': -11388, 'のか': 2093, 'ので': -7059, 'のに': -6041, 'のの': -6125, 'はい': 1073, 'はが': -1033, 'はず': -2532, 'ばれ': 1813, 'まし': -1316, 'まで': -6621, 'まれ': 5409, 'めて': -3153, 'もい': 2230, 'もの': -10713, 'らか': -944, 'らし': -1611, 'らに': -1897, 'りし': 651, 'りま': 1620, 'れた': 4270, 'れて': 849, 'れば': 4114, 'ろう': 6067, 'われ': 7901, 'を通': -11877, 'んだ': 728, 'んな': -4115, '一人': 602, '一方': -1375, '一日': 970, '一部': -1051, '上が': -4479, '会社': -1116, '出て': 2163, '分の': -7758, '同党': 970, '同日': -913, '大阪': -2471, '委員': -1250, '少な': -1050, '年度': -8669, '年間': -1626, '府県': -2363, '手権': -1982, '新聞': -4066, '日新': -722, '日本': -7068, '日米': 3372, '曜日': -601, '朝鮮': -2355, '本人': -2697, '東京': -1543, '然と': -1384, '社会': -1276, '立て': -990, '第に': -1612, '米国': -4268};\n  this.BW3__ = {'あた': -2194, 'あり': 719, 'ある': 3846, 'い．': -1185, 'い。': -1185, 'いい': 5308, 'いえ': 2079, 'いく': 3029, 'いた': 2056, 'いっ': 1883, 'いる': 5600, 'いわ': 1527, 'うち': 1117, 'うと': 4798, 'えと': 1454, 'か．': 2857, 'か。': 2857, 'かけ': -743, 'かっ': -4098, 'かに': -669, 'から': 6520, 'かり': -2670, 'が，': 1816, 'が、': 1816, 'がき': -4855, 'がけ': -1127, 'がっ': -913, 'がら': -4977, 'がり': -2064, 'きた': 1645, 'けど': 1374, 'こと': 7397, 'この': 1542, 'ころ': -2757, 'さい': -714, 'さを': 976, 'し，': 1557, 'し、': 1557, 'しい': -3714, 'した': 3562, 'して': 1449, 'しな': 2608, 'しま': 1200, 'す．': -1310, 'す。': -1310, 'する': 6521, 'ず，': 3426, 'ず、': 3426, 'ずに': 841, 'そう': 428, 'た．': 8875, 'た。': 8875, 'たい': -594, 'たの': 812, 'たり': -1183, 'たる': -853, 'だ．': 4098, 'だ。': 4098, 'だっ': 1004, 'った': -4748, 'って': 300, 'てい': 6240, 'てお': 855, 'ても': 302, 'です': 1437, 'でに': -1482, 'では': 2295, 'とう': -1387, 'とし': 2266, 'との': 541, 'とも': -3543, 'どう': 4664, 'ない': 1796, 'なく': -903, 'など': 2135, 'に，': -1021, 'に、': -1021, 'にし': 1771, 'にな': 1906, 'には': 2644, 'の，': -724, 'の、': -724, 'の子': -1000, 'は，': 1337, 'は、': 1337, 'べき': 2181, 'まし': 1113, 'ます': 6943, 'まっ': -1549, 'まで': 6154, 'まれ': -793, 'らし': 1479, 'られ': 6820, 'るる': 3818, 'れ，': 854, 'れ、': 854, 'れた': 1850, 'れて': 1375, 'れば': -3246, 'れる': 1091, 'われ': -605, 'んだ': 606, 'んで': 798, 'カ月': 990, '会議': 860, '入り': 1232, '大会': 2217, '始め': 1681, '市': 965, '新聞': -5055, '日，': 974, '日、': 974, '社会': 2024};\n  this.TC1__ = {'AAA': 1093, 'HHH': 1029, 'HHM': 580, 'HII': 998, 'HOH': -390, 'HOM': -331, 'IHI': 1169, 'IOH': -142, 'IOI': -1015, 'IOM': 467, 'MMH': 187, 'OOI': -1832};\n  this.TC2__ = {'HHO': 2088, 'HII': -1023, 'HMM': -1154, 'IHI': -1965, 'KKH': 703, 'OII': -2649};\n  this.TC3__ = {'AAA': -294, 'HHH': 346, 'HHI': -341, 'HII': -1088, 'HIK': 731, 'HOH': -1486, 'IHH': 128, 'IHI': -3041, 'IHO': -1935, 'IIH': -825, 'IIM': -1035, 'IOI': -542, 'KHH': -1216, 'KKA': 491, 'KKH': -1217, 'KOK': -1009, 'MHH': -2694, 'MHM': -457, 'MHO': 123, 'MMH': -471, 'NNH': -1689, 'NNO': 662, 'OHO': -3393};\n  this.TC4__ = {'HHH': -203, 'HHI': 1344, 'HHK': 365, 'HHM': -122, 'HHN': 182, 'HHO': 669, 'HIH': 804, 'HII': 679, 'HOH': 446, 'IHH': 695, 'IHO': -2324, 'IIH': 321, 'III': 1497, 'IIO': 656, 'IOO': 54, 'KAK': 4845, 'KKA': 3386, 'KKK': 3065, 'MHH': -405, 'MHI': 201, 'MMH': -241, 'MMM': 661, 'MOM': 841};\n  this.TQ1__ = {'BHHH': -227, 'BHHI': 316, 'BHIH': -132, 'BIHH': 60, 'BIII': 1595, 'BNHH': -744, 'BOHH': 225, 'BOOO': -908, 'OAKK': 482, 'OHHH': 281, 'OHIH': 249, 'OIHI': 200, 'OIIH': -68};\n  this.TQ2__ = {'BIHH': -1401, 'BIII': -1033, 'BKAK': -543, 'BOOO': -5591};\n  this.TQ3__ = {'BHHH': 478, 'BHHM': -1073, 'BHIH': 222, 'BHII': -504, 'BIIH': -116, 'BIII': -105, 'BMHI': -863, 'BMHM': -464, 'BOMH': 620, 'OHHH': 346, 'OHHI': 1729, 'OHII': 997, 'OHMH': 481, 'OIHH': 623, 'OIIH': 1344, 'OKAK': 2792, 'OKHH': 587, 'OKKA': 679, 'OOHH': 110, 'OOII': -685};\n  this.TQ4__ = {'BHHH': -721, 'BHHM': -3604, 'BHII': -966, 'BIIH': -607, 'BIII': -2181, 'OAAA': -2763, 'OAKK': 180, 'OHHH': -294, 'OHHI': 2446, 'OHHO': 480, 'OHIH': -1573, 'OIHH': 1935, 'OIHI': -493, 'OIIH': 626, 'OIII': -4007, 'OKAK': -8156};\n  this.TW1__ = {'につい': -4681, '東京都': 2026};\n  this.TW2__ = {'ある程': -2049, 'いった': -1256, 'ころが': -2434, 'しょう': 3873, 'その後': -4430, 'だって': -1049, 'ていた': 1833, 'として': -4657, 'ともに': -4517, 'もので': 1882, '一気に': -792, '初めて': -1512, '同時に': -8097, '大きな': -1255, '対して': -2721, '社会党': -3216};\n  this.TW3__ = {'いただ': -1734, 'してい': 1314, 'として': -4314, 'につい': -5483, 'にとっ': -5989, 'に当た': -6247, 'ので，': -727, 'ので、': -727, 'のもの': -600, 'れから': -3752, '十二月': -2287};\n  this.TW4__ = {'いう．': 8576, 'いう。': 8576, 'からな': -2348, 'してい': 2958, 'たが，': 1516, 'たが、': 1516, 'ている': 1538, 'という': 1349, 'ました': 5543, 'ません': 1097, 'ようと': -4258, 'よると': 5865};\n  this.UC1__ = {'A': 484, 'K': 93, 'M': 645, 'O': -505};\n  this.UC2__ = {'A': 819, 'H': 1059, 'I': 409, 'M': 3987, 'N': 5775, 'O': 646};\n  this.UC3__ = {'A': -1370, 'I': 2311};\n  this.UC4__ = {'A': -2643, 'H': 1809, 'I': -1032, 'K': -3450, 'M': 3565, 'N': 3876, 'O': 6646};\n  this.UC5__ = {'H': 313, 'I': -1238, 'K': -799, 'M': 539, 'O': -831};\n  this.UC6__ = {'H': -506, 'I': -253, 'K': 87, 'M': 247, 'O': -387};\n  this.UP1__ = {'O': -214};\n  this.UP2__ = {'B': 69, 'O': 935};\n  this.UP3__ = {'B': 189};\n  this.UQ1__ = {'BH': 21, 'BI': -12, 'BK': -99, 'BN': 142, 'BO': -56, 'OH': -95, 'OI': 477, 'OK': 410, 'OO': -2422};\n  this.UQ2__ = {'BH': 216, 'BI': 113, 'OK': 1759};\n  this.UQ3__ = {'BA': -479, 'BH': 42, 'BI': 1913, 'BK': -7198, 'BM': 3160, 'BN': 6427, 'BO': 14761, 'OI': -827, 'ON': -3212};\n  this.UW1__ = {'，': 156, '、': 156, '｢': -463, 'あ': -941, 'う': -127, 'が': -553, 'き': 121, 'こ': 505, 'で': -201, 'と': -547, 'ど': -123, 'に': -789, 'の': -185, 'は': -847, 'も': -466, 'や': -470, 'よ': 182, 'ら': -292, 'り': 208, 'れ': 169, 'を': -446, 'ん': -137, '・': -135, '主': -402, '京': -268, '区': -912, '午': 871, '国': -460, '大': 561, '委': 729, '市': -411, '日': -141, '理': 361, '生': -408, '県': -386, '都': -718};\n  this.UW2__ = {'，': -829, '、': -829, '〇': 892, '｢': -645, '｣': 3145, 'あ': -538, 'い': 505, 'う': 134, 'お': -502, 'か': 1454, 'が': -856, 'く': -412, 'こ': 1141, 'さ': 878, 'ざ': 540, 'し': 1529, 'す': -675, 'せ': 300, 'そ': -1011, 'た': 188, 'だ': 1837, 'つ': -949, 'て': -291, 'で': -268, 'と': -981, 'ど': 1273, 'な': 1063, 'に': -1764, 'の': 130, 'は': -409, 'ひ': -1273, 'べ': 1261, 'ま': 600, 'も': -1263, 'や': -402, 'よ': 1639, 'り': -579, 'る': -694, 'れ': 571, 'を': -2516, 'ん': 2095, 'ア': -587, 'カ': 306, 'キ': 568, 'ッ': 831, '三': -758, '不': -2150, '世': -302, '中': -968, '主': -861, '事': 492, '人': -123, '会': 978, '保': 362, '入': 548, '初': -3025, '副': -1566, '北': -3414, '区': -422, '大': -1769, '天': -865, '太': -483, '子': -1519, '学': 760, '実': 1023, '小': -2009, '市': -813, '年': -1060, '強': 1067, '手': -1519, '揺': -1033, '政': 1522, '文': -1355, '新': -1682, '日': -1815, '明': -1462, '最': -630, '朝': -1843, '本': -1650, '東': -931, '果': -665, '次': -2378, '民': -180, '気': -1740, '理': 752, '発': 529, '目': -1584, '相': -242, '県': -1165, '立': -763, '第': 810, '米': 509, '自': -1353, '行': 838, '西': -744, '見': -3874, '調': 1010, '議': 1198, '込': 3041, '開': 1758, '間': -1257};\n  this.UW3__ = {'1': -800, '，': 4889, '−': -1723, '、': 4889, '々': -2311, '〇': 5827, '｣': 2670, '〓': -3573, 'あ': -2696, 'い': 1006, 'う': 2342, 'え': 1983, 'お': -4864, 'か': -1163, 'が': 3271, 'く': 1004, 'け': 388, 'げ': 401, 'こ': -3552, 'ご': -3116, 'さ': -1058, 'し': -395, 'す': 584, 'せ': 3685, 'そ': -5228, 'た': 842, 'ち': -521, 'っ': -1444, 'つ': -1081, 'て': 6167, 'で': 2318, 'と': 1691, 'ど': -899, 'な': -2788, 'に': 2745, 'の': 4056, 'は': 4555, 'ひ': -2171, 'ふ': -1798, 'へ': 1199, 'ほ': -5516, 'ま': -4384, 'み': -120, 'め': 1205, 'も': 2323, 'や': -788, 'よ': -202, 'ら': 727, 'り': 649, 'る': 5905, 'れ': 2773, 'わ': -1207, 'を': 6620, 'ん': -518, 'ア': 551, 'グ': 1319, 'ス': 874, 'ッ': -1350, 'ト': 521, 'ム': 1109, 'ル': 1591, 'ロ': 2201, 'ン': 278, '・': -3794, '一': -1619, '下': -1759, '世': -2087, '両': 3815, '中': 653, '主': -758, '予': -1193, '二': 974, '人': 2742, '今': 792, '他': 1889, '以': -1368, '低': 811, '何': 4265, '作': -361, '保': -2439, '元': 4858, '党': 3593, '全': 1574, '公': -3030, '六': 755, '共': -1880, '円': 5807, '再': 3095, '分': 457, '初': 2475, '別': 1129, '前': 2286, '副': 4437, '力': 365, '動': -949, '務': -1872, '化': 1327, '北': -1038, '区': 4646, '千': -2309, '午': -783, '協': -1006, '口': 483, '右': 1233, '各': 3588, '合': -241, '同': 3906, '和': -837, '員': 4513, '国': 642, '型': 1389, '場': 1219, '外': -241, '妻': 2016, '学': -1356, '安': -423, '実': -1008, '家': 1078, '小': -513, '少': -3102, '州': 1155, '市': 3197, '平': -1804, '年': 2416, '広': -1030, '府': 1605, '度': 1452, '建': -2352, '当': -3885, '得': 1905, '思': -1291, '性': 1822, '戸': -488, '指': -3973, '政': -2013, '教': -1479, '数': 3222, '文': -1489, '新': 1764, '日': 2099, '旧': 5792, '昨': -661, '時': -1248, '曜': -951, '最': -937, '月': 4125, '期': 360, '李': 3094, '村': 364, '東': -805, '核': 5156, '森': 2438, '業': 484, '氏': 2613, '民': -1694, '決': -1073, '法': 1868, '海': -495, '無': 979, '物': 461, '特': -3850, '生': -273, '用': 914, '町': 1215, '的': 7313, '直': -1835, '省': 792, '県': 6293, '知': -1528, '私': 4231, '税': 401, '立': -960, '第': 1201, '米': 7767, '系': 3066, '約': 3663, '級': 1384, '統': -4229, '総': 1163, '線': 1255, '者': 6457, '能': 725, '自': -2869, '英': 785, '見': 1044, '調': -562, '財': -733, '費': 1777, '車': 1835, '軍': 1375, '込': -1504, '通': -1136, '選': -681, '郎': 1026, '郡': 4404, '部': 1200, '金': 2163, '長': 421, '開': -1432, '間': 1302, '関': -1282, '雨': 2009, '電': -1045, '非': 2066, '駅': 1620};\n  this.UW4__ = {'，': 3930, '．': 3508, '―': -4841, '、': 3930, '。': 3508, '〇': 4999, '｢': 1895, '｣': 3798, '〓': -5156, 'あ': 4752, 'い': -3435, 'う': -640, 'え': -2514, 'お': 2405, 'か': 530, 'が': 6006, 'き': -4482, 'ぎ': -3821, 'く': -3788, 'け': -4376, 'げ': -4734, 'こ': 2255, 'ご': 1979, 'さ': 2864, 'し': -843, 'じ': -2506, 'す': -731, 'ず': 1251, 'せ': 181, 'そ': 4091, 'た': 5034, 'だ': 5408, 'ち': -3654, 'っ': -5882, 'つ': -1659, 'て': 3994, 'で': 7410, 'と': 4547, 'な': 5433, 'に': 6499, 'ぬ': 1853, 'ね': 1413, 'の': 7396, 'は': 8578, 'ば': 1940, 'ひ': 4249, 'び': -4134, 'ふ': 1345, 'へ': 6665, 'べ': -744, 'ほ': 1464, 'ま': 1051, 'み': -2082, 'む': -882, 'め': -5046, 'も': 4169, 'ゃ': -2666, 'や': 2795, 'ょ': -1544, 'よ': 3351, 'ら': -2922, 'り': -9726, 'る': -14896, 'れ': -2613, 'ろ': -4570, 'わ': -1783, 'を': 13150, 'ん': -2352, 'カ': 2145, 'コ': 1789, 'セ': 1287, 'ッ': -724, 'ト': -403, 'メ': -1635, 'ラ': -881, 'リ': -541, 'ル': -856, 'ン': -3637, '・': -4371, 'ー': -11870, '一': -2069, '中': 2210, '予': 782, '事': -190, '井': -1768, '人': 1036, '以': 544, '会': 950, '体': -1286, '作': 530, '側': 4292, '先': 601, '党': -2006, '共': -1212, '内': 584, '円': 788, '初': 1347, '前': 1623, '副': 3879, '力': -302, '動': -740, '務': -2715, '化': 776, '区': 4517, '協': 1013, '参': 1555, '合': -1834, '和': -681, '員': -910, '器': -851, '回': 1500, '国': -619, '園': -1200, '地': 866, '場': -1410, '塁': -2094, '士': -1413, '多': 1067, '大': 571, '子': -4802, '学': -1397, '定': -1057, '寺': -809, '小': 1910, '屋': -1328, '山': -1500, '島': -2056, '川': -2667, '市': 2771, '年': 374, '庁': -4556, '後': 456, '性': 553, '感': 916, '所': -1566, '支': 856, '改': 787, '政': 2182, '教': 704, '文': 522, '方': -856, '日': 1798, '時': 1829, '最': 845, '月': -9066, '木': -485, '来': -442, '校': -360, '業': -1043, '氏': 5388, '民': -2716, '気': -910, '沢': -939, '済': -543, '物': -735, '率': 672, '球': -1267, '生': -1286, '産': -1101, '田': -2900, '町': 1826, '的': 2586, '目': 922, '省': -3485, '県': 2997, '空': -867, '立': -2112, '第': 788, '米': 2937, '系': 786, '約': 2171, '経': 1146, '統': -1169, '総': 940, '線': -994, '署': 749, '者': 2145, '能': -730, '般': -852, '行': -792, '規': 792, '警': -1184, '議': -244, '谷': -1000, '賞': 730, '車': -1481, '軍': 1158, '輪': -1433, '込': -3370, '近': 929, '道': -1291, '選': 2596, '郎': -4866, '都': 1192, '野': -1100, '銀': -2213, '長': 357, '間': -2344, '院': -2297, '際': -2604, '電': -878, '領': -1659, '題': -792, '館': -1984, '首': 1749, '高': 2120};\n  this.UW5__ = {'1': -514, '，': 465, '．': -299, 'E2': -32768, '］': -2762, '、': 465, '。': -299, '｢': 363, 'あ': 1655, 'い': 331, 'う': -503, 'え': 1199, 'お': 527, 'か': 647, 'が': -421, 'き': 1624, 'ぎ': 1971, 'く': 312, 'げ': -983, 'さ': -1537, 'し': -1371, 'す': -852, 'だ': -1186, 'ち': 1093, 'っ': 52, 'つ': 921, 'て': -18, 'で': -850, 'と': -127, 'ど': 1682, 'な': -787, 'に': -1224, 'の': -635, 'は': -578, 'べ': 1001, 'み': 502, 'め': 865, 'ゃ': 3350, 'ょ': 854, 'り': -208, 'る': 429, 'れ': 504, 'わ': 419, 'を': -1264, 'ん': 327, 'イ': 241, 'ル': 451, 'ン': -343, '中': -871, '京': 722, '会': -1153, '党': -654, '務': 3519, '区': -901, '告': 848, '員': 2104, '大': -1296, '学': -548, '定': 1785, '嵐': -1304, '市': -2991, '席': 921, '年': 1763, '思': 872, '所': -814, '挙': 1618, '新': -1682, '日': 218, '月': -4353, '査': 932, '格': 1356, '機': -1508, '氏': -1347, '田': 240, '町': -3912, '的': -3149, '相': 1319, '省': -1052, '県': -4003, '研': -997, '社': -278, '空': -813, '統': 1955, '者': -2233, '表': 663, '語': -1073, '議': 1219, '選': -1018, '郎': -368, '長': 786, '間': 1191, '題': 2368, '館': -689};\n  this.UW6__ = {'1': -270, '，': 227, '．': 808, 'E1': 306, '、': 227, '。': 808, 'あ': -307, 'う': 189, 'か': 241, 'が': -73, 'く': -121, 'こ': -200, 'じ': 1782, 'す': 383, 'た': -428, 'っ': 573, 'て': -1014, 'で': 101, 'と': -105, 'な': -253, 'に': -149, 'の': -417, 'は': -236, 'も': -206, 'り': 187, 'る': -135, 'を': 195, 'ル': -673, 'ン': -496, '一': -277, '中': 201, '件': -800, '会': 624, '前': 302, '区': 1792, '員': -1212, '委': 798, '学': -960, '市': 887, '広': -695, '後': 535, '業': -697, '相': 753, '社': -507, '福': 974, '空': -822, '者': 1811, '連': 463, '郎': 1082};\n\n  return this;\n};\n\nutil.inherits(TokenizerJa, Tokenizer);\n\n\n/**\n * @param {string} str\n * @return {string}\n * @private\n */\nTokenizerJa.prototype.ctype_ = function(str) {\n  for (var i = 0, length = this.chartype_.length; i < length; i++) {\n    if (str.match(this.chartype_[i][0])) {\n      return this.chartype_[i][1];\n    }\n  }\n  return 'O';\n};\n\n\n/**\n * @param {string} v\n * @return {number}\n * @private\n */\nTokenizerJa.prototype.ts_ = function(v) {\n  if (v) { return v; }\n  return 0;\n};\n\n\n/**\n * Remove punctuations signs from tokens.\n *\n * @param {Array.<string>} tokens An array of tokens.\n * @return {Array.<string>} An array of tokens.\n * @private\n */\nTokenizerJa.prototype.removePuncTokens = function(tokens) {\n  return tokens\n      .map(function(token) {\n        return token.replace(/[＿－・，、；：！？．。（）［］｛｝｢｣＠＊＼／＆＃％｀＾＋＜＝＞｜～≪≫─＄＂_\\-･,､;:!?.｡()[\\]{}「」@*\\/&#%`^+<=>|~«»$\"\\s]+/g, '');\n      })\n      .filter(function(token) {\n        return token != '';\n      });\n};\n\n\n/**\n * @param {string} text\n * @return {Array.<string>}\n */\nTokenizerJa.prototype.tokenize = function(text) {\n  if (text == null || text == undefined || text == '') {\n    return [];\n  }\n  text = normalize(text);\n  var result = [];\n  var seg = ['B3', 'B2', 'B1'];\n  var ctype = ['O', 'O', 'O'];\n  var o = text.split('');\n  var i;\n  var length;\n  for (i = 0, length = o.length; i < length; ++i) {\n    seg.push(o[i]);\n    ctype.push(this.ctype_(o[i]));\n  }\n  seg.push('E1');\n  seg.push('E2');\n  seg.push('E3');\n  ctype.push('O');\n  ctype.push('O');\n  ctype.push('O');\n  var word = seg[3];\n  var p1 = 'U';\n  var p2 = 'U';\n  var p3 = 'U';\n  for (i = 4, length = seg.length - 3; i < length; ++i) {\n    var score = this.BIAS__;\n    var w1 = seg[i - 3];\n    var w2 = seg[i - 2];\n    var w3 = seg[i - 1];\n    var w4 = seg[i];\n    var w5 = seg[i + 1];\n    var w6 = seg[i + 2];\n    var c1 = ctype[i - 3];\n    var c2 = ctype[i - 2];\n    var c3 = ctype[i - 1];\n    var c4 = ctype[i];\n    var c5 = ctype[i + 1];\n    var c6 = ctype[i + 2];\n    score += this.ts_(this.UP1__[p1]);\n    score += this.ts_(this.UP2__[p2]);\n    score += this.ts_(this.UP3__[p3]);\n    score += this.ts_(this.BP1__[p1 + p2]);\n    score += this.ts_(this.BP2__[p2 + p3]);\n    score += this.ts_(this.UW1__[w1]);\n    score += this.ts_(this.UW2__[w2]);\n    score += this.ts_(this.UW3__[w3]);\n    score += this.ts_(this.UW4__[w4]);\n    score += this.ts_(this.UW5__[w5]);\n    score += this.ts_(this.UW6__[w6]);\n    score += this.ts_(this.BW1__[w2 + w3]);\n    score += this.ts_(this.BW2__[w3 + w4]);\n    score += this.ts_(this.BW3__[w4 + w5]);\n    score += this.ts_(this.TW1__[w1 + w2 + w3]);\n    score += this.ts_(this.TW2__[w2 + w3 + w4]);\n    score += this.ts_(this.TW3__[w3 + w4 + w5]);\n    score += this.ts_(this.TW4__[w4 + w5 + w6]);\n    score += this.ts_(this.UC1__[c1]);\n    score += this.ts_(this.UC2__[c2]);\n    score += this.ts_(this.UC3__[c3]);\n    score += this.ts_(this.UC4__[c4]);\n    score += this.ts_(this.UC5__[c5]);\n    score += this.ts_(this.UC6__[c6]);\n    score += this.ts_(this.BC1__[c2 + c3]);\n    score += this.ts_(this.BC2__[c3 + c4]);\n    score += this.ts_(this.BC3__[c4 + c5]);\n    score += this.ts_(this.TC1__[c1 + c2 + c3]);\n    score += this.ts_(this.TC2__[c2 + c3 + c4]);\n    score += this.ts_(this.TC3__[c3 + c4 + c5]);\n    score += this.ts_(this.TC4__[c4 + c5 + c6]);\n    //score += this.ts_(this.TC5__[c4 + c5 + c6]);\n    score += this.ts_(this.UQ1__[p1 + c1]);\n    score += this.ts_(this.UQ2__[p2 + c2]);\n    score += this.ts_(this.UQ3__[p3 + c3]);\n    score += this.ts_(this.BQ1__[p2 + c2 + c3]);\n    score += this.ts_(this.BQ2__[p2 + c3 + c4]);\n    score += this.ts_(this.BQ3__[p3 + c2 + c3]);\n    score += this.ts_(this.BQ4__[p3 + c3 + c4]);\n    score += this.ts_(this.TQ1__[p2 + c1 + c2 + c3]);\n    score += this.ts_(this.TQ2__[p2 + c2 + c3 + c4]);\n    score += this.ts_(this.TQ3__[p3 + c1 + c2 + c3]);\n    score += this.ts_(this.TQ4__[p3 + c2 + c3 + c4]);\n    var p = 'O';\n    if (score > 0) {\n      result.push(word);\n      word = '';\n      p = 'B';\n    }\n    p1 = p2;\n    p2 = p3;\n    p3 = p;\n    word += seg[i];\n  }\n  result.push(word);\n\n  result = this.removePuncTokens(result);\n\n  return result;\n};\n\nmodule.exports = TokenizerJa;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/normalizers/normalizer_ja.js":"/*\n Copyright (c) 2012, Guillaume Marty\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n\n/**\n * Normalize Japanese inputs and expose function to perform several conversions.\n *\n * Note: The space character is treated like a roman character as it usually\n *   has the same width as them in Japanese texts.\n *\n * \\@todo Replace characters range from ㈠ to ㉃, ㊀ to ㊰ and ㇰ to ㇿ.\n * \\@todo Lazy initializations of conversionTables and converters.\n * \\@todo Would fixHalfwidthKana be useful?\n *\n * Descriptions of functions exposed:\n * normalizeJapanese 「全角」英字・数字を「半角」、「半角」記・カタカナを「全角」に変換\n * converters.fullwidthToHalfwidth.alphabet    「全角」英字を「半角」に変換\n * converters.halfwidthToFullwidth.alphabet    「半角」英字を「全角」に変換\n * converters.fullwidthToHalfwidth.numbers     「全角」数字を「半角」に変換\n * converters.halfwidthToFullwidth.numbers     「半角」数字を「全角」に変換 「全角」スペースを「半角」\n * converters.fullwidthToHalfwidth.punctuation 「全角」記号を「半角」に変換 「半角」スペースを「全角」\n * converters.halfwidthToFullwidth.punctuation 「半角」記号を「全角」に変換\n * converters.fullwidthToHalfwidth.katakana    「全角カタカナ」を「半角カタカナ」に変換\n * converters.halfwidthToFullwidth.katakana    「半角カタカナ」を「全角カタカナ」に変換\n * converters.hiraganaToKatakana               「カタカナ」を「ひらがな」に変換\n * converters.katakanaToHiragana               「ひらがな」を「カタカナ」に変換\n */\n\nvar flip = require('../util/utils.js').flip;\nvar merge = require('../util/utils.js').merge;\nvar replacer = require('../util/utils').replacer;\n\n// From http://fernweh.jp/b/mb_convert_kana_js/\nvar conversionTables = {\n  fullwidthToHalfwidth: {\n    alphabet: {\n      'ａ': 'a',\n      'ｂ': 'b',\n      'ｃ': 'c',\n      'ｄ': 'd',\n      'ｅ': 'e',\n      'ｆ': 'f',\n      'ｇ': 'g',\n      'ｈ': 'h',\n      'ｉ': 'i',\n      'ｊ': 'j',\n      'ｋ': 'k',\n      'ｌ': 'l',\n      'ｍ': 'm',\n      'ｎ': 'n',\n      'ｏ': 'o',\n      'ｐ': 'p',\n      'ｑ': 'q',\n      'ｒ': 'r',\n      'ｓ': 's',\n      'ｔ': 't',\n      'ｕ': 'u',\n      'ｖ': 'v',\n      'ｗ': 'w',\n      'ｘ': 'x',\n      'ｙ': 'y',\n      'ｚ': 'z',\n      'Ａ': 'A',\n      'Ｂ': 'B',\n      'Ｃ': 'C',\n      'Ｄ': 'D',\n      'Ｅ': 'E',\n      'Ｆ': 'F',\n      'Ｇ': 'G',\n      'Ｈ': 'H',\n      'Ｉ': 'I',\n      'Ｊ': 'J',\n      'Ｋ': 'K',\n      'Ｌ': 'L',\n      'Ｍ': 'M',\n      'Ｎ': 'N',\n      'Ｏ': 'O',\n      'Ｐ': 'P',\n      'Ｑ': 'Q',\n      'Ｒ': 'R',\n      'Ｓ': 'S',\n      'Ｔ': 'T',\n      'Ｕ': 'U',\n      'Ｖ': 'V',\n      'Ｗ': 'W',\n      'Ｘ': 'X',\n      'Ｙ': 'Y',\n      'Ｚ': 'Z',\n      '　': ' ' // Fullwidth space\n    },\n\n    numbers: {\n      '０': '0',\n      '１': '1',\n      '２': '2',\n      '３': '3',\n      '４': '4',\n      '５': '5',\n      '６': '6',\n      '７': '7',\n      '８': '8',\n      '９': '9'\n    },\n\n    symbol: {\n      '＿': '_',\n      '－': '-',\n      '，': ',',\n      '；': ';',\n      '：': ':',\n      '！': '!',\n      '？': '?',\n      '．': '.',\n      '（': '(',\n      '）': ')',\n      '［': '[',\n      '］': ']',\n      '｛': '{',\n      '｝': '}',\n      '＠': '@',\n      '＊': '*',\n      '＼': '\\\\',\n      '／': '/',\n      '＆': '&',\n      '＃': '#',\n      '％': '%',\n      '｀': '`',\n      '＾': '^',\n      '＋': '+',\n      '＜': '<',\n      '＝': '=',\n      '＞': '>',\n      '｜': '|',\n      // Never converted: '～': '~',\n      '≪': '«',\n      '≫': '»',\n      '─': '-',\n      '＄': '$',\n      '＂': '\"'\n    },\n\n    purePunctuation: {\n      '、': '､',\n      '。': '｡',\n      '・': '･',\n      '「': '｢',\n      '」': '｣'\n    },\n\n    punctuation: {},\n\n    katakana: {\n      '゛': 'ﾞ',\n      '゜': 'ﾟ',\n      'ー': 'ｰ',\n\n      'ヴ': 'ｳﾞ',\n      'ガ': 'ｶﾞ',\n      'ギ': 'ｷﾞ',\n      'グ': 'ｸﾞ',\n      'ゲ': 'ｹﾞ',\n      'ゴ': 'ｺﾞ',\n      'ザ': 'ｻﾞ',\n      'ジ': 'ｼﾞ',\n      'ズ': 'ｽﾞ',\n      'ゼ': 'ｾﾞ',\n      'ゾ': 'ｿﾞ',\n      'ダ': 'ﾀﾞ',\n      'ヂ': 'ﾁﾞ',\n      'ヅ': 'ﾂﾞ',\n      'デ': 'ﾃﾞ',\n      'ド': 'ﾄﾞ',\n      'バ': 'ﾊﾞ',\n      'パ': 'ﾊﾟ',\n      'ビ': 'ﾋﾞ',\n      'ピ': 'ﾋﾟ',\n      'ブ': 'ﾌﾞ',\n      'プ': 'ﾌﾟ',\n      'ベ': 'ﾍﾞ',\n      'ペ': 'ﾍﾟ',\n      'ボ': 'ﾎﾞ',\n      'ポ': 'ﾎﾟ',\n\n      'ァ': 'ｧ',\n      'ア': 'ｱ',\n      'ィ': 'ｨ',\n      'イ': 'ｲ',\n      'ゥ': 'ｩ',\n      'ウ': 'ｳ',\n      'ェ': 'ｪ',\n      'エ': 'ｴ',\n      'ォ': 'ｫ',\n      'オ': 'ｵ',\n      'カ': 'ｶ',\n      'キ': 'ｷ',\n      'ク': 'ｸ',\n      'ケ': 'ｹ',\n      'コ': 'ｺ',\n      'サ': 'ｻ',\n      'シ': 'ｼ',\n      'ス': 'ｽ',\n      'セ': 'ｾ',\n      'ソ': 'ｿ',\n      'タ': 'ﾀ',\n      'チ': 'ﾁ',\n      'ッ': 'ｯ',\n      'ツ': 'ﾂ',\n      'テ': 'ﾃ',\n      'ト': 'ﾄ',\n      'ナ': 'ﾅ',\n      'ニ': 'ﾆ',\n      'ヌ': 'ﾇ',\n      'ネ': 'ﾈ',\n      'ノ': 'ﾉ',\n      'ハ': 'ﾊ',\n      'ヒ': 'ﾋ',\n      'フ': 'ﾌ',\n      'ヘ': 'ﾍ',\n      'ホ': 'ﾎ',\n      'マ': 'ﾏ',\n      'ミ': 'ﾐ',\n      'ム': 'ﾑ',\n      'メ': 'ﾒ',\n      'モ': 'ﾓ',\n      'ャ': 'ｬ',\n      'ヤ': 'ﾔ',\n      'ュ': 'ｭ',\n      'ユ': 'ﾕ',\n      'ョ': 'ｮ',\n      'ヨ': 'ﾖ',\n      'ラ': 'ﾗ',\n      'リ': 'ﾘ',\n      'ル': 'ﾙ',\n      'レ': 'ﾚ',\n      'ロ': 'ﾛ',\n      'ワ': 'ﾜ',\n      'ヲ': 'ｦ',\n      'ン': 'ﾝ'\n    }\n  },\n\n  halfwidthToFullwidth: {}\n};\n\nvar fixFullwidthKana = {\n  'ゝ゛': 'ゞ',\n  'ヽ゛': 'ヾ',\n\n  'う゛': 'ゔ',\n  'か゛': 'が',\n  'き゛': 'ぎ',\n  'く゛': 'ぐ',\n  'け゛': 'げ',\n  'こ゛': 'ご',\n  'さ゛': 'ざ',\n  'し゛': 'じ',\n  'す゛': 'ず',\n  'せ゛': 'ぜ',\n  'そ゛': 'ぞ',\n  'た゛': 'だ',\n  'ち゛': 'ぢ',\n  'つ゛': 'づ',\n  'て゛': 'で',\n  'と゛': 'ど',\n  'は゛': 'ば',\n  'は゜': 'ぱ',\n  'ひ゛': 'び',\n  'ひ゜': 'ぴ',\n  'ふ゛': 'ぶ',\n  'ふ゜': 'ぷ',\n  'へ゛': 'べ',\n  'へ゜': 'ぺ',\n  'ほ゛': 'ぼ',\n  'ほ゜': 'ぽ',\n  'っな': 'んな',\n  'っに': 'んに',\n  'っぬ': 'んぬ',\n  'っね': 'んね',\n  'っの': 'んの',\n\n  'ウ゛': 'ヴ',\n  'カ゛': 'ガ',\n  'キ゛': 'ギ',\n  'ク゛': 'グ',\n  'ケ゛': 'ゲ',\n  'コ゛': 'ゴ',\n  'サ゛': 'ザ',\n  'シ゛': 'ジ',\n  'ス゛': 'ズ',\n  'セ゛': 'ゼ',\n  'ソ゛': 'ゾ',\n  'タ゛': 'ダ',\n  'チ゛': 'ヂ',\n  'ツ゛': 'ヅ',\n  'テ゛': 'デ',\n  'ト゛': 'ド',\n  'ハ゛': 'バ',\n  'ハ゜': 'パ',\n  'ヒ゛': 'ビ',\n  'ヒ゜': 'ピ',\n  'フ゛': 'ブ',\n  'フ゜': 'プ',\n  'ヘ゛': 'ベ',\n  'ヘ゜': 'ペ',\n  'ホ゛': 'ボ',\n  'ホ゜': 'ポ',\n  'ッナ': 'ンナ',\n  'ッニ': 'ンニ',\n  'ッヌ': 'ンヌ',\n  'ッネ': 'ンネ',\n  'ッノ': 'ンノ'\n};\n\nvar fixCompositeSymbolsTable = {\n  '㋀': '1月',\n  '㋁': '2月',\n  '㋂': '3月',\n  '㋃': '4月',\n  '㋄': '5月',\n  '㋅': '6月',\n  '㋆': '7月',\n  '㋇': '8月',\n  '㋈': '9月',\n  '㋉': '10月',\n  '㋊': '11月',\n  '㋋': '12月',\n\n  '㏠': '1日',\n  '㏡': '2日',\n  '㏢': '3日',\n  '㏣': '4日',\n  '㏤': '5日',\n  '㏥': '6日',\n  '㏦': '7日',\n  '㏧': '8日',\n  '㏨': '9日',\n  '㏩': '10日',\n  '㏪': '11日',\n  '㏫': '12日',\n  '㏬': '13日',\n  '㏭': '14日',\n  '㏮': '15日',\n  '㏯': '16日',\n  '㏰': '17日',\n  '㏱': '18日',\n  '㏲': '19日',\n  '㏳': '20日',\n  '㏴': '21日',\n  '㏵': '22日',\n  '㏶': '23日',\n  '㏷': '24日',\n  '㏸': '25日',\n  '㏹': '26日',\n  '㏺': '27日',\n  '㏻': '28日',\n  '㏼': '29日',\n  '㏽': '30日',\n  '㏾': '31日',\n\n  '㍘': '0点',\n  '㍙': '1点',\n  '㍚': '2点',\n  '㍛': '3点',\n  '㍜': '4点',\n  '㍝': '5点',\n  '㍞': '6点',\n  '㍟': '7点',\n  '㍠': '8点',\n  '㍡': '9点',\n  '㍢': '10点',\n  '㍣': '11点',\n  '㍤': '12点',\n  '㍥': '13点',\n  '㍦': '14点',\n  '㍧': '15点',\n  '㍨': '16点',\n  '㍩': '17点',\n  '㍪': '18点',\n  '㍫': '19点',\n  '㍬': '20点',\n  '㍭': '21点',\n  '㍮': '22点',\n  '㍯': '23点',\n  '㍰': '24点',\n\n  '㍻': '平成',\n  '㍼': '昭和',\n  '㍽': '大正',\n  '㍾': '明治',\n  '㍿': '株式会社',\n\n  '㌀': 'アパート',\n  '㌁': 'アルファ',\n  '㌂': 'アンペア',\n  '㌃': 'アール',\n  '㌄': 'イニング',\n  '㌅': 'インチ',\n  '㌆': 'ウオン',\n  '㌇': 'エスクード',\n  '㌈': 'エーカー',\n  '㌉': 'オンス',\n  '㌊': 'オーム',\n  '㌋': 'カイリ', //海里\n  '㌌': 'カラット',\n  '㌍': 'カロリー',\n  '㌎': 'ガロン',\n  '㌏': 'ガンマ',\n  '㌐': 'ギガ',\n  '㌑': 'ギニー',\n  '㌒': 'キュリー',\n  '㌓': 'ギルダー',\n  '㌔': 'キロ',\n  '㌕': 'キログラム',\n  '㌖': 'キロメートル',\n  '㌗': 'キロワット',\n  '㌘': 'グラム',\n  '㌙': 'グラムトン',\n  '㌚': 'クルゼイロ',\n  '㌛': 'クローネ',\n  '㌜': 'ケース',\n  '㌝': 'コルナ',\n  '㌞': 'コーポ',\n  '㌟': 'サイクル',\n  '㌠': 'サンチーム',\n  '㌡': 'シリング',\n  '㌢': 'センチ',\n  '㌣': 'セント',\n  '㌤': 'ダース',\n  '㌥': 'デシ',\n  '㌦': 'ドル',\n  '㌧': 'トン',\n  '㌨': 'ナノ',\n  '㌩': 'ノット',\n  '㌪': 'ハイツ',\n  '㌫': 'パーセント',\n  '㌬': 'パーツ',\n  '㌭': 'バーレル',\n  '㌮': 'ピアストル',\n  '㌯': 'ピクル',\n  '㌰': 'ピコ',\n  '㌱': 'ビル',\n  '㌲': 'ファラッド',\n  '㌳': 'フィート',\n  '㌴': 'ブッシェル',\n  '㌵': 'フラン',\n  '㌶': 'ヘクタール',\n  '㌷': 'ペソ',\n  '㌸': 'ペニヒ',\n  '㌹': 'ヘルツ',\n  '㌺': 'ペンス',\n  '㌻': 'ページ',\n  '㌼': 'ベータ',\n  '㌽': 'ポイント',\n  '㌾': 'ボルト',\n  '㌿': 'ホン',\n  '㍀': 'ポンド',\n  '㍁': 'ホール',\n  '㍂': 'ホーン',\n  '㍃': 'マイクロ',\n  '㍄': 'マイル',\n  '㍅': 'マッハ',\n  '㍆': 'マルク',\n  '㍇': 'マンション',\n  '㍈': 'ミクロン',\n  '㍉': 'ミリ',\n  '㍊': 'ミリバール',\n  '㍋': 'メガ',\n  '㍌': 'メガトン',\n  '㍍': 'メートル',\n  '㍎': 'ヤード',\n  '㍏': 'ヤール',\n  '㍐': 'ユアン',\n  '㍑': 'リットル',\n  '㍒': 'リラ',\n  '㍓': 'ルピー',\n  '㍔': 'ルーブル',\n  '㍕': 'レム',\n  '㍖': 'レントゲン',\n  '㍗': 'ワット'\n};\n\n// punctuation is pure_punctuation\nconversionTables.fullwidthToHalfwidth.punctuation = merge(\n    conversionTables.fullwidthToHalfwidth.symbol,\n    conversionTables.fullwidthToHalfwidth.purePunctuation\n)\n\n// Fill in the conversion tables with the flipped tables.\nconversionTables.halfwidthToFullwidth.alphabet = flip(conversionTables.fullwidthToHalfwidth.alphabet);\nconversionTables.halfwidthToFullwidth.numbers = flip(conversionTables.fullwidthToHalfwidth.numbers);\nconversionTables.halfwidthToFullwidth.symbol = flip(conversionTables.fullwidthToHalfwidth.symbol);\nconversionTables.halfwidthToFullwidth.purePunctuation = flip(conversionTables.fullwidthToHalfwidth.purePunctuation);\nconversionTables.halfwidthToFullwidth.punctuation = flip(conversionTables.fullwidthToHalfwidth.punctuation);\nconversionTables.halfwidthToFullwidth.katakana = flip(conversionTables.fullwidthToHalfwidth.katakana);\n\n// Build the normalization table.\nconversionTables.normalize = merge(\n    conversionTables.fullwidthToHalfwidth.alphabet,\n    conversionTables.fullwidthToHalfwidth.numbers,\n    conversionTables.fullwidthToHalfwidth.symbol,\n    conversionTables.halfwidthToFullwidth.purePunctuation,\n    conversionTables.halfwidthToFullwidth.katakana\n    );\n\nvar converters = {\n  fullwidthToHalfwidth: {\n    alphabet: replacer(conversionTables.fullwidthToHalfwidth.alphabet),\n    numbers: replacer(conversionTables.fullwidthToHalfwidth.numbers),\n    symbol: replacer(conversionTables.fullwidthToHalfwidth.symbol),\n    purePunctuation: replacer(conversionTables.fullwidthToHalfwidth.purePunctuation),\n    punctuation: replacer(conversionTables.fullwidthToHalfwidth.punctuation),\n    katakana: replacer(conversionTables.fullwidthToHalfwidth.katakana)\n  },\n\n  halfwidthToFullwidth: {\n    alphabet: replacer(conversionTables.halfwidthToFullwidth.alphabet),\n    numbers: replacer(conversionTables.halfwidthToFullwidth.numbers),\n    symbol: replacer(conversionTables.halfwidthToFullwidth.symbol),\n    purePunctuation: replacer(conversionTables.halfwidthToFullwidth.purePunctuation),\n    punctuation: replacer(conversionTables.halfwidthToFullwidth.punctuation),\n    katakana: replacer(conversionTables.halfwidthToFullwidth.katakana)\n  },\n\n  fixFullwidthKana: replacer(fixFullwidthKana),\n  normalize: replacer(conversionTables.normalize)\n};\n\nvar fixCompositeSymbols = replacer(fixCompositeSymbolsTable);\n\n\n/**\n * Convert hiragana to fullwidth katakana.\n * According to http://jsperf.com/converting-japanese, these implementations are\n * faster than using lookup tables.\n *\n * @param {string} str A string.\n * @return {string} A string not containing hiragana.\n */\nconverters.hiraganaToKatakana = function(str) {\n  str = converters.halfwidthToFullwidth.katakana(str);\n  str = converters.fixFullwidthKana(str);\n\n  str = str.replace(/ゝ/g, 'ヽ');\n  str = str.replace(/ゞ/g, 'ヾ');\n  //str = str.replace(/?/g, '𛀀'); // Letter archaic E\n\n  str = str.replace(/[ぁ-ゖ]/g, function(str) {\n    return String.fromCharCode(str.charCodeAt(0) + 96);\n  });\n\n  return str;\n};\n\n\n/**\n * Convert katakana to hiragana.\n *\n * @param {string} str A string.\n * @return {string} A string not containing katakana.\n */\nconverters.katakanaToHiragana = function(str) {\n  str = converters.halfwidthToFullwidth.katakana(str);\n  str = converters.fixFullwidthKana(str);\n\n  str = str.replace(/ヽ/g, 'ゝ');\n  str = str.replace(/ヾ/g, 'ゞ');\n  //str = str.replace(/?/g, '𛀁'); // Letter archaic E\n\n  str = str.replace(/[ァ-ヶ]/g, function(str) {\n    return String.fromCharCode(str.charCodeAt(0) - 96);\n  });\n\n  return str;\n};\n\n\n/**\n * Fix kana and apply the following processes;\n * * Replace repeat characters\n * * Alphabet to halfwidth\n * * Numbers to halfwidth\n * * Punctuation to fullwidth\n * * Katakana to fullwidth\n * * Fix fullwidth kana\n * * Replace composite symbols\n *\n * @param {string} str\n * @return {string}\n */\nvar normalize_ja = function(str) {\n  // Replace repeat characters.\n  str = str\n    .replace(/(..)々々/g, '$1$1')\n    .replace(/(.)々/g, '$1$1');\n\n  str = converters.normalize(str);\n  str = converters.fixFullwidthKana(str);\n\n  // Replace composite symbols.\n  str = fixCompositeSymbols(str);\n\n  return str;\n};\n\nexports.normalize_ja = normalize_ja;\nexports.converters = converters;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/utils.js":"/*\r\n Copyright (c) 2012, Guillaume Marty\r\n\r\n Permission is hereby granted, free of charge, to any person obtaining a copy\r\n of this software and associated documentation files (the \"Software\"), to deal\r\n in the Software without restriction, including without limitation the rights\r\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\n copies of the Software, and to permit persons to whom the Software is\r\n furnished to do so, subject to the following conditions:\r\n\r\n The above copyright notice and this permission notice shall be included in\r\n all copies or substantial portions of the Software.\r\n\r\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\r\n THE SOFTWARE.\r\n */\r\n\r\n\r\n/**\r\n * Generate a replacing function given a table of patterns. Inspired by:\r\n * http://code.google.com/p/jslibs/wiki/JavascriptTips#String_converter\r\n * The order of elements is significant. Longer elements should be listed first.\r\n * @see Speed test http://jsperf.com/build-a-regexp-table\r\n *\r\n * @param {Object.<string, string>} translationTable The translation table of key value.\r\n * @return {function(string): string} A translating function.\r\n */\r\nfunction replacer(translationTable) {\r\n  /**\r\n   * An array of translationTable keys.\r\n   * @type {Array.<string>}\r\n   */\r\n  var pattern = [];\r\n\r\n  /**\r\n   * The regular expression doing the replacement job.\r\n   * @type {RegExp}\r\n   */\r\n  var regExp;\r\n\r\n  /**\r\n   * Used to iterate over translationTable.\r\n   * @type {string}\r\n   */\r\n  var key;\r\n\r\n  for (key in translationTable) {\r\n    // Escaping regexp special chars.\r\n    // @see Speed test for type casting to string http://jsperf.com/string-type-casting/2\r\n    // @see http://closure-library.googlecode.com/svn/docs/closure_goog_string_string.js.source.html#line956\r\n    key = ('' + key).replace(/([-()\\[\\]{}+?*.$\\^|,:#<!\\\\\\/])/g, '\\\\$1').\r\n      replace(/\\x08/g, '\\\\x08');\r\n\r\n    pattern.push(key);\r\n  }\r\n\r\n  regExp = new RegExp(pattern.join('|'), 'g');\r\n\r\n  /**\r\n   * @param {string} str Input string.\r\n   * @return {string} The string replaced.\r\n   */\r\n  return function(str) {\r\n    return str.replace(regExp, function(str) {\r\n      return translationTable[str];\r\n    });\r\n  };\r\n}\r\n\r\n\r\n/**\r\n * Exchanges all keys with their associated values in an object.\r\n *\r\n * @param {Object.<string, string>} obj An object of strings.\r\n * @return {Object.<string, string>} An object of strings.\r\n */\r\nfunction flip(obj) {\r\n  var newObj = Object.create(null),\r\n      key;\r\n\r\n  for (key in obj) {\r\n    newObj[obj[key]] = key;\r\n  }\r\n\r\n  return newObj;\r\n}\r\n\r\n\r\n/**\r\n * Merge several objects. Properties from earlier objects are overwritten by\r\n * laters's in case of conflict.\r\n *\r\n * @param {...Object.<string, string>} var_args One or more objects of strings.\r\n * @return {!Object.<string, string>} An object of strings.\r\n */\r\nfunction merge(var_args) {\r\n  var args = [].slice.call(arguments),\r\n      newObj = Object.create(null),\r\n      id = 0, key;\r\n\r\n  while (args[id]) {\r\n    for (key in args[id]) {\r\n      newObj[key] = args[id][key];\r\n    }\r\n\r\n    id++;\r\n  }\r\n\r\n  return newObj;\r\n}\r\n\r\nexports.replacer = replacer;\r\nexports.flip = flip;\r\nexports.merge = merge;\r\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/stopwords_ja.js":"// Original copyright:\n/*\n Licensed to the Apache Software Foundation (ASF) under one or more\n contributor license agreements.  See the NOTICE file distributed with\n this work for additional information regarding copyright ownership.\n The ASF licenses this file to You under the Apache License, Version 2.0\n the \"License\"); you may not use this file except in compliance with\n the License.  You may obtain a copy of the License at\n\n http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n*/\n\n// This version:\n/*\nCopyright (c) 2012, Guillaume Marty\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n// a list of commonly used words that have little meaning and can be excluded\n// from analysis.\n// Original location:\n// http://svn.apache.org/repos/asf/lucene/dev/trunk/lucene/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/stopwords.txt\nvar words = ['の', 'に', 'は', 'を', 'た', 'が', 'で', 'て', 'と', 'し', 'れ', 'さ',\n  'ある', 'いる', 'も', 'する', 'から', 'な', 'こと', 'として', 'い', 'や', 'れる',\n  'など', 'なっ', 'ない', 'この', 'ため', 'その', 'あっ', 'よう', 'また', 'もの',\n  'という', 'あり', 'まで', 'られ', 'なる', 'へ', 'か', 'だ', 'これ', 'によって',\n  'により', 'おり', 'より', 'による', 'ず', 'なり', 'られる', 'において', 'ば', 'なかっ',\n  'なく', 'しかし', 'について', 'せ', 'だっ', 'その後', 'できる', 'それ', 'う', 'ので',\n  'なお', 'のみ', 'でき', 'き', 'つ', 'における', 'および', 'いう', 'さらに', 'でも',\n  'ら', 'たり', 'その他', 'に関する', 'たち', 'ます', 'ん', 'なら', 'に対して', '特に',\n  'せる', '及び', 'これら', 'とき', 'では', 'にて', 'ほか', 'ながら', 'うち', 'そして',\n  'とともに', 'ただし', 'かつて', 'それぞれ', 'または', 'お', 'ほど', 'ものの', 'に対する',\n  'ほとんど', 'と共に', 'といった', 'です', 'とも', 'ところ', 'ここ'];\n\n// tell the world about the noise words.\nmodule.exports = words;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/aggressive_tokenizer_nl.js":"/*\nCopyright (c) 2011, Chris Umbel, Martijn de Boer\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Tokenizer = require('./tokenizer'),\n    util = require('util');\n\nvar AggressiveTokenizer = function() {\n    Tokenizer.call(this);\n};\nutil.inherits(AggressiveTokenizer, Tokenizer);\n\nmodule.exports = AggressiveTokenizer;\n\nAggressiveTokenizer.prototype.tokenize = function(text) {\n    // break a string up into an array of tokens by anything non-word\n    return this.trim(text.split(/[^a-zA-Z0-9_']+/));\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/tokenizer_case.js":"/*\n Copyright (c) 2011, Chris Umbel, Alex Langberg\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n\nvar Tokenizer = require('./tokenizer'),\n  util = require('util'),\n  CaseTokenizer = function() {\n    Tokenizer.call(this);\n  };\n\nutil.inherits(CaseTokenizer, Tokenizer);\n\nCaseTokenizer.prototype.attach = function() {\n  var self = this;\n\n  String.prototype.tokenize = function(preserveApostrophe) {\n    return self.tokenize(this, preserveApostrophe);\n  }\n};\n\n// Idea from Seagull: http://stackoverflow.com/a/26482650\nCaseTokenizer.prototype.tokenize = function(text, preserveApostrophe) {\n  var whitelist = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'];\n  var lower = text.toLowerCase();\n  var upper = text.toUpperCase();\n  var result = '';\n  var i;\n\n  for (i = 0; i < lower.length; ++i) {\n    if (lower[i] !== upper[i] || whitelist.indexOf(lower[i]) > -1 || (text[i] === '\\'' && preserveApostrophe)) {\n      result += text[i];\n    } else {\n      result += ' ';\n    }\n  }\n\n  return this.trim(result.replace(/\\s+/g, ' ').split(' '));\n};\n\nmodule.exports = CaseTokenizer;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/regexp_tokenizer.js":"/*\nCopyright (c) 2011, Rob Ellis, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Tokenizer = require('./tokenizer'),\n    util = require(\"util\"),\n    _ = require('underscore')._;\n\n// Base Class for RegExp Matching\nvar RegexpTokenizer = function(options) {\n    var options = options || {};\n    this._pattern = options.pattern || this._pattern;\n    this.discardEmpty = options.discardEmpty || true;\n\n    // Match and split on GAPS not the actual WORDS\n    this._gaps = options.gaps;\n    \n    if (this._gaps === undefined) {\n        this._gaps = true;\n    }\n};\n\nutil.inherits(RegexpTokenizer, Tokenizer);\n\nRegexpTokenizer.prototype.tokenize = function(s) {\n    var results;\n\n    if (this._gaps) {\n        results = s.split(this._pattern);\n        return (this.discardEmpty) ? _.without(results,'',' ') : results;\n    } else {\n        return s.match(this._pattern);\n    }\n};\n\nexports.RegexpTokenizer = RegexpTokenizer;\n\n/***\n * A tokenizer that divides a text into sequences of alphabetic and\n * non-alphabetic characters.  E.g.:\n *\n *      >>> WordTokenizer().tokenize(\"She said 'hello'.\")\n *      ['She', 'said', 'hello']\n * \n */\nvar WordTokenizer = function(options) {\n    this._pattern = /[^A-Za-zА-Яа-я0-9_]+/;\n    RegexpTokenizer.call(this,options)\n};\n\nutil.inherits(WordTokenizer, RegexpTokenizer);\nexports.WordTokenizer = WordTokenizer;\n\n/***\n * A tokenizer that divides a text into sequences of alphabetic and\n * non-alphabetic characters.  E.g.:\n *\n *      >>> WordPunctTokenizer().tokenize(\"She said 'hello'.\")\n *      [\"She\",\"said\",\"'\",\"hello\",\"'\",\".\"]\n * \n */\nvar WordPunctTokenizer = function(options) {\n    this._pattern = new RegExp(/(\\w+|[а-я0-9_]+|\\.|\\!|\\'|\\\"\")/i);\n    RegexpTokenizer.call(this,options)\n};\n\nutil.inherits(WordPunctTokenizer, RegexpTokenizer);\nexports.WordPunctTokenizer = WordPunctTokenizer;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/treebank_word_tokenizer.js":"/*\nCopyright (c) 2011, Rob Ellis, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Tokenizer = require('./tokenizer'),\n    util = require(\"util\"),\n    _ = require('underscore')._;\n\nvar contractions2 = [\n    /(.)('ll|'re|'ve|n't|'s|'m|'d)\\b/ig,\n    /\\b(can)(not)\\b/ig,\n    /\\b(D)('ye)\\b/ig,\n    /\\b(Gim)(me)\\b/ig,\n    /\\b(Gon)(na)\\b/ig,\n    /\\b(Got)(ta)\\b/ig,\n    /\\b(Lem)(me)\\b/ig,\n    /\\b(Mor)('n)\\b/ig,\n    /\\b(T)(is)\\b/ig,\n    /\\b(T)(was)\\b/ig,\n    /\\b(Wan)(na)\\b/ig];\n\nvar contractions3 = [\n    /\\b(Whad)(dd)(ya)\\b/ig,\n    /\\b(Wha)(t)(cha)\\b/ig\n];\n\nvar TreebankWordTokenizer = function() {\n};\n\nutil.inherits(TreebankWordTokenizer, Tokenizer);\n\nTreebankWordTokenizer.prototype.tokenize = function(text) {\n    contractions2.forEach(function(regexp) {\n\ttext = text.replace(regexp,\"$1 $2\");\n    });\n    \n    contractions3.forEach(function(regexp) {\n\ttext = text.replace(regexp,\"$1 $2 $3\");\n    });\n\n    // most punctuation\n    text = text.replace(/([^\\w\\.\\'\\-\\/\\+\\<\\>,&])/g, \" $1 \");\n\n    // commas if followed by space\n    text = text.replace(/(,\\s)/g, \" $1\");\n\n    // single quotes if followed by a space\n    text = text.replace(/('\\s)/g, \" $1\");\n\n    // periods before newline or end of string\n    text = text.replace(/\\. *(\\n|$)/g, \" . \");\n    \n    return  _.without(text.split(/\\s+/), '');\t\n};\n\nmodule.exports = TreebankWordTokenizer;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tokenizers/sentence_tokenizer.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar Tokenizer = require('./tokenizer'),\n    util = require('util');\n\nvar SentenceTokenizer = function() {\n    Tokenizer.call(this);\n};\nutil.inherits(SentenceTokenizer, Tokenizer);\n\nSentenceTokenizer.prototype.tokenize = function(text) {\n    // break string up in to sentences based on punctation and quotation marks\n    var tokens = text.match(/([\\\"\\'\\‘\\“\\'\\\"\\[\\(\\{\\⟨][^\\.\\?\\!]+[\\.\\?\\!][\\\"\\'\\’\\”\\'\\\"\\]\\)\\}\\⟩]|[^\\.\\?\\!]+[\\.\\?\\!])\\s?/g);\n\n    // remove unecessary white space\n    tokens = tokens.map(Function.prototype.call, String.prototype.trim);\n\n    return this.trim(tokens);\n};\n\nmodule.exports = SentenceTokenizer;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/classifiers/bayes_classifier.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar util = require('util'),\n    Classifier = require('./classifier'),\n    ApparatusBayesClassifier = require('apparatus').BayesClassifier;\n\nvar BayesClassifier = function(stemmer, smoothing) {\n    var abc = new ApparatusBayesClassifier();\n    if (smoothing && isFinite(smoothing)) {\n        abc = new ApparatusBayesClassifier(smoothing);\n    }\n    Classifier.call(this, abc, stemmer);\n};\n\nutil.inherits(BayesClassifier, Classifier);\n\nfunction restore(classifier, stemmer) {\n    classifier = Classifier.restore(classifier, stemmer);\n    classifier.__proto__ = BayesClassifier.prototype;\n    classifier.classifier = ApparatusBayesClassifier.restore(classifier.classifier);\n\n    return classifier;\n}\n\nfunction load(filename, stemmer, callback) {\n    Classifier.load(filename, function(err, classifier) {\n        if (err) {\n            return callback(err);\n        }\n        else {\n            callback(err, restore(classifier, stemmer));\n        }\n    });\n}\n\nBayesClassifier.restore = restore;\nBayesClassifier.load = load;\n\nmodule.exports = BayesClassifier;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/classifiers/classifier.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar PorterStemmer = require('../stemmers/porter_stemmer'),\nThreads = require('webworker-threads'),\nutil = require('util'),\nevents = require('events')\nos = require('os');\n\nvar Classifier = function(classifier, stemmer) {\n    this.classifier = classifier;\n    this.docs = [];\n    this.features = {};\n    this.stemmer = stemmer || PorterStemmer;\n    this.lastAdded = 0;\n    this.events = new events.EventEmitter();\n};\n\nfunction addDocument(text, classification) {\n\n    // Ignore further processing if classification is undefined\n    if(typeof classification === 'undefined') return;\n\n    // If classification is type of string then make sure it's dosen't have blank space at both end\n    if(typeof classification === 'string'){\n      classification = classification.trim();\n    }\n\n    if(typeof text === 'string')\n\ttext = this.stemmer.tokenizeAndStem(text);\n\n    if(text.length === 0) {\n        // ignore empty documents\n        return;\n    }\n\n    this.docs.push({\n\tlabel: classification,\n\ttext: text\n    });\n\n    for (var i = 0; i < text.length; i++) {\n        var token = text[i];\n        this.features[token] = (this.features[token] || 0) + 1;\n    }\n}\n\nfunction removeDocument(text, classification) {\n  var docs = this.docs\n    , doc\n    , pos;\n\n  if (typeof text === 'string') {\n    text = this.stemmer.tokenizeAndStem(text);\n  }\n\n  for (var i = 0, ii = docs.length; i < ii; i++) {\n    doc = docs[i];\n    if (doc.text.join(' ') == text.join(' ') &&\n        doc.label == classification) {\n      pos = i;\n    }\n  }\n\n  // Remove if there's a match\n  if (!isNaN(pos)) {\n    this.docs.splice(pos, 1);\n\n    for (var i = 0, ii = text.length; i < ii; i++) {\n      delete this.features[text[i]];\n    }\n  }\n}\n\nfunction textToFeatures(observation) {\n    var features = [];\n\n    if(typeof observation === 'string')\n\tobservation = this.stemmer.tokenizeAndStem(observation);\n\n    for(var feature in this.features) {\n        if(observation.indexOf(feature) > -1)\n            features.push(1);\n        else\n            features.push(0);\n    }\n\n    return features;\n}\n\nfunction docsToFeatures(docs) {\n    var parsedDocs = [];\n\n    for (var i = 0; i < docs.length; i++) {\n        var features = [];\n\n        for (var feature in FEATURES) {\n            if (docs[i].observation.indexOf(feature) > -1)\n                features.push(1);\n            else\n                features.push(0);\n        }\n\n        parsedDocs.push({\n            index: docs[i].index,\n            features: features\n        });\n    }\n\n    return JSON.stringify(parsedDocs);\n}\n\nfunction train() {\n    var totalDocs = this.docs.length;\n    for(var i = this.lastAdded; i < totalDocs; i++) {\n        var features = this.textToFeatures(this.docs[i].text);\n        this.classifier.addExample(features, this.docs[i].label);\n        this.events.emit('trainedWithDocument', {index: i, total: totalDocs, doc: this.docs[i]});\n        this.lastAdded++;\n    }\n    this.events.emit('doneTraining', true);\n    this.classifier.train();\n}\n\nfunction trainParallel(numThreads, callback) {\n    if (!callback) {\n        callback = numThreads;\n        numThreads = undefined;\n    }\n\n    if (isNaN(numThreads)) {\n        numThreads = os.cpus().length;\n    }\n\n    var totalDocs = this.docs.length;\n    var threadPool = Threads.createPool(numThreads);\n    var docFeatures = {};\n    var finished = 0;\n    var self = this;\n\n    // Init pool; send the features array and the parsing function\n    threadPool.all.eval('var FEATURES = ' + JSON.stringify(this.features));\n    threadPool.all.eval(docsToFeatures);\n\n    // Convert docs to observation objects\n    var obsDocs = [];\n    for (var i = this.lastAdded; i < totalDocs; i++) {\n        var observation = this.docs[i].text;\n        if (typeof observation === 'string')\n            observation = this.stemmer.tokenizeAndStem(observation);\n        obsDocs.push({\n            index: i,\n            observation: observation\n        });\n    }\n\n    // Called when a batch completes processing\n    var onFeaturesResult = function(docs) {\n        setTimeout(function() {\n            self.events.emit('processedBatch', {\n                size: docs.length,\n                docs: totalDocs,\n                batches: numThreads,\n                index: finished\n            });\n        });\n\n        for (var j = 0; j < docs.length; j++) {\n            docFeatures[docs[j].index] = docs[j].features;\n        }\n    };\n\n    // Called when all batches finish processing\n    var onFinished = function(err) {\n        if (err) {\n            threadPool.destroy();\n            return callback(err);\n        }\n\n        for (var j = self.lastAdded; j < totalDocs; j++) {\n            self.classifier.addExample(docFeatures[j], self.docs[j].label);\n            self.events.emit('trainedWithDocument', {\n                index: j,\n                total: totalDocs,\n                doc: self.docs[j]\n            });\n            self.lastAdded++;\n        }\n\n        self.events.emit('doneTraining', true);\n        self.classifier.train();\n\n        threadPool.destroy();\n        callback(null);\n    };\n\n    // Split the docs and start processing\n    var batchSize = Math.ceil(obsDocs.length / numThreads);\n    var lastError;\n\n    for (var i = 0; i < numThreads; i++) {\n        var batchDocs = obsDocs.slice(i * batchSize, (i+1) * batchSize);\n        var batchJson = JSON.stringify(batchDocs);\n\n        threadPool.any.eval('docsToFeatures(' + batchJson + ')', function(err, docs) {\n            lastError = err || lastError;\n            finished++;\n\n            if (docs) {\n                docs = JSON.parse(docs);\n                onFeaturesResult(docs);\n            }\n\n            if (finished >= numThreads) {\n                onFinished(lastError);\n            }\n        });\n    }\n}\n\nfunction trainParallelBatches(options) {\n    var numThreads = options && options.numThreads;\n    var batchSize = options && options.batchSize;\n\n    if (isNaN(numThreads)) {\n        numThreads = os.cpus().length;\n    }\n\n    if (isNaN(batchSize)) {\n        batchSize = 2500;\n    }\n\n    var totalDocs = this.docs.length;\n    var threadPool = Threads.createPool(numThreads);\n    var docFeatures = {};\n    var finished = 0;\n    var self = this;\n\n    var abort = false;\n    var onError = function(err) {\n        if (!err || abort) return;\n        abort = true;\n        threadPool.destroy(true);\n        self.events.emit('doneTrainingError', err);\n    };\n\n    // Init pool; send the features array and the parsing function\n    var str = JSON.stringify(this.features);\n    threadPool.all.eval('var FEATURES = ' + str + ';', onError);\n    threadPool.all.eval(docsToFeatures, onError);\n\n    // Convert docs to observation objects\n    var obsDocs = [];\n    for (var i = this.lastAdded; i < totalDocs; i++) {\n        var observation = this.docs[i].text;\n        if (typeof observation === 'string')\n            observation = this.stemmer.tokenizeAndStem(observation);\n        obsDocs.push({\n            index: i,\n            observation: observation\n        });\n    }\n\n    // Split the docs in batches\n    var obsBatches = [];\n    var i = 0;\n    while (true) {\n        var batch = obsDocs.slice(i * batchSize, (i+1) * batchSize);\n        if (!batch || !batch.length) break;\n        obsBatches.push(batch);\n        i++;\n    }\n    obsDocs = null;\n    self.events.emit('startedTraining', {\n        docs: totalDocs,\n        batches: obsBatches.length\n    });\n\n    // Called when a batch completes processing\n    var onFeaturesResult = function(docs) {\n        self.events.emit('processedBatch', {\n            size: docs.length,\n            docs: totalDocs,\n            batches: obsBatches.length,\n            index: finished\n        });\n\n        for (var j = 0; j < docs.length; j++) {\n            docFeatures[docs[j].index] = docs[j].features;\n        }\n    };\n\n    // Called when all batches finish processing\n    var onFinished = function() {\n        threadPool.destroy(true);\n        abort = true;\n\n        for (var j = self.lastAdded; j < totalDocs; j++) {\n            self.classifier.addExample(docFeatures[j], self.docs[j].label);\n            self.events.emit('trainedWithDocument', {\n                index: j,\n                total: totalDocs,\n                doc: self.docs[j]\n            });\n            self.lastAdded++;\n        }\n\n        self.events.emit('doneTraining', true);\n        self.classifier.train();\n    };\n\n    // Called to send the next batch to be processed\n    var batchIndex = 0;\n    var sendNext = function() {\n        if (abort) return;\n        if (batchIndex >= obsBatches.length) {\n            return;\n        }\n\n        sendBatch(JSON.stringify(obsBatches[batchIndex]));\n        batchIndex++;\n    };\n\n    // Called to send a batch of docs to the threads\n    var sendBatch = function(batchJson) {\n        if (abort) return;\n        threadPool.any.eval('docsToFeatures(' + batchJson + ');', function(err, docs) {\n            if (err) {\n                return onError(err);\n            }\n\n            finished++;\n\n            if (docs) {\n                docs = JSON.parse(docs);\n                setTimeout(onFeaturesResult.bind(null, docs));\n            }\n\n            if (finished >= obsBatches.length) {\n                setTimeout(onFinished);\n            }\n\n            setTimeout(sendNext);\n        });\n    };\n\n    // Start processing\n    for (var i = 0; i < numThreads; i++) {\n        sendNext();\n    }\n}\n\nfunction retrain() {\n  this.classifier = new (this.classifier.constructor)();\n  this.lastAdded = 0;\n  this.train();\n}\n\nfunction retrainParallel(numThreads, callback) {\n  this.classifier = new (this.classifier.constructor)();\n  this.lastAdded = 0;\n  this.trainParallel(numThreads, callback);\n}\n\nfunction getClassifications(observation) {\n    return this.classifier.getClassifications(this.textToFeatures(observation));\n}\n\nfunction classify(observation) {\n    return this.classifier.classify(this.textToFeatures(observation));\n}\n\nfunction restore(classifier, stemmer) {\n    classifier.stemmer = stemmer || PorterStemmer;\n    classifier.events = new events.EventEmitter();\n    return classifier;\n}\n\nfunction save(filename, callback) {\n    var data = JSON.stringify(this);\n    var fs = require('fs');\n    var classifier = this;\n    fs.writeFile(filename, data, 'utf8', function(err) {\n        if(callback) {\n            callback(err, err ? null : classifier);\n        }\n    });\n}\n\nfunction load(filename, callback) {\n    var fs = require('fs');\n\n    fs.readFile(filename, 'utf8', function(err, data) {\n        var classifier;\n\n        if(!err) {\n            classifier = JSON.parse(data);\n        }\n\n        if(callback)\n            callback(err, classifier);\n    });\n}\n\nClassifier.prototype.addDocument = addDocument;\nClassifier.prototype.removeDocument = removeDocument;\nClassifier.prototype.train = train;\nClassifier.prototype.trainParallel = trainParallel;\nClassifier.prototype.trainParallelBatches = trainParallelBatches;\nClassifier.prototype.retrain = retrain;\nClassifier.prototype.retrainParallel = retrainParallel;\nClassifier.prototype.classify = classify;\nClassifier.prototype.textToFeatures = textToFeatures;\nClassifier.prototype.save = save;\nClassifier.prototype.getClassifications = getClassifications;\nClassifier.restore = restore;\nClassifier.load = load;\n\nmodule.exports = Classifier;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/classifiers/logistic_regression_classifier.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar util = require('util'),\n    Classifier = require('./classifier'),\n    ApparatusLogisticRegressionClassifier = require('apparatus').LogisticRegressionClassifier;\n\nvar LogisticRegressionClassifier = function(stemmer) {\n    Classifier.call(this, new ApparatusLogisticRegressionClassifier(), stemmer);\n};\n\nutil.inherits(LogisticRegressionClassifier, Classifier);\n\nfunction restore(classifier, stemmer) {\n    classifier = Classifier.restore(classifier, stemmer);\n    classifier.__proto__ = LogisticRegressionClassifier.prototype;\n    classifier.classifier = ApparatusLogisticRegressionClassifier.restore(classifier.classifier);\n\n    return classifier;\n}\n\nfunction load(filename, stemmer, callback) {\n    Classifier.load(filename, function(err, classifier) {\n        if (err) {\n            callback(err);\n        }\n        else {\n            callback(err, restore(classifier, stemmer));\n        }\n    });\n}\n\nfunction train() {\n    // we need to reset the traning state because logistic regression\n    // needs its matricies to have their widths synced, etc.\n    this.lastAdded = 0;\n    this.classifier = new ApparatusLogisticRegressionClassifier();\n    Classifier.prototype.train.call(this);\n}\n\nLogisticRegressionClassifier.prototype.train = train;\nLogisticRegressionClassifier.restore = restore;\nLogisticRegressionClassifier.load = load;\n\nmodule.exports = LogisticRegressionClassifier;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/inflectors/noun_inflector.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar SingularPluralInflector = require('./singular_plural_inflector'),\n    util = require('util'),\n    FormSet = require('./form_set');\n\nfunction attach() {\n    var inflector = this;\n    \n    String.prototype.singularizeNoun = function() {\n        return inflector.singularize(this);\n    }\n    \n    String.prototype.pluralizeNoun = function() {\n        return inflector.pluralize(this);\n    }\n}\n\nvar NounInflector = function() {\n    this.ambiguous = [\n        'bison', 'bream', 'carp', 'chassis', 'cod', 'corps', 'debris', 'deer',\n        'diabetes', 'equipment', 'elk', 'fish', 'flounder', 'gallows', 'graffiti',\n        'headquarters', 'herpes', 'highjinks', 'homework', 'information',\n        'mackerel', 'mews', 'money', 'news', 'rice', 'rabies', 'salmon', 'series',\n        'sheep', 'shrimp', 'species', 'swine', 'trout', 'tuna', 'whiting', 'wildebeest'\n    ];\n    \n    this.customPluralForms = [];\n    this.customSingularForms = [];    \n    this.singularForms = new FormSet();\n    this.pluralForms = new FormSet();\n\n    this.attach = attach;\n\n    this.addIrregular(\"child\", \"children\");\n    this.addIrregular(\"man\", \"men\");\n    this.addIrregular(\"person\", \"people\");\n    this.addIrregular(\"sex\", \"sexes\");\n    this.addIrregular(\"mouse\", \"mice\");\n    this.addIrregular(\"ox\", \"oxen\");\n    this.addIrregular(\"foot\", \"feet\");\n    this.addIrregular(\"tooth\", \"teeth\");\n    this.addIrregular(\"goose\", \"geese\");\n    this.addIrregular(\"ephemeris\", \"ephemerides\");\n    this.addIrregular(\"cloth\", \"clothes\");\n    \n    // see if it is possible to unify the creation of both the singular and\n    // plural regexes or maybe even just have one list. with a complete list\n    // of rules it may only be possible for some regular forms, but worth a shot    \n    this.pluralForms.regularForms.push([/y$/i, 'ies']);\n    this.pluralForms.regularForms.push([/ife$/i, 'ives']);\n    this.pluralForms.regularForms.push([/(antenn|formul|nebul|vertebr|vit)a$/i, '$1ae']);    \n    this.pluralForms.regularForms.push([/(octop|vir|radi|nucle|fung|cact|stimul)us$/i, '$1i']);    \n    this.pluralForms.regularForms.push([/(buffal|tomat|tornad)o$/i, '$1oes']);    \n    this.pluralForms.regularForms.push([/(sis)$/i, 'ses']);\n    this.pluralForms.regularForms.push([/(matr|vert|ind|cort)(ix|ex)$/i, '$1ices']);\n    this.pluralForms.regularForms.push([/sses$/i, 'sses']);\n    this.pluralForms.regularForms.push([/(x|ch|ss|sh|s|z)$/i, '$1es']);\n    this.pluralForms.regularForms.push([/^(?!talis|.*hu)(.*)man$/i, '$1men']);\n    this.pluralForms.regularForms.push([/(.*)/i, '$1s']);\n\n    this.singularForms.regularForms.push([/([^v])ies$/i, '$1y']);\n    this.singularForms.regularForms.push([/ives$/i, 'ife']);\n    this.singularForms.regularForms.push([/(antenn|formul|nebul|vertebr|vit)ae$/i, '$1a']);\n    this.singularForms.regularForms.push([/(octop|vir|radi|nucle|fung|cact|stimul)(i)$/i, '$1us']);\n    this.singularForms.regularForms.push([/(buffal|tomat|tornad)(oes)$/i, '$1o']);\n    this.singularForms.regularForms.push([/(analy|naly|synop|parenthe|diagno|the)ses$/i, '$1sis']);\n    this.singularForms.regularForms.push([/(vert|ind|cort)(ices)$/i, '$1ex']);\n    // our pluralizer won''t cause this form of appendix (appendicies)\n    // but we should handle it\n    this.singularForms.regularForms.push([/(matr|append)(ices)$/i, '$1ix']);\n    this.singularForms.regularForms.push([/(x|ch|ss|sh|s|z)es$/i, '$1']);\n    this.singularForms.regularForms.push([/men$/i, 'man']);\n    this.singularForms.regularForms.push([/ss$/i, 'ss']);\n    this.singularForms.regularForms.push([/s$/i, '']);\n    \n    this.pluralize = function (token) {\n        return this.ize(token, this.pluralForms, this.customPluralForms);\n    };\n    \n    this.singularize = function(token) {\n        return this.ize(token, this.singularForms, this.customSingularForms);\n    };\n};\n\nutil.inherits(NounInflector, SingularPluralInflector);\n    \nmodule.exports = NounInflector;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/inflectors/singular_plural_inflector.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar TenseInflector = function () {\n};\n\nTenseInflector.prototype.addSingular = function(pattern, replacement) {\n    this.customSingularForms.push([pattern, replacement]);    \n};\n\nTenseInflector.prototype.addPlural = function(pattern, replacement) {\n    this.customPluralForms.push([pattern, replacement]);\n};\n\nTenseInflector.prototype.ize = function (token, formSet, customForms) {\n    var restoreCase = this.restoreCase(token);\n    return restoreCase(this.izeRegExps(token, customForms) || this.izeAbiguous(token) ||\n        this.izeRegulars(token, formSet) || this.izeRegExps(token, formSet.regularForms) ||\n        token);\n}\n\nTenseInflector.prototype.izeAbiguous = function (token) {\n    if(this.ambiguous.indexOf(token.toLowerCase()) > -1)\n        return token.toLowerCase();\n\n    return false;\n}\n\nTenseInflector.prototype.pluralize = function (token) {\n    return this.ize(token, this.pluralForms, this.customPluralForms);\n};\n\nTenseInflector.prototype.singularize = function(token) {\n    return this.ize(token, this.singularForms, this.customSingularForms);\n};    \n\nvar uppercaseify = function(token) {\n    return token.toUpperCase();\n}\nvar capitalize = function(token) {\n    return token[0].toUpperCase() + token.slice(1);\n}\nvar lowercaseify = function(token) {\n    return token.toLowerCase();\n}\n\nTenseInflector.prototype.restoreCase = function(token) {\n    if (token[0] === token[0].toUpperCase()) {\n        if (token[1] && token[1] === token[1].toLowerCase()) {\n            return capitalize;\n        } else {\n            return uppercaseify;\n        }\n    } else {\n        return lowercaseify;\n    }\n}\n\nTenseInflector.prototype.izeRegulars = function(token, formSet) {\n    token = token.toLowerCase();\n    if(formSet.irregularForms.hasOwnProperty(token) && formSet.irregularForms[token])\n        return formSet.irregularForms[token];\n\n    return false;\n}\n\nTenseInflector.prototype.addForm = function(singularTable, pluralTable, singular, plural) {\n    singular = singular.toLowerCase();\n    plural = plural.toLowerCase();\n    pluralTable[singular] = plural;\n    singularTable[plural] = singular;\n};\n\nTenseInflector.prototype.addIrregular = function(singular, plural) {\n    this.addForm(this.singularForms.irregularForms, this.pluralForms.irregularForms, singular, plural);\n};\n\nTenseInflector.prototype.izeRegExps = function(token, forms) {\n        var i, form;\n        for(i = 0; i < forms.length; i++) {\n            form = forms[i];\n            \n            if(token.match(form[0]))\n                return token.replace(form[0], form[1]);\n        }\n        \n        return false;\n    }\n\nmodule.exports = TenseInflector;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/inflectors/form_set.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar FormSet = function() {\n    this.regularForms = [];\n    this.irregularForms = {};\n}\n\nmodule.exports = FormSet;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/inflectors/fr/noun_inflector.js":"/*\n Copyright (c) 2012, Guillaume Marty\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n\n/**\n * A noun inflector for French.\n * Compiled from:\n * \\@see http://fr.wiktionary.org/wiki/Annexe:Pluriels_irr%C3%A9guliers_en_fran%C3%A7ais\n * \\@see http://fr.wikipedia.org/wiki/Pluriels_irr%C3%A9guliers_en_fran%C3%A7ais\n *\n * \\@todo Take compounded noun into account (eaux-fortes, pique-nique...).\n * \\@todo General note: French also requires AdjectiveInflector (femininize...).\n */\n\nvar SingularPluralInflector = require('../singular_plural_inflector'),\n    util = require('util'),\n    FormSet = require('../form_set');\n\nfunction attach() {\n  var inflector = this;\n\n  String.prototype.singularizeNoun = function() {\n    return inflector.singularize(this);\n  };\n\n  String.prototype.pluralizeNoun = function() {\n    return inflector.pluralize(this);\n  };\n}\n\n\n\n/**\n * @constructor\n */\nvar NounInflector = function() {\n  // Ambiguous a.k.a. invariant.\n  // \\@todo Expand this list to be as comprehensive as possible.\n  this.ambiguous = [\n    // Nouns ending by -s\n    'à-peu-près', 'à-propos', 'abattis', 'abcès', 'abois', 'abribus', 'abus',\n    'accès', 'acquis', 'adénovirus', 'adonis', 'ados', 'agrès', 'aguets',\n    'ailleurs', 'ais', 'albatros', 'albinos', 'alias', 'aloès', 'amaryllis',\n    'amas', 'ampélopsis', 'ananas', 'anchois', 'angélus', 'anis', 'anticorps',\n    'antihéros', 'antirides', 'anus', 'appas', 'appentis', 'appui-bras',\n    'appuie-bras', 'arcanes', 'argus', 'arrérages', 'arrière-pays', 'as',\n    'ascaris', 'asparagus', 'atlas', 'atours', 'aurochs', 'autobus',\n    'autofocus', 'avant-bras', 'avant-corps', 'avant-propos', 'avers', 'avis',\n    'axis', 'barbouillis', 'bas', 'beaujolais', 'beaux-arts', 'biais',\n    'bibliobus', 'biceps', 'bicross', 'bien-fonds', 'bloc-notes', 'blockhaus',\n    'blocus', 'blues', 'bois', 'bonus', 'bout-dehors', 'bouts-rimés',\n    'branle-bas', 'bras', 'brebis', 'bris', 'brise-lames', 'brise-mottes',\n    'brûlis', 'buis', 'burnous', 'bus', 'business', 'cabas', 'cacatoès',\n    'cacatois', 'cactus', 'cadenas', 'cafouillis', 'caillebotis', 'calvados',\n    'cambouis', 'campus', 'canevas', 'cannabis', 'carquois', 'cas',\n    'casse-noisettes', 'casse-pieds', 'cassis', 'caucus', 'cens', 'cervelas',\n    'chablis', 'chamois', 'chaos', 'chas', 'chasselas', 'châssis',\n    'chatouillis', 'chauffe-assiettes', 'chauve-souris', 'chorus', 'choucas',\n    'circoncis', 'cirrus', 'clafoutis', 'clapotis', 'cliquetis', 'clos',\n    'cochylis', 'colis', 'coloris', 'commis', 'compas', 'compromis',\n    'compte-chèques', 'compte-gouttes', 'compte-tours', 'concours', 'confins',\n    'congrès', 'consensus', 'contrepoids', 'contresens', 'contretemps',\n    'corn flakes', 'corps', 'corps-à-corps', 'corpus', 'cosinus', 'cosmos',\n    'coulis', 'coupe-ongles', 'cours', 'court-jus', 'couscous', 'coutelas',\n    'crocus', 'croquis', 'cross', 'cubitus', 'cumulus', 'cure-dents',\n    'cure-ongles', 'cure-pipes', 'cursus', 'cyclo-cross', 'cyprès', 'dais',\n    'damas', 'débarras', 'débours', 'débris', 'décès', 'dedans', 'dehors',\n    'delirium tremens', 'demi-gros', 'dépens', 'dessous', 'dessus', 'détritus',\n    'deux-mâts', 'deux-pièces', 'deux-points', 'deux-roues', 'deux-temps',\n    'dévers', 'devis', 'diplodocus', 'discours', 'dos', 'ébats', 'éboulis',\n    'échalas', 'edelweiss', 'élaeis', 'éleis', 'éléphantiasis', 'embarras',\n    'empois', 'en-cas', 'encens', 'enclos', 'endos', 'engrais', 'entrelacs',\n    'entremets', 'envers', 'épluche-légumes', 'ers', 'espace-temps',\n    'essuie-mains', 'eucalyptus', 'ex-libris', 'excès', 'express', 'extrados',\n    'faciès', 'fait-divers', 'fatras', 'faux-sens', 'favoris', 'ficus',\n    'fier-à-bras', 'finnois', 'florès', 'focus', 'fœtus', 'fois', 'forceps',\n    'fouillis', 'fracas', 'frais', 'français', 'franglais', 'frimas',\n    'friselis', 'frisottis', 'froncis', 'frottis', 'fucus', 'gâchis', 'galetas',\n    'galimatias', 'garde-à-vous', 'garde-corps', 'gargouillis', 'gars',\n    'gâte-bois', 'gazouillis', 'génois', 'gibus', 'glacis', 'glas', 'gneiss',\n    'gobe-mouches', 'grès', 'gribouillis', 'guet-apens', 'habeas corpus',\n    'hachis', 'haras', 'hardes', 'harnais', 'haut-le-corps', 'hautbois',\n    'herbe-aux-chats', 'héros', 'herpès', 'hiatus', 'hibiscus', 'hors-concours',\n    'hors-pistes', 'hourdis', 'huis-clos', 'humérus', 'humus', 'ibis', 'iléus',\n    'indique-fuites', 'infarctus', 'inlandsis', 'insuccès', 'intercours',\n    'intrados', 'intrus', 'iris', 'isatis', 'jais', 'jars', 'jeans',\n    'jeuconcours', 'judas', 'juliénas', 'jus', 'justaucorps', 'kakatoès',\n    'kermès', 'kriss', 'lacis', 'laïus', 'lambris', 'lapis', 'laps', 'lapsus',\n    'laquais', 'las', 'lattis', 'lave-mains', 'lavis', 'lèche-bottes',\n    'lèche-vitrines', 'legs', 'lias', 'liégeois', 'lilas', 'lis', 'lœss',\n    'logis', 'loris', 'lotus', 'louis', 'lupus', 'lys', 'mâchicoulis', 'madras',\n    'maïs', 'malappris', 'malus', 'mânes', 'maquis', 'marais', 'maroilles',\n    'marquis', 'mas', 'mass-médias', 'matelas', 'matois', 'médius', 'mépris',\n    'mérinos', 'mess', 'mets', 'mi-bas', 'micro-ondes', 'mille-pattes',\n    'millepertuis', 'minibus', 'minois', 'minus', 'mirabilis', 'mois',\n    'monocorps', 'monte-plats', 'mors', 'motocross', 'mots-croisés', 'motus',\n    'mouchetis', 'mucus', 'myosotis', 'nævus', 'négus', 'niais',\n    'nimbo-stratus', 'nimbus', 'norois', 'nounours', 'nu-pieds', 'oasis',\n    'obus', 'olibrius', 'omnibus', 'opus', 'os', 'ours', 'ouvre-boîtes',\n    'ouvre-bouteilles', 'palais', 'palis', 'palmarès', 'palus', 'panais',\n    'panaris', 'pancréas', 'papyrus', 'par-dehors', 'paradis', 'parcours',\n    'pardessus', 'pare-balles', 'pare-chocs', 'parvis', 'pas', 'passe-temps',\n    'pataquès', 'pathos', 'patois', 'pavois', 'pays', 'permis',\n    'petit-bourgeois', 'petit-gris', 'petit-pois', 'phallus', 'phimosis',\n    'pickles', 'pilotis', 'pique-fleurs', 'pis', 'pithiviers', 'pityriasis',\n    'plateau-repas', 'plâtras', 'plein-temps', 'plexiglas', 'plexus', 'plus',\n    'poids', 'pois', 'pont-levis', 'porte-avions', 'porte-bagages',\n    'porte-billets', 'porte-bouteilles', 'porte-clés', 'porte-hélicoptères',\n    'porte-jarretelles', 'porte-revues', 'pouls', 'préavis', 'presse-fruits',\n    'presse-papiers', 'princeps', 'printemps', 'procès', 'processus', 'progrès',\n    'propos', 'prospectus', 'protège-dents', 'psoriasis', 'pubis', 'puits',\n    'pus', 'putois', 'quatre-épices', 'quatre-feuilles', 'quatre-heures',\n    'quatre-mâts', 'quatre-quarts', 'quatre-temps', 'quitus', 'rabais',\n    'rachis', 'radis', 'radius', 'raïs', 'ramassis', 'rébus', 'reclus',\n    'recours', 'refus', 'relais', 'remords', 'remous', 'remue-méninges',\n    'rendez-vous', 'repas', 'répons', 'repos', 'repris', 'reps', 'rétrovirus',\n    'revers', 'rhinocéros', 'rictus', 'rince-doigts', 'ris', 'rollmops',\n    'rosé-des-prés', 'roulis', 'rubis', 'salmigondis', 'salsifis', 'sans-logis',\n    'sas', 'sassafras', 'sauternes', 'schnaps', 'schuss', 'secours', 'semis',\n    'sens', 'serre-fils', 'serre-livres', 'sévices', 'sinus', 'skunks',\n    'souris', 'sournois', 'sous-bois', 'stradivarius', 'stras', 'strass',\n    'strato-cumulus', 'stratus', 'stress', 'succès', 'surdos', 'surplus',\n    'surpoids', 'sursis', 'suspens', 'synopsis', 'syphilis', 'taffetas',\n    'taillis', 'talus', 'tamaris', 'tamis', 'tapis', 'tas', 'taudis', 'temps',\n    'tennis', 'terminus', 'terre-neuvas', 'tétanos', 'tétras', 'thalamus',\n    'thermos', 'thesaurus', 'thésaurus', 'thymus', 'tire-fesses', 'tonus',\n    'torchis', 'torticolis', 'tournedos', 'tournevis', 'tournis', 'tracas',\n    'traîne-savates', 'travers', 'tréfonds', 'treillis', 'trépas', 'trias',\n    'triceps', 'trichomonas', 'trois-étoiles', 'trois-mâts', 'trois-quarts',\n    'trolleybus', 'tumulus', 'typhus', 'univers', 'us', 'utérus', 'vasistas',\n    'vélocross', 'velours', 'verglas', 'verjus', 'vernis', 'vers',\n    'vert-de-gris', 'vide-ordures', 'vide-poches', 'villageois', 'virus',\n    'vis-à-vis', 'volubilis', 'vulgum pecus', 'waters', 'williams', 'xérès',\n\n    // Nouns ending by -x\n    'abat-voix', 'afflux', 'alpax', 'anthrax', 'apex', 'aptéryx',\n    'archéoptéryx', 'arrière-faix', 'bombyx', 'borax', 'bordeaux', 'bouseux',\n    'box', 'carex', 'casse-noix', 'cedex', 'céphalothorax', 'cérambyx', 'chaux',\n    'choix', 'coccyx', 'codex', 'contumax', 'coqueleux', 'cortex', 'courroux',\n    'croix', 'crucifix', 'culex', 'demodex', 'duplex', 'entre-deux', 'époux',\n    'équivaux', 'eux', 'ex', 'faix', 'faucheux', 'faux', 'fax', 'ferreux',\n    'flux', 'fox', 'freux', 'furax', 'hapax', 'harengueux', 'hélix',\n    'horse-pox', 'houx', 'index', 'influx', 'inox', 'juke-box', 'kleenex',\n    'lagothrix', 'larynx', 'lastex', 'latex', 'lux', 'lynx', 'macareux', 'max',\n    'mésothorax', 'mi-voix', 'mirepoix', 'motteux', 'multiplex', 'murex',\n    'narthex', 'noix', 'onyx', 'opopanax', 'oropharynx', 'paix', 'panax',\n    'perdrix', 'pharynx', 'phénix', 'phlox', 'phoenix', 'pneumothorax', 'poix',\n    'portefaix', 'pousse-cailloux', 'preux', 'prix', 'prothorax', 'pucheux',\n    'pyrex', 'pyroligneux', 'quadruplex', 'queux', 'redoux', 'reflex', 'reflux',\n    'relax', 'rhinopharynx', 'rose-croix', 'rouvieux', 'roux', 'rumex',\n    'saindoux', 'sardonyx', 'scolex', 'sèche-cheveux', 'silex', 'simplex',\n    'sioux', 'sirex', 'smilax', 'solex', 'songe-creux', 'spalax', 'sphex',\n    'sphinx', 'storax', 'strix', 'styrax', 'surfaix', 'surtaux', 'syrinx',\n    'tamarix', 'taux', 'télex', 'thorax', 'tord-boyaux', 'toux', 'trionyx',\n    'tripoux', 'tubifex', 'vertex', 'vidéotex', 'vielleux', 'vieux',\n    'violoneux', 'voix', 'volvox', 'vortex',\n\n    // Nouns ending by -z\n    'allume-gaz', 'assez', 'biogaz', 'cache-nez', 'camping-gaz', 'chez',\n    'chintz', 'ersatz', 'fez', 'free-jazz', 'fritz', 'gaz', 'gin-fizz', 'hertz',\n    'jazz', 'jerez', 'kibboutz', 'kilohertz', 'kolkhoz', 'kronprinz', 'lapiaz',\n    'lez', 'mégahertz', 'merguez', 'nez', 'pince-nez', 'quartz', 'quiz', 'ranz',\n    'raz', 'recez', 'rémiz', 'rez', 'riz', 'ruolz', 'seltz', 'serre-nez'\n  ];\n\n  this.customPluralForms = [];\n  this.customSingularForms = [];\n  this.singularForms = new FormSet();\n  this.pluralForms = new FormSet();\n\n  this.attach = attach;\n\n  this.addIrregular('ail', 'aulx');\n  this.addIrregular('bétail', 'bestiaux');\n  this.addIrregular('bonhomme', 'bonshommes');\n  this.addIrregular('ciel', 'cieux');\n  this.addIrregular('monsieur', 'messieurs');\n  this.addIrregular('mafioso', 'mafiosi');\n  this.addIrregular('œil', 'yeux');\n  this.addIrregular('putto', 'putti');\n  this.addIrregular('targui', 'touareg'); // touareg -> touaregs is also OK.\n\n  // Pluralize\n  this.pluralForms.regularForms.push([/^(av|b|c|carnav|cérémoni|chac|corr|emment|emmenth|festiv|fut|gavi|gra|narv|p|récit|rég|rit|rorqu|st)al$/i, '$1als']);\n  this.pluralForms.regularForms.push([/^(aspir|b|cor|ém|ferm|gemm|soupir|trav|vant|vent|vitr)ail$/i, '$1aux']);\n  this.pluralForms.regularForms.push([/^(bij|caill|ch|gen|hib|jouj|p|rip|chouch)ou$/i, '$1oux']);\n  this.pluralForms.regularForms.push([/^(gr|berimb|don|karb|land|pil|rest|sarr|un)au$/i, '$1aus']);\n  this.pluralForms.regularForms.push([/^(bl|ém|enf|pn)eu$/i, '$1eus']);\n  this.pluralForms.regularForms.push([/(au|eau|eu|œu)$/i, '$1x']);\n  this.pluralForms.regularForms.push([/al$/i, 'aux']);\n  this.pluralForms.regularForms.push([/(s|x)$/i, '$1']);\n  this.pluralForms.regularForms.push([/(.*)$/i, '$1s']);\n\n  // Singularize\n  this.singularForms.regularForms.push([/^(aspir|b|cor|ém|ferm|gemm|soupir|trav|vant|vent|vitr)aux$/i, '$1ail']);\n  this.singularForms.regularForms.push([/^(aloy|b|bouc|boy|burg|conoy|coy|cr|esquim|ét|fabli|flé|flûti|glu|gr|gru|hoy|joy|kérab|matéri|nobli|noy|pré|sen|sén|t|touch|tuss|tuy|v|ypré)aux$/i, '$1au']);\n  this.singularForms.regularForms.push([/^(bij|caill|ch|gen|hib|jouj|p|rip|chouch)oux$/i, '$1ou']);\n  this.singularForms.regularForms.push([/^(bis)?aïeux$/i, '$1aïeul']);\n  this.singularForms.regularForms.push([/^apparaux$/i, 'appareil']); // One way transform, don't put on irregular list.\n  this.singularForms.regularForms.push([/^ciels$/i, 'ciel']);\n  this.singularForms.regularForms.push([/^œils$/i, 'œil']);\n  this.singularForms.regularForms.push([/(eau|eu|œu)x$/i, '$1']);\n  this.singularForms.regularForms.push([/aux$/i, 'al']);\n  this.singularForms.regularForms.push([/(.*)s$/i, '$1']);\n\n  this.pluralize = function(token) {\n    return this.ize(token, this.pluralForms, this.customPluralForms);\n  };\n\n  this.singularize = function(token) {\n    return this.ize(token, this.singularForms, this.customSingularForms);\n  };\n};\n\nutil.inherits(NounInflector, SingularPluralInflector);\n\nmodule.exports = NounInflector;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/inflectors/ja/noun_inflector.js":"/*\n Copyright (c) 2012, Guillaume Marty\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n\n/**\n * A noun inflector for Japanese.\n * Compiled from several sources including:\n * \\@see http://answers.yahoo.com/question/index?qid=20080528201740AASBWy6\n * \\@see http://www.excite.co.jp/dictionary/english_japanese/\n *\n * This script assumes input is normalized using normalizer_ja().\n * Pluralizing Japanese has a very limited interest.\n * Japanese don't usually distinct plural from singular, so even a word looking\n * like a singular might actually be a plural.\n *\n * Singularization of nouns ending by -tachi or -ra is achieved using a\n * comprehensive black list, while nouns ending by -domo or -gata use a white\n * list because there are too many exceptions.\n *\n * \\@todo Singularize nouns ending by -ら, but there are too many exceptions.\n * \\@todo Expand the list of common plurals ending by -domo and -gata.\n */\n\nvar SingularPluralInflector = require('../singular_plural_inflector'),\n    util = require('util'),\n    FormSet = require('../form_set');\n\nfunction attach() {\n  var inflector = this;\n\n  String.prototype.singularizeNoun = function() {\n    return inflector.singularize(this);\n  };\n\n  String.prototype.pluralizeNoun = function() {\n    return inflector.pluralize(this);\n  };\n}\n\n\n\n/**\n * @constructor\n */\nvar NounInflector = function() {\n  // Ambiguous a.k.a. invariant.\n  this.ambiguous = [\n    'ともだち', '友だち', '友達', '遊び友達', '飲み友達', '酒飲み友達', '茶飲み友達',\n    '学校友達', '女友達', '男友達', '幼友達'\n  ];\n\n  this.customPluralForms = [];\n  this.customSingularForms = [];\n  this.singularForms = new FormSet();\n  this.pluralForms = new FormSet();\n\n  this.attach = attach;\n\n  this.addIrregular('神', '神神');\n  this.addIrregular('人', '人人');\n  this.addIrregular('年', '年年');\n  this.addIrregular('月', '月月');\n  this.addIrregular('日', '日日');\n  this.addIrregular('星', '星星');\n  this.addIrregular('島', '島島');\n  this.addIrregular('我', '我我');\n  this.addIrregular('山', '山山');\n  this.addIrregular('国', '国国');\n  this.addIrregular('所', '所所');\n  this.addIrregular('隅', '隅隅');\n\n  /**\n   * Notes:\n   * -たち exceptions: いたち, おいたち, ついたち, かたち, かおかたち, なりかたち, いでたち, はたち, からたち, なりたち\n   * -達 exceptions: 伊達, 男伊達, 栄達, 上意下達, 熟達, 上達, 下意上達, 先達, 送達, 速達, 即日速達, 書留速達, 調達, 通達, 伝達, 到達, 配達, 牛乳配達, 新聞配達, 無料配達, 四通八達, 発達, 未発達, 御用達, 宮内庁御用達, 練達, 闊達\n   * -等 exceptions: 一等, 下等, 何等, 均等, 勲等, 高等, 三等, 初等, 上等, 親等, 二親等, 数等, 対等, 中等, 同等, 特等, 二等, 品等, 不等, 平等, 悪平等, 男女平等, 不平等, 優等, 劣等\n   */\n\n  // Pluralize\n  this.pluralForms.regularForms.push([/^(.+)$/i, '$1たち']);\n\n  // Singularize\n  this.singularForms.regularForms.push([/^(.+)たち$/i, function(a, mask) {\n    if (['い', 'おい', 'つい', 'か', 'かおか', 'なりか', 'いで', 'は', 'から',\n      'なり'].indexOf(mask) >= 0)\n      return mask + 'たち';\n    return mask;\n  }]);\n  this.singularForms.regularForms.push([/^(.+)達$/i, function(a, mask) {\n    if (['伊', '伊', '栄', '上意下', '熟', '上', '下意上', '先', '送', '速',\n      '即日速', '書留速', '調', '通', '伝', '到', '配', '牛乳配', '新聞配', '無料配',\n      '四通八', '発', '未発', '御用', '宮内庁御用', '練', '闊'].indexOf(mask) >= 0)\n      return mask + '達';\n    return mask;\n  }]);  // Singularize nouns ending by -等, but not exceptions.\n  this.singularForms.regularForms.push([/^(.+)等$/i, function(a, mask) {\n    if (['一', '下', '何', '均', '勲', '高', '三', '初', '親', '二親', '数', '対',\n      '中', '同', '特', '二', '品', '不', '平', '悪平', '男女平', '不平', '優',\n      '劣'].indexOf(mask) >= 0)\n      return mask + '等';\n    return mask;\n  }]);\n  this.singularForms.regularForms.push([/^(人間|わたくし|私|てまえ|手前|野郎|やろう|勇者|がき|ガキ|餓鬼|あくとう|悪党|猫|家来)(共|ども)$/i, '$1']);\n  this.singularForms.regularForms.push([/^(神様|先生|あなた|大名|女中|奥様)(方|がた)$/i, '$1']);\n\n  this.pluralize = function(token) {\n    return this.ize(token, this.pluralForms, this.customPluralForms);\n  };\n\n  this.singularize = function(token) {\n    return this.ize(token, this.singularForms, this.customSingularForms);\n  };\n};\n\nutil.inherits(NounInflector, SingularPluralInflector);\n\nmodule.exports = NounInflector;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/inflectors/present_verb_inflector.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar util = require('util'),\n    SingularPluralInflector = require('./singular_plural_inflector'),\n    FormSet = require('./form_set');\n\nfunction attach() {\n    var inflector = this;\n    \n    String.prototype.singularizePresentVerb = function() {\n        return inflector.singularize(this);\n    }\n    \n    String.prototype.pluralizePresentVerb = function() {\n        return inflector.pluralize(this);\n    }\n}\n\nvar VerbInflector = function() {\n    this.ambiguous = [\n        'will'\n    ];\n    \n    this.attach = attach;\n        \n    this.customPluralForms = [];\n    this.customSingularForms = [];    \n    this.singularForms = new FormSet();\n    this.pluralForms = new FormSet();\n\n    this.addIrregular(\"am\", \"are\");    \n    this.addIrregular(\"is\", \"are\");\n    this.addIrregular(\"was\", \"were\");\n    this.addIrregular(\"has\", \"have\");\n    \n    this.singularForms.regularForms.push([/ed$/i, 'ed']);\n    this.singularForms.regularForms.push([/ss$/i, 'sses']);\n    this.singularForms.regularForms.push([/x$/i, 'xes']);    \n    this.singularForms.regularForms.push([/(h|z|o)$/i, '$1es']);\n    this.singularForms.regularForms.push([/$zz/i, 'zzes']);\n    this.singularForms.regularForms.push([/([^a|e|i|o|u])y$/i, '$1ies']);\n    this.singularForms.regularForms.push([/$/i, 's']);\n\n    this.pluralForms.regularForms.push([/sses$/i, 'ss']);\n    this.pluralForms.regularForms.push([/xes$/i, 'x']);\n    this.pluralForms.regularForms.push([/([cs])hes$/i, '$1h']);\n    this.pluralForms.regularForms.push([/zzes$/i, 'zz']);\n    this.pluralForms.regularForms.push([/([^h|z|o|i])es$/i, '$1e']);\n    this.pluralForms.regularForms.push([/ies$/i, 'y']);//flies->fly\n    this.pluralForms.regularForms.push([/e?s$/i, '']); \n};\n\nutil.inherits(VerbInflector, SingularPluralInflector);\n\nmodule.exports = VerbInflector;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/inflectors/count_inflector.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nfunction nthForm(i) {\n    var teenth = (i % 100);\n\n    if(teenth > 10 && teenth < 14)\n        return 'th';\n    else {\n        switch(i % 10) {\n            case 1:\n                return 'st';\n                break;\n            case 2:\n                return 'nd';\n                break;            \n            case 3:\n                return 'rd';\n                break;\n            default:\n                return 'th';\n        }\n    }\n}\n\nfunction nth(i) {\n    return i.toString() + nthForm(i);\n}\n\nvar CountInflector = function() {\n};\n\nCountInflector.nth = nth;\n\nmodule.exports = CountInflector;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/wordnet/wordnet.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar IndexFile = require('./index_file'),\n  DataFile = require('./data_file');\n\nfunction pushResults(data, results, offsets, callback) {\n  var wordnet = this;\n\n  if(offsets.length == 0) {\n    callback(results);\n  } else {\n    data.get(offsets.pop(), function(record) {\n      results.push(record);\n      wordnet.pushResults(data, results, offsets, callback);\n    });\n  }\n}\n\nfunction lookupFromFiles(files, results, word, callback) {\n  var wordnet = this;\n\n  if(files.length == 0)\n    callback(results);\n  else {\n    var file = files.pop();\n\n    file.index.lookup(word, function(record) {\n      if(record) {\n        wordnet.pushResults(file.data, results, record.synsetOffset, function() {\n          wordnet.lookupFromFiles(files, results, word, callback);\n        });\n      } else {\n        wordnet.lookupFromFiles(files, results, word, callback);\n      }\n    });\n  }\n}\n\nfunction lookup(word, callback) {\n  word = word.toLowerCase().replace(/\\s+/g, '_');\n\n  this.lookupFromFiles([\n    {index: this.nounIndex, data: this.nounData},\n    {index: this.verbIndex, data: this.verbData},\n    {index: this.adjIndex, data: this.adjData},\n    {index: this.advIndex, data: this.advData},\n  ], [], word, callback);\n}\n\nfunction get(synsetOffset, pos, callback) {\n  var dataFile = this.getDataFile(pos);\n  var wordnet = this;\n\n  dataFile.get(synsetOffset, function(result) {\n    callback(result);\n  });\n}\n\nfunction getDataFile(pos) {\n    switch(pos) {\n      case 'n':\n        return this.nounData;\n      case 'v':\n        return this.verbData;\n      case 'a': case 's':\n        return this.adjData;\n      case 'r':\n        return this.advData;\n    }\n}\n\nfunction loadSynonyms(synonyms, results, ptrs, callback) {\n  var wordnet = this;\n\n  if(ptrs.length > 0) {\n    var ptr = ptrs.pop();\n\n    this.get(ptr.synsetOffset, ptr.pos, function(result) {\n      synonyms.push(result);\n      wordnet.loadSynonyms(synonyms, results, ptrs, callback);\n    });\n  } else {\n    wordnet.loadResultSynonyms(synonyms, results, callback);\n  }\n}\n\nfunction loadResultSynonyms(synonyms, results, callback) {\n  var wordnet = this;\n\n  if(results.length > 0) {\n    var result = results.pop();\n    wordnet.loadSynonyms(synonyms, results, result.ptrs, callback);\n  } else\n    callback(synonyms);\n}\n\nfunction lookupSynonyms(word, callback) {\n  var wordnet = this;\n\n  wordnet.lookup(word, function(results) {\n    wordnet.loadResultSynonyms([], results, callback);\n  });\n}\n\nfunction getSynonyms() {\n  var wordnet = this;\n  var callback = arguments[2] ? arguments[2] : arguments[1];\n  var pos = arguments[0].pos ? arguments[0].pos : arguments[1];\n  var synsetOffset = arguments[0].synsetOffset ? arguments[0].synsetOffset : arguments[0];\n\n  this.get(synsetOffset, pos, function(result) {\n    wordnet.loadSynonyms([], [], result.ptrs, callback);\n  });\n}\n\nfunction WordNet(dataDir) {\n\n  if (!dataDir) {\n    try {\n      var WNdb = require('wordnet-db');\n    } catch(e) {\n      console.error(\"Please 'npm install wordnet-db' before using WordNet module or specify a dict directory.\");\n      throw e;\n    }\n    dataDir = WNdb.path;\n  }\n\n  this.nounIndex = new IndexFile(dataDir, 'noun');\n  this.verbIndex = new IndexFile(dataDir, 'verb');\n  this.adjIndex = new IndexFile(dataDir, 'adj');\n  this.advIndex = new IndexFile(dataDir, 'adv');\n\n  this.nounData = new DataFile(dataDir, 'noun');\n  this.verbData = new DataFile(dataDir, 'verb');\n  this.adjData = new DataFile(dataDir, 'adj');\n  this.advData = new DataFile(dataDir, 'adv');\n\n  this.get = get;\n  this.lookup = lookup;\n  this.lookupFromFiles = lookupFromFiles;\n  this.pushResults = pushResults;\n  this.loadResultSynonyms = loadResultSynonyms;\n  this.loadSynonyms = loadSynonyms;\n  this.lookupSynonyms = lookupSynonyms;\n  this.getSynonyms = getSynonyms;\n  this.getDataFile = getDataFile;\n}\n\nmodule.exports = WordNet;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/wordnet/index_file.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar WordNetFile = require('./wordnet_file'),\n  fs = require('fs'),\n  util = require('util');\n\nfunction getFileSize(path) {\n  var stat = fs.statSync(path);\n  return stat.size;\n}\n\nfunction findPrevEOL(fd, pos, callback) {\n  var buff = new Buffer(1024);\n  if(pos == 0)\n    callback(0);\n  else {\n    fs.read(fd, buff, 0, 1, pos, function(err, count) {\n      if(buff[0] == 10)\n        callback(pos + 1);\n      else\n        findPrevEOL(fd, pos - 1, callback);\n    });\n  }\n}\n\nfunction readLine(fd, pos, callback) {\n  var buff = new Buffer(1024);\n  findPrevEOL(fd, pos, function(pos) {\n    WordNetFile.appendLineChar(fd, pos, 0, buff, callback);\n  });\n}\n\nfunction miss(callback) {\n  callback({status: 'miss'});\n}\n\nfunction findAt(fd, size, pos, lastPos, adjustment, searchKey, callback, lastKey) {\n  if (lastPos == pos || pos >= size) {\n    miss(callback);\n  } else {\n    readLine(fd, pos, function(line) {\n      var tokens = line.split(/\\s+/);\n      var key = tokens[0];\n\n    if(key == searchKey) {\n        callback({status: 'hit', key: key, 'line': line, tokens: tokens});\n      } else if(adjustment == 1 || key == lastKey)  {\n        miss(callback);\n      } else {\n        adjustment = Math.ceil(adjustment * 0.5);\n\n        if (key < searchKey) {\n          findAt(fd, size, pos + adjustment, pos, adjustment, searchKey, callback, key);\n        } else {\n          findAt(fd, size, pos - adjustment, pos, adjustment, searchKey, callback, key);\n        }\n      }\n    });\n  }\n}\n\nfunction find(searchKey, callback) {\n  var indexFile = this;\n\n  indexFile.open(function(err, fd, done) {\n    if(err) {\n      console.log(err);\n    } else {\n      var size = getFileSize(indexFile.filePath) - 1;\n      var pos = Math.ceil(size / 2);\n      findAt(fd, size, pos, null, pos, searchKey,\n        function(result) { callback(result); done(); });\n    }\n  });\n}\n\nfunction lookupFromFile(word, callback) {\n  this.find(word, function(record) {\n    var indexRecord = null;\n\n    if(record.status == 'hit') {\n      var ptrs = [], offsets = [];\n\n      for(var i = 0; i < parseInt(record.tokens[3]); i++)\n        ptrs.push(record.tokens[i]);\n\n      for(var i = 0; i < parseInt(record.tokens[2]); i++)\n        offsets.push(parseInt(record.tokens[ptrs.length + 6 + i], 10));\n\n      indexRecord = {\n        lemma: record.tokens[0],\n        pos: record.tokens[1],\n        ptrSymbol: ptrs,\n        senseCnt:  parseInt(record.tokens[ptrs.length + 4], 10),\n        tagsenseCnt:  parseInt(record.tokens[ptrs.length + 5], 10),\n        synsetOffset:  offsets\n      };\n    }\n\n    callback(indexRecord);\n  });\n}\n\nfunction lookup(word, callback) {\n  this.lookupFromFile(word, callback);\n}\n\nvar IndexFile = function(dataDir, name) {\n  WordNetFile.call(this, dataDir, 'index.' + name);\n};\n\nutil.inherits(IndexFile, WordNetFile);\n\nIndexFile.prototype.lookupFromFile = lookupFromFile;\nIndexFile.prototype.lookup = lookup;\nIndexFile.prototype.find = find;\n\nIndexFile.prototype._findAt = findAt;\n\nmodule.exports = IndexFile;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/wordnet/wordnet_file.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar  fs = require('fs'),\n  path = require('path'),\n  util = require('util');\n\n\nfunction appendLineChar(fd, pos, buffPos, buff, callback) {\n  if(buffPos >= buff.length) {\n    var newBuff = new Buffer(buff.length * 2);\n    buff.copy(newBuff, 0, 0, buff.length);\n    buff = newBuff;\n  }\n\n  fs.read(fd, buff, buffPos, 1, pos, function(err, count) {\n    if(err)\n      console.log(err);\n    else {\n      if(buff[buffPos] == 10 || buffPos == buff.length)\n        callback(buff.slice(0, buffPos).toString('UTF-8'));\n      else {\n        appendLineChar(fd, pos + 1, buffPos + 1, buff, callback);\n      }\n    }\n  });\n}\n\nfunction open(callback) {\n  var filePath = this.filePath;\n\n  fs.open(filePath, 'r', null, function(err, fd) {\n    if (err) {\n        console.log('Unable to open %s', filePath);\n        return;\n    }\n    callback(err, fd, function() {fs.close(fd)});\n  });\n}\n\nvar WordNetFile = function(dataDir, fileName) {\n  this.dataDir = dataDir;\n  this.fileName = fileName;\n  this.filePath = require('path').join(this.dataDir, this.fileName);\n};\n\nWordNetFile.prototype.open = open;\nWordNetFile.appendLineChar = appendLineChar;\n\nmodule.exports = WordNetFile;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/wordnet/data_file.js":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar WordNetFile = require('./wordnet_file'),\n  fs = require('fs'),\n  util = require('util');\n\nfunction get(location, callback) {\n  var buff = new Buffer(4096);\n\n  this.open(function(err, fd, done) {\n    WordNetFile.appendLineChar(fd, location, 0, buff, function(line) {\n      done();\n      var data = line.split('| ');\n      var tokens = data[0].split(/\\s+/);\n      var ptrs = [];\n      var wCnt = parseInt(tokens[3], 16);\n      var synonyms = [];\n\n      for(var i = 0; i < wCnt; i++) {\n        synonyms.push(tokens[4 + i * 2]);\n      }\n\n      var ptrOffset = (wCnt - 1) * 2 + 6;\n      for(var i = 0; i < parseInt(tokens[ptrOffset], 10); i++) {\n        ptrs.push({\n          pointerSymbol: tokens[ptrOffset + 1 + i * 4],\n          synsetOffset: parseInt(tokens[ptrOffset + 2 + i * 4], 10),\n          pos: tokens[ptrOffset + 3 + i * 4],\n          sourceTarget: tokens[ptrOffset + 4 + i * 4]\n        });\n      }\n\n      // break \"gloss\" into definition vs. examples\n      var glossArray = data[1].split(\"; \");\n      var definition = glossArray[0];\n      var examples = glossArray.slice(1);    \n\n      for (var k=0; k < examples.length; k++) {\n        examples[k] = examples[k].replace(/\\\"/g,'').replace(/\\s\\s+/g,'');\n      }\n      \n      callback({\n        synsetOffset: parseInt(tokens[0], 10),\n        lexFilenum: parseInt(tokens[1], 10),\n        pos: tokens[2],\n        wCnt: wCnt,\n        lemma: tokens[4],\n        synonyms: synonyms,\n        lexId: tokens[5],\n        ptrs: ptrs,\n        gloss: data[1],\n        def: definition,\n        exp: examples\n      });\n    });\n  });\n}\n\nvar DataFile = function(dataDir, name) {\n  WordNetFile.call(this, dataDir, 'data.' + name);\n};\n\nutil.inherits(DataFile, WordNetFile);\nDataFile.prototype.get = get;\n\nmodule.exports = DataFile;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/tfidf/tfidf.js":"/*\nCopyright (c) 2011, Rob Ellis, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar _ = require(\"underscore\")._,\n    Tokenizer = require('../tokenizers/regexp_tokenizer').WordTokenizer,\n    tokenizer = new Tokenizer(),\n    stopwords = require('../util/stopwords').words,\n    fs = require('fs');\n\nfunction buildDocument(text, key) {\n    var stopOut;\n\n    if(typeof text === 'string') {\n        text = tokenizer.tokenize(text.toLowerCase());\n        stopOut = true;\n    } else if(!_.isArray(text)) {\n        stopOut = false;\n        return text;\n    }\n\n    return text.reduce(function(document, term) {\n        // next line solves https://github.com/NaturalNode/natural/issues/119\n        if(typeof document[term] === 'function') document[term] = 0;\n        if(!stopOut || stopwords.indexOf(term) < 0)\n            document[term] = (document[term] ? document[term] + 1 : 1);\n        return document;\n    }, {__key: key});\n}\n\nfunction tf(term, document) {\n    return document[term] ? document[term]: 0;\n}\n\nfunction documentHasTerm(term, document) {\n    return document[term] && document[term] > 0;\n}\n\nfunction TfIdf(deserialized) {\n    if(deserialized)\n        this.documents = deserialized.documents;\n    else\n        this.documents = [];\n\n    this._idfCache = {};\n}\n\n// backwards compatibility for < node 0.10\nfunction isEncoding(encoding) {\n    if (typeof Buffer.isEncoding !== 'undefined')\n        return Buffer.isEncoding(encoding);\n    switch ((encoding + '').toLowerCase()) {\n        case 'hex':\n        case 'utf8':\n        case 'utf-8':\n        case 'ascii':\n        case 'binary':\n        case 'base64':\n        case 'ucs2':\n        case 'ucs-2':\n        case 'utf16le':\n        case 'utf-16le':\n        case 'raw':\n            return true;\n    }\n    return false;\n}\n\nmodule.exports = TfIdf;\nTfIdf.tf = tf;\n\nTfIdf.prototype.idf = function(term, force) {\n\n    // Lookup the term in the New term-IDF caching,\n    // this will cut search times down exponentially on large document sets.\n    if(this._idfCache[term] && this._idfCache.hasOwnProperty(term) && force !== true)\n        return this._idfCache[term];\n\n    var docsWithTerm = this.documents.reduce(function(count, document) {\n        return count + (documentHasTerm(term, document) ? 1 : 0);\n    }, 0);\n\n    var idf = 1 + Math.log((this.documents.length) / ( 1 + docsWithTerm ));\n\n    // Add the idf to the term cache and return it\n    this._idfCache[term] = idf;\n    return idf;\n};\n\n// If restoreCache is set to true, all terms idf scores currently cached will be recomputed.\n// Otherwise, the cache will just be wiped clean\nTfIdf.prototype.addDocument = function(document, key, restoreCache) {\n    this.documents.push(buildDocument(document, key));\n\n    // make sure the cache is invalidated when new documents arrive\n    if(restoreCache === true) {\n        for(var term in this._idfCache) {\n            // invoking idf with the force option set will\n            // force a recomputation of the idf, and it will\n            // automatically refresh the cache value.\n            this.idf(term, true);\n        }\n    }   else {\n        this._idfCache = {};\n    }\n};\n\n// If restoreCache is set to true, all terms idf scores currently cached will be recomputed.\n// Otherwise, the cache will just be wiped clean\nTfIdf.prototype.addFileSync = function(path, encoding, key, restoreCache) {\n    if(!encoding)\n        encoding = 'utf8';\n    if(!isEncoding(encoding))\n        throw new Error('Invalid encoding: ' + encoding);\n\n    var document = fs.readFileSync(path, encoding);\n    this.documents.push(buildDocument(document, key));\n\n    // make sure the cache is invalidated when new documents arrive\n    if(restoreCache === true) {\n        for(var term in this._idfCache) {\n            // invoking idf with the force option set will\n            // force a recomputation of the idf, and it will\n            // automatically refresh the cache value.\n            this.idf(term, true);\n        }\n    }\n    else {\n        this._idfCache = {};\n    }\n};\n\nTfIdf.prototype.tfidf = function(terms, d) {\n    var _this = this;\n\n    if(!_.isArray(terms))\n        terms = tokenizer.tokenize(terms.toString().toLowerCase());\n\n    return terms.reduce(function(value, term) {\n        var idf = _this.idf(term);\n        idf = idf === Infinity ? 0 : idf;\n        return value + (tf(term, _this.documents[d]) * idf);\n    }, 0.0);\n};\n\nTfIdf.prototype.listTerms = function(d) {\n    var terms = [];\n\n    for(var term in this.documents[d]) {\n        if(term != '__key')\n           terms.push({term: term, tfidf: this.tfidf(term, d)});\n    }\n\n    return terms.sort(function(x, y) { return y.tfidf - x.tfidf; });\n};\n\nTfIdf.prototype.tfidfs = function(terms, callback) {\n    var tfidfs = new Array(this.documents.length);\n\n    for(var i = 0; i < this.documents.length; i++) {\n        tfidfs[i] = this.tfidf(terms, i);\n\n        if(callback)\n            callback(i, tfidfs[i], this.documents[i].__key);\n    }\n\n    return tfidfs;\n};\n\n// Define a tokenizer other than the default \"WordTokenizer\"\nTfIdf.prototype.setTokenizer = function(t) {\n    if(!_.isFunction(t.tokenize))\n        throw new Error('Expected a valid Tokenizer');\n    tokenizer = t;\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/trie/trie.js":"/*\nCopyright (c) 2014 Ken Koch\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n/** \n * The basis of the TRIE structure.\n **/\nfunction Trie(caseSensitive) {\n\tthis.dictionary = {};\n\tthis.$ = false;\n\n\tif(typeof caseSensitive === \"undefined\") {\n\t\tcaseSensitive = true;\n\t}\n\n\tthis.cs = caseSensitive;\n}\n\n/**\n * Add a single string to the TRIE, returns true if the word was already in the \n * trie.\n **/\nTrie.prototype.addString = function(string) {\n\tif(this.cs === false) {\n\t\tstring = string.toLowerCase();\n\t}\n\n\t// If the string has only one letter, mark this as a word.\n\tif(string.length === 0) {\n\t\tvar wasWord = this.$;\n\t\tthis.$ = true;\n\t\treturn wasWord;\n\t}\n\n\t// Make sure theres a Trie node in our dictionary\n\tvar next = this.dictionary[string[0]];\n\n\tif(!next) {\n\t\tthis.dictionary[string[0]] = new Trie(this.cs);\n\t\tnext = this.dictionary[string[0]];\n\t}\n\n\t// Continue adding the string\n\treturn next.addString(string.substring(1));\n};\n\n/**\n * Add multiple strings to the TRIE\n **/\nTrie.prototype.addStrings = function(list) {\n\tfor(var i in list) {\n\t\tthis.addString(list[i]);\n\t}\n};\n\n/**\n * A function to search the TRIE and return an array of\n * words which have same prefix <prefix>\n * for example if we had the following words in our database:\n * a, ab, bc, cd, abc, abd\n * and we search the string: a\n * we will get :\n * [a, ab, abc, abd]\n **/\nTrie.prototype.keysWithPrefix = function(prefix) {\n    if(this.caseSensitive === false) {\n        prefix = prefix.toLowerCase();\n    }\n\n    function isEmpty (object) {\n        for (var key in object) if (object.hasOwnProperty(key)) return false;\n        return true;\n    }\n\n    function get (node, word) {\n        if(!node) return null;\n        if(word.length == 0) return node;\n        return get(node.dictionary[word[0]], word.substring(1));\n    }\n\n    function recurse ( node, stringAgg, resultsAgg) {\n        if (!node) return;\n\n        // Check if this is a word\n        if (node.$) {\n            resultsAgg.push(stringAgg);\n        }\n\n        if (isEmpty(node.dictionary)) {\n            return ;\n        }\n\n        for (var c in node.dictionary) {\n            recurse (node.dictionary[c],stringAgg + c, resultsAgg);\n        }\n    }\n\n    var results = [];\n    recurse (get(this, prefix), prefix, results);\n    return results;\n};\n\n/** \n * A function to search the given string and return true if it lands\n * on on a word. Essentially testing if the word exists in the database.\n **/\nTrie.prototype.contains = function(string) {\n\tif(this.cs === false) {\n\t\tstring = string.toLowerCase();\n\t}\n\n\tif(string.length === 0) {\n\t\treturn this.$;\n\t}\n\n\t// Otherwise, we need to continue searching\n\tvar firstLetter = string[0];\n\tvar next = this.dictionary[firstLetter];\t\t\n\n\t// If we don't have a node, this isn't a word\n\tif(!next) {\n\t\treturn false;\n\t}\n\n\t// Otherwise continue the search at the next node\n\treturn next.contains(string.substring(1));\n}\n\n/**\n * A function to search the TRIE and return an array of words which were encountered along the way.\n * This will only return words with full prefix matches.\n * for example if we had the following words in our database:\n * a, ab, bc, cd, abc\n * and we searched the string: abcd\n * we would get only:\n * [a, ab, abc]\n **/\nTrie.prototype.findMatchesOnPath = function(search) {\n\tif(this.cs === false) {\n\t\tsearch = search.toLowerCase();\n\t}\n\n\tfunction recurse(node, search, stringAgg, resultsAgg) {\n\t\t// Check if this is a word.\n\t\tif(node.$) {\n\t\t\tresultsAgg.push(stringAgg);\n\t\t}\n\n\t\t// Check if the have completed the seearch\n\t\tif(search.length === 0) {\n\t\t\treturn resultsAgg;\n\t\t}\n\n\t\t// Otherwise, continue searching\n\t\tvar next = node.dictionary[search[0]];\n\t\tif(!next) {\n\t\t\treturn resultsAgg;\n\t\t}\n\t\treturn recurse(next, search.substring(1), stringAgg + search[0], resultsAgg);\n\t};\n\n\treturn recurse(this, search, \"\", []);\n};\n\n/**\n * Returns the longest match and the remaining part that could not be matched.\n * inspired by [NLTK containers.trie.find_prefix](http://nltk.googlecode.com/svn-/trunk/doc/api/nltk.containers.Trie-class.html).\n **/\nTrie.prototype.findPrefix = function(search) {\n\tif(this.cs === false) {\n\t\tsearch = search.toLowerCase();\n\t}\n\t\n\tfunction recurse(node, search, stringAgg, lastWord) {\n\t\t// Check if this is a word\n\t\tif(node.$) {\n\t\t\tlastWord = stringAgg;\n\t\t}\n\n\t\t// Check if we have no more to search\n\t\tif(search.length === 0) {\n\t\t\treturn [lastWord, search];\n\t\t}\n\n\t\t// Continue searching\n\t\tvar next = node.dictionary[search[0]];\n\t\tif(!next) {\n\t\t\treturn [lastWord, search];\n\t\t}\n\t\treturn recurse(next, search.substring(1), stringAgg + search[0], lastWord);\n\t};\n\n\treturn recurse(this, search, \"\", null);\n};\n\n/**\n * Computes the number of actual nodes from this node to the end.\n * Note: This involves traversing the entire structure and may not be\n * good for frequent use.\n **/\nTrie.prototype.getSize = function() { \n\tvar total = 1;\n\tfor(var c in this.dictionary) {\n\t\ttotal += this.dictionary[c].getSize();\n\t}\n\treturn total;\n};\n\n/**\n * EXPORT THE TRIE\n **/\nmodule.exports = Trie;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/analyzers/sentence_analyzer.js":"/*\nCopyright (c) 2011, Rob Ellis, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar _ = require(\"underscore\")._;\n\n/*\n Sentences Analizer Class\n From http://www.writingcentre.uottawa.ca/hypergrammar/sntpurps.html\n\n Take a POS input and analyse it for\n  - Type of Sentense\n     - Interrogative\n       - Tag Questions\n       - \n     - Declarative\n     - Exclamatory \n     - Imperative\n\n  - Parts of a Sentense\n     - Subject\n     - Predicate\n\n  - Show Preposition Phrases\n*/\n\nvar Sentences = function(pos, callback) {\n    this.posObj = pos;\n    this.senType = null;\n    callback(this);\n};\n\nSentences.prototype.part = function(callback) {\n    var subject = [],\n\tpredicat = [],\n\tverbFound = false;\n\t\n    this.prepositionPhrases();\n\t\n    for (var i = 0; i < this.posObj.tags.length; i++) {\n        if (this.posObj.tags[i].pos == \"VB\") {\n            if (i === 0) {\n                verbFound = true;\n            } else {\n                // We need to Test for any EX before the VB\n                if (this.posObj.tags[i - 1].pos != \"EX\") {\n                    verbFound = true;\n                } else {\n                    predicat.push(this.posObj.tags[i].token);\n                }\t\t\t\t\t\n            }\n        }\n\n        // Add Pronoun Phrase (pp) Or Subject Phrase (sp)\n        if (!verbFound) {\n            if (this.posObj.tags[i].pp != true)\n                this.posObj.tags[i].spos = \"SP\";\n            \n            subject.push(this.posObj.tags[i].token);\n        } else {\n            if (this.posObj.tags[i].pp != true)\n                this.posObj.tags[i].spos = \"PP\";\n            \n            predicat.push(this.posObj.tags[i].token)\n        }\n    }\n\t\n    if (subject.length == 0) {\n\tthis.posObj.tags.push({token:\"You\",spos:\"SP\",pos:\"PRP\",added:true});\n    }\n    \n    callback(this);\t\n};\n\n// Takes POS and removes IN to NN or NNS\n// Adds a PP for each prepositionPhrases\nSentences.prototype.prepositionPhrases = function() {\n    var remove = false;\n\n    for (var i = 0; i < this.posObj.tags.length; i++) {\n        if (this.posObj.tags[i].pos.match(\"IN\")) {\n            remove = true;\n        }\n    \n        if (remove) {\n            this.posObj.tags[i].pp = true;\n        }\n    \n        if (this.posObj.tags[i].pos.match(\"NN\")) {\n            remove = false;\n        }\n    }\t\n};\n\nSentences.prototype.subjectToString = function() {\n    return this.posObj.tags.map(function(t){ if (t.spos == \"SP\" || t.spos == \"S\" ) return t.token }).join(' ');\n};\n\nSentences.prototype.predicateToString = function() {\n    return this.posObj.tags.map(function(t){ if (t.spos == \"PP\" || t.spos == \"P\" ) return t.token }).join(' ');\n};\n\nSentences.prototype.implicitYou = function() {\n    for (var i = 0; i < this.posObj.tags.length;i++) {\n        if (this.posObj.tags[i].added) {\n            return true;\n        }\n    }\n    \n    return false;\n};\n\nSentences.prototype.toString = function() {\n    return this.posObj.tags.map(function(t){return t.token}).join(' ');\n};\n\n// This is quick and incomplete.\nSentences.prototype.type = function(callback) {\n    var callback = callback || false;\n\n    // Check for implicit you before popping a tag.\n    var implicitYou = this.implicitYou();\n\n    // FIXME - punct seems useless\n    var lastElement = this.posObj.punct();\n    lastElement = (lastElement.length != 0) ? lastElement.pop() : this.posObj.tags.pop();\n\n    if (lastElement.pos !== \".\") {\n        if (implicitYou) {\n            this.senType = \"COMMAND\";\n        } else if (_([\"WDT\",\"WP\",\"WP$\",\"WRB\"]).contains(this.posObj.tags[0].pos)) {\n            // Sentences that start with: who, what where when why and how, then they are questions\n            this.senType = \"INTERROGATIVE\";\n        } else if (_([\"PRP\"]).contains(lastElement.pos)) {\n            // Sentences that end in a Personal pronoun are most likely questions\n            // eg. We should run away, should we [?]\n            // eg. You want to see that again, do you [?]\n            this.senType = \"INTERROGATIVE\";\n        } else {\n            this.senType = \"UNKNOWN\";\n        }\n            \n    } else {\n        switch(lastElement.token) {\n            case \"?\": this.senType = \"INTERROGATIVE\"; break;\n            case \"!\": this.senType = (implicitYou) ? \"COMMAND\":\"EXCLAMATORY\"; break;\n            case \".\": this.senType = (implicitYou) ? \"COMMAND\":\"DECLARATIVE\";\tbreak;\n        }\n    }\n    \n    if (callback && _(callback).isFunction()) {\n        callback(this);\n    } else {\n        return this.senType;\n    }\n};\n\nmodule.exports = Sentences;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/shortest_path_tree.js":"/*\n Copyright (c) 2014, Lee Wenzhu\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n'use strict';\n\nvar EdgeWeightedDigraph = require('./edge_weighted_digraph'),\n    Topological = require('./topological');\n\n/**\n  *  The ShortestPathTree represents a data type for solving the\n  *  single-source shortest paths problem in edge-weighted directed\n  *  acyclic graphs (DAGs). The edge weights can be positive, negative, or zero.\n  *  This implementation uses a topological-sort based algorithm.\n  *  the distTo() and hasPathTo() methods take\n  *  constant time and the pathTo() method takes time proportional to the\n  *  number of edges in the longest path returned.\n  */\nvar ShortestPathTree = function(digraph, start) {\n    var _this = this;\n    this.edgeTo = [];\n    this.distTo = [];\n    this.distTo[start] = 0.0;\n    this.start = start;\n    this.top = new Topological(digraph);\n    this.top.order().forEach(function(vertex){\n        _this.relaxVertex(digraph, vertex, _this);\n    });\n};\n\nShortestPathTree.prototype.relaxEdge = function(e) {\n    var distTo = this.distTo,\n        edgeTo = this.edgeTo;\n    var v = e.from(), w = e.to();\n    if (distTo[w] > distTo[v] + e.weight) {\n        distTo[w] = distTo[v] + e.weight;\n        edgeTo[w] = e;\n    }\n};\n\n/**\n * relax a vertex v in the specified digraph g\n * @param {EdgeWeightedDigraph} the apecified digraph\n * @param {Vertex} v vertex to be relaxed\n */\nShortestPathTree.prototype.relaxVertex = function(digraph, vertex, tree) {\n    var distTo = tree.distTo;\n    var edgeTo = tree.edgeTo;\n    digraph.getAdj(vertex).forEach(function(edge){\n        var w = edge.to();\n        distTo[w] = /\\d/.test(distTo[w]) ? distTo[w] : Number.MAX_VALUE;\n        distTo[vertex] = distTo[vertex] || 0;\n        if (distTo[w] > distTo[vertex] + edge.weight) {\n            // in case of the result of 0.28+0.34 is 0.62000001\n            distTo[w] = parseFloat((distTo[vertex] + edge.weight).toFixed(2));\n            edgeTo[w] = edge;\n        }\n    });\n\n};\n\nShortestPathTree.prototype.getDistTo = function(v) {\n    return this.distTo[v];\n};\n\nShortestPathTree.prototype.hasPathTo = function(v) {\n    var dist = this.distTo[v];\n    if(v == this.start) return false;\n    return /\\d/.test(dist) ? dist != Number.MAX_VALUE : false;\n};\n\nShortestPathTree.prototype.pathTo = function(v) {\n    if (!this.hasPathTo(v) || v == this.start) return [];\n    var path = [];\n    var edgeTo = this.edgeTo;\n    for (var e = edgeTo[v]; !!e; e = edgeTo[e.from()]) {\n        path.push(e.to());\n    }\n    path.push(this.start);\n    return path.reverse();\n};\n\nmodule.exports = ShortestPathTree;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/edge_weighted_digraph.js":"/*\n Copyright (c) 2014, Lee Wenzhu\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n'use strict';\n\nvar util = require('util'),\n    Bag = require('./bag');\n\nvar DirectedEdge = function(start, end, weight) {\n    this.start = start;\n    this.end = end;\n    this.weight = weight;\n};\n\nDirectedEdge.prototype.weight = function() {\n    return this.weight;\n};\n\nDirectedEdge.prototype.from = function() {\n    return this.start;\n};\n\nDirectedEdge.prototype.to = function() {\n    return this.end;\n};\n\nDirectedEdge.prototype.toString = function() {\n    return util.format('%s -> %s, %s', this.start, this.end, this.weight);\n};\n\nvar EdgeWeightedDigraph = function() {\n    this.edgesNum = 0;\n    this.adj = []; // adjacency list\n};\n\n/**\n * the number of vertexs saved.\n */\nEdgeWeightedDigraph.prototype.v = function() {\n    return this.adj.length;\n};\n\n/**\n * the number of edges saved.\n */\nEdgeWeightedDigraph.prototype.e = function() {\n    return this.edgesNum;\n};\n\nEdgeWeightedDigraph.prototype.add = function(start, end, weight) {\n    var e = new DirectedEdge(start, end, weight);\n    this.addEdge(e);\n};\n\nEdgeWeightedDigraph.prototype.addEdge = function(e) {\n    if(!this.adj[e.from()]) {\n        this.adj[e.from()] = new Bag();\n    }\n    this.adj[e.from()].add(e);\n    this.edgesNum++;\n};\n\n/**\n * use callback on all edges from v.\n */\nEdgeWeightedDigraph.prototype.getAdj = function(v) {\n    if(!this.adj[v]) return [];\n    return this.adj[v].unpack();\n};\n\n/**\n * use callback on all edges.\n */\nEdgeWeightedDigraph.prototype.edges = function() {\n    var adj = this.adj;\n    var list = new Bag();\n    for(var i in adj) {\n        adj[i].unpack().forEach(function(item) {\n            list.add(item);\n        });\n    }\n    return list.unpack();\n};\n\nEdgeWeightedDigraph.prototype.toString = function() {\n    var result = [];\n    var list = this.edges();\n    list.forEach(function(edge) {\n        result.push(edge.toString());\n    });\n    return result.join('\\n');\n};\n\nmodule.exports = EdgeWeightedDigraph;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/bag.js":"/*\n Copyright (c) 2014, Lee Wenzhu\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n'use strict';\n\nfunction Bag() {\n    this.dictionary = [];\n    this.nElement = 0;\n};\n\nBag.prototype.add = function(element) {\n    this.dictionary.push(element);\n    this.nElement++;\n    return this;\n};\n\nBag.prototype.isEmpty = function() {\n    return this.nElement > 0;\n};\n\nBag.prototype.contains = function(item) {\n    return this.dictionary.indexOf(item) >= 0;\n};\n\n/**\n * unpack the bag , and get all items\n */\nBag.prototype.unpack = function() {\n    // return a copy is better than original\n    return this.dictionary.slice();\n};\n\nmodule.exports = Bag;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/topological.js":"/*\n Copyright (c) 2014, Lee Wenzhu\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n'use strict';\n\n/**\n * a topo sort for a digraph\n * @param {Digraph}\n */\nvar Topological = function(g) {\n    this.isDag = true;\n    this.sorted = topoSort(uniqueVertexs(g.edges()), g.edges());\n};\n\nTopological.prototype.isDAG = function() {\n    return this.isDag;\n};\n\n/**\n * get ordered vertexs of digraph\n */\nTopological.prototype.order = function() {\n    return this.sorted.slice();\n};\n\n/**\n * @param {Array} all vertex in digraph\n * @param {Object} all edges in the digraph\n */\nfunction topoSort(vertexs, edges) {\n    var sorted = [];\n    var cursor = vertexs.length,\n        visited = {},\n        i = cursor;\n    while (i--) {\n        if (!visited[i]) visit(vertexs[i], i, []);\n    }\n\n    return sorted.reverse();\n\n    function visit(vertex, i, predecessors) {\n        if(predecessors.indexOf(vertex) >= 0) {\n            throw new Error('Cyclic dependency:' + JSON.stringify(vertex));\n        }\n\n        if(visited[i]) return;\n        visited[i] = true;\n\n        var outgoing = edges.filter(function(edge) {\n            return edge.to() === vertex;\n        });\n\n        var preds = [];\n        if(outgoing.length > 0) {\n            preds = predecessors.concat(vertex);\n        }\n        var from;\n        outgoing.forEach(function(edge) {\n            from = edge.from();\n            visit(from, vertexs.indexOf(from), preds);\n        });\n\n        sorted[--cursor] = vertex;\n    };\n};\n\n\nfunction uniqueVertexs(edges) {\n    var vertexs = [];\n    var from, to;\n    edges.forEach(function(edge) {\n        from = edge.from();\n        to = edge.to();\n        if (vertexs.indexOf(from) < 0) vertexs.push(from);\n        if (vertexs.indexOf(to) < 0) vertexs.push(to);\n    });\n    return vertexs;\n};\n\nmodule.exports = Topological;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/spellcheck/spellcheck.js":"\nvar Trie = require('../trie/trie');\n\n// Probabilistic spellchecker based on http://norvig.com/spell-correct.html\n// The general idea is simple. Given a word, the spellchecker calculates all strings that are some user-defined edit distance away. Of those many candidates, it filters the ones that are not words and then returns an array of possible corrections in order of decreasing probability, based on the edit distance and the candidate's frequency in the input corpus\n// Words that are an edit distance of n away from the mispelled word are considered infinitely more probable than words that are of an edit distance >n\n\n// wordlist is a corpus (an array) from which word probabilities are calculated (so something like /usr/share/dict/words (on OSX) will work okay, but real world text will work better)\nfunction Spellcheck(wordlist) {\n    this.trie = new Trie();\n    this.trie.addStrings(wordlist);\n    this.word2frequency = {};\n    for(var i in wordlist) {\n        if(!this.word2frequency[wordlist[i]]) {\n            this.word2frequency[wordlist[i]] = 0;\n        }\n        this.word2frequency[wordlist[i]]++;\n    }\n}\n\nSpellcheck.prototype.isCorrect = function(word) {\n    return this.trie.contains(word);\n}\n\n// Returns a list of suggested corrections, from highest to lowest probability \n// maxDistance is the maximum edit distance \n// According to Norvig, literature suggests that 80% to 95% of spelling errors are an edit distance of 1 away from the correct word. This is good, because there are roughly 54n+25 strings 1 edit distance away from any given string of length n. So after maxDistance = 2, this becomes very slow.\nSpellcheck.prototype.getCorrections = function(word, maxDistance) {\n    var self = this;\n    if(!maxDistance) maxDistance = 1;\n    var edits = this.editsWithMaxDistance(word, maxDistance);\n    edits = edits.slice(1,edits.length);\n    edits = edits.map(function(editList) {\n       return editList.filter(function(word) { return self.isCorrect(word); })\n                      .map(function(word) { return [word, self.word2frequency[word]]; })\n                      .sort(function(a,b) { return a[1] > b[1] ? -1 : 1; })\n                      .map(function(wordscore) { return wordscore[0]; });\n    });\n    var flattened = [];\n    for(var i in edits) {\n        if(edits[i].length) flattened = flattened.concat(edits[i]);\n    }\n    return flattened.filter(function (v, i, a) { return a.indexOf(v) == i });\n}\n\n// Returns all edits that are 1 edit-distance away from the input word\nSpellcheck.prototype.edits = function(word) {\n    var alphabet = 'abcdefghijklmnopqrstuvwxyz';\n    var edits = [];\n    for(var i=0; i<word.length+1; i++) {\n        if(i>0) edits.push(word.slice(0,i-1)+word.slice(i,word.length)); // deletes\n        if(i>0 && i<word.length+1) edits.push(word.slice(0,i-1) + word.slice(i,i+1) + word.slice(i-1, i) + word.slice(i+1,word.length)); // transposes\n        for(var k=0; k<alphabet.length; k++) {\n            if(i>0) edits.push(word.slice(0,i-1)+alphabet[k]+word.slice(i,word.length)); // replaces\n            edits.push(word.slice(0,i)+alphabet[k]+word.slice(i,word.length)); // inserts\n        }\n    }\n    // Deduplicate edits\n    edits = edits.filter(function (v, i, a) { return a.indexOf(v) == i });\n    return edits;\n}\n\n// Returns all edits that are up to \"distance\" edit distance away from the input word\nSpellcheck.prototype.editsWithMaxDistance = function(word, distance) { \n    return this.editsWithMaxDistanceHelper(distance, [[word]]);\n}\n\nSpellcheck.prototype.editsWithMaxDistanceHelper = function(distanceCounter, distance2edits) {\n    if(distanceCounter == 0) return distance2edits;\n    var currentDepth = distance2edits.length-1;\n    var words = distance2edits[currentDepth];\n    var edits = this.edits(words[0]);\n    distance2edits[currentDepth+1] = [];\n    for(var i in words) {\n        distance2edits[currentDepth+1] = distance2edits[currentDepth+1].concat(this.edits(words[i]));\n    }\n    return this.editsWithMaxDistanceHelper(distanceCounter-1, distance2edits);\n}\n\nmodule.exports = Spellcheck;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/util/longest_path_tree.js":"/*\n Copyright (c) 2014, Lee Wenzhu\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n'use strict';\n\nvar EdgeWeightedDigraph = require('./edge_weighted_digraph'),\n    Topological = require('./topological');\n\n/**\n  *  The LongestPathTree represents a data type for solving the\n  *  single-source longest paths problem in edge-weighted directed\n  *  acyclic graphs (DAGs). The edge weights can be positive, negative, or zero.\n  *  This implementation uses a topological-sort based algorithm.\n  *  the distTo() and hasPathTo() methods take\n  *  constant time and the pathTo() method takes time proportional to the\n  *  number of edges in the longest path returned.\n  */\nvar LongestPathTree = function(digraph, start) {\n    var _this = this;\n    this.edgeTo = [];\n    this.distTo = [];\n    this.distTo[start] = 0.0;\n    this.start = start;\n    this.top = new Topological(digraph);\n    this.top.order().forEach(function(vertex){\n        _this.relaxVertex(digraph, vertex, _this);\n    });\n};\n\nLongestPathTree.prototype.relaxEdge = function(e) {\n    var distTo = this.distTo,\n        edgeTo = this.edgeTo;\n    var v = e.from(), w = e.to();\n    if (distTo[w] < distTo[v] + e.weight) {\n        distTo[w] = distTo[v] + e.weight;\n        edgeTo[w] = e;\n    }\n};\n\n/**\n * relax a vertex v in the specified digraph g\n * @param {EdgeWeightedDigraph} the apecified digraph\n * @param {Vertex} v vertex to be relaxed\n */\nLongestPathTree.prototype.relaxVertex = function(digraph, vertex, tree) {\n    var distTo = tree.distTo;\n    var edgeTo = tree.edgeTo;\n\n    digraph.getAdj(vertex).forEach(function(edge){\n        var w = edge.to();\n        distTo[w] = distTo[w] || 0.0;\n        distTo[vertex] = distTo[vertex] || 0.0;\n        if (distTo[w] < distTo[vertex] + edge.weight) {\n            // in case of the result of 0.28+0.34 is 0.62000001\n            distTo[w] = parseFloat((distTo[vertex] + edge.weight).toFixed(2));\n            edgeTo[w] = edge;\n        }\n    });\n\n};\n\nLongestPathTree.prototype.getDistTo = function(v) {\n    return this.distTo[v];\n};\n\nLongestPathTree.prototype.hasPathTo = function(v) {\n    return !!this.distTo[v];\n};\n\nLongestPathTree.prototype.pathTo = function(v) {\n    if (!this.hasPathTo(v)) return [];\n    var path = [];\n    var edgeTo = this.edgeTo;\n    for (var e = edgeTo[v]; !!e; e = edgeTo[e.from()]) {\n        path.push(e.to());\n    }\n    path.push(this.start);\n    return path.reverse();\n};\n\nmodule.exports = LongestPathTree;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/ngrams/ngrams.js":"/*\nCopyright (c) 2011, Rob Ellis, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar _ = require(\"underscore\")._,\n    Tokenizer = require('../tokenizers/regexp_tokenizer').WordTokenizer,\n    tokenizer = new Tokenizer();\n\nexports.setTokenizer = function(t) {\n    if(!_.isFunction(t.tokenize))\n        throw new Error('Expected a valid Tokenizer');\n    tokenizer = t;\n}\n\nexports.ngrams = function(sequence, n, startSymbol, endSymbol) {\n    return ngrams(sequence, n, startSymbol, endSymbol);\n}\n\nexports.bigrams = function(sequence, startSymbol, endSymbol) {\n    return ngrams(sequence, 2, startSymbol, endSymbol);\n}\n\nexports.trigrams = function(sequence, startSymbol, endSymbol) {\n    return ngrams(sequence, 3, startSymbol, endSymbol);\n}\n\nexports.multrigrams = function(sequence, n, startSymbol, endSymbol) {\n    return ngrams(sequence, n, startSymbol, endSymbol);\n}\n\nvar ngrams = function(sequence, n, startSymbol, endSymbol) {\n    var result = [];\n    \n    if (!_(sequence).isArray()) {\n        sequence = tokenizer.tokenize(sequence);\n    }\n\n    var count = _.max([0, sequence.length - n + 1]);\n\n    // Check for left padding    \n    if(typeof startSymbol !== \"undefined\" && startSymbol !== null) {\n        // Create an array of (n) start symbols\n        var blanks = [];\n        for(var i = 0 ; i < n ; i++) {\n            blanks.push(startSymbol);\n        }\n\n        // Create the left padding\n        for(var p = n - 1 ; p > 0 ; p--) {\n            // Create a tuple of (p) start symbols and (n - p) words\n            result.push(blanks.slice(0, p).concat(sequence.slice(0, n - p)));\n        }\n    }\n\n    // Build the complete ngrams\n    for (var i = 0; i < count; i++) {\n        result.push(sequence.slice(i, i + n));\n    }\n\n    // Check for right padding\n    if(typeof endSymbol !== \"undefined\" && endSymbol !== null) {\n        // Create an array of (n) end symbols\n        var blanks = [];\n        for(var i = 0 ; i < n ; i++) {\n            blanks.push(endSymbol);\n        }\n\n        // create the right padding\n        for(var p = n - 1 ; p > 0 ; p--) {\n            // Create a tuple of (p) start symbols and (n - p) words\n            result.push(sequence.slice(sequence.length - p, sequence.length).concat(blanks.slice(0, n - p)));\n        }\n    }\n    \n    return result;\n}\n\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/ngrams/ngrams_zh.js":"/*\nCopyright (c) 2014, Lee Wenzhu\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nvar _ = require(\"underscore\")._;\n\nexports.ngrams = function(sequence, n, startSymbol, endSymbol) {\n    return ngrams(sequence, n, startSymbol, endSymbol);\n}\n\nexports.bigrams = function(sequence, startSymbol, endSymbol) {\n    return ngrams(sequence, 2, startSymbol, endSymbol);\n}\n\nexports.trigrams = function(sequence, startSymbol, endSymbol) {\n    return ngrams(sequence, 3, startSymbol, endSymbol);\n}\n\nvar ngrams = function(sequence, n, startSymbol, endSymbol) {\n    var result = [], i;\n    \n    if (!_(sequence).isArray()) {\n        sequence = sequence.split('');\n    }\n\n    var count = _.max([0, sequence.length - n + 1]);\n\n    // Check for left padding    \n    if(typeof startSymbol !== \"undefined\" && startSymbol !== null) {\n        // Create an array of (n) start symbols\n        var blanks = [];\n        for(i = 0 ; i < n ; i++) {\n            blanks.push(startSymbol);\n        }\n\n        // Create the left padding\n        for(var p = n - 1 ; p > 0 ; p--) {\n            // Create a tuple of (p) start symbols and (n - p) words\n            result.push(blanks.slice(0, p).concat(sequence.slice(0, n - p)));\n        }\n    }\n\n    // Build the complete ngrams\n    for (i = 0; i < count; i++) {\n        result.push(sequence.slice(i, i + n));\n    }\n\n    // Check for right padding\n    if(typeof endSymbol !== \"undefined\" && endSymbol !== null) {\n        // Create an array of (n) end symbols\n        var blanks = [];\n        for(var i = 0 ; i < n ; i++) {\n            blanks.push(endSymbol);\n        }\n\n        // create the right padding\n        for(var p = n - 1 ; p > 0 ; p--) {\n            // Create a tuple of (p) start symbols and (n - p) words\n            result.push(sequence.slice(sequence.length - p, sequence.length).concat(blanks.slice(0, n - p)));\n        }\n    }\n    \n    return result;\n};\n\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/distance/jaro-winkler_distance.js":"/*\r\nCopyright (c) 2012, Adam Phillabaum, Chris Umbel\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in\r\nall copies or substantial portions of the Software.\r\n\r\nUnless otherwise stated by a specific section of code\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\r\nTHE SOFTWARE.\r\n*/\r\n\r\n// Computes the Jaro distance between two string -- intrepreted from:\r\n// http://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance\r\n// s1 is the first string to compare\r\n// s2 is the second string to compare\r\nfunction distance(s1, s2) {\r\n    if (typeof(s1) !== \"string\" || typeof(s2) !== \"string\") {\r\n        return 0;\r\n    }\r\n\r\n    if (s1.length === 0 || s2.length === 0) {\r\n        return 0;\r\n    }\r\n\r\n    s1 = s1.toLowerCase(), s2 = s2.toLowerCase();\r\n\r\n    var matchWindow = (Math.floor(Math.max(s1.length, s2.length) / 2.0)) - 1;\r\n    var matches1 = new Array(s1.length);\r\n    var matches2 = new Array(s2.length);\r\n    var m = 0; // number of matches\r\n    var t = 0; // number of transpositions\r\n    var i = 0; // index for string 1\r\n    var k = 0; // index for string 2\r\n\r\n    //debug helpers\r\n    //console.log(\"s1: \" + s1 + \"; s2: \" + s2);\r\n    //console.log(\" - matchWindow: \" + matchWindow);\r\n\r\n    for (i = 0; i < s1.length; i++) { // loop to find matched characters\r\n        var start = Math.max(0, (i - matchWindow)); // use the higher of the window diff\r\n        var end = Math.min((i + matchWindow + 1), s2.length); // use the min of the window and string 2 length\r\n\r\n        for (k = start; k < end; k++) { // iterate second string index\r\n            if (matches2[k]) { // if second string character already matched\r\n                continue;\r\n            }\r\n            if (s1[i] !== s2[k]) { // characters don't match\r\n                continue;\r\n            }\r\n\r\n            // assume match if the above 2 checks don't continue\r\n            matches1[i] = true;\r\n            matches2[k] = true;\r\n            m++;\r\n            break;\r\n        }\r\n    }\r\n\r\n    // nothing matched\r\n    if (m === 0) {\r\n        return 0.0;\r\n    }\r\n\r\n    k = 0; // reset string 2 index\r\n    for(i = 0; i < s1.length; i++) { // loop to find transpositions\r\n        if (!matches1[i]) { // non-matching character\r\n            continue;\r\n        }\r\n        while(!matches2[k]) { // move k index to the next match\r\n            k++;\r\n        }\r\n        if (s1[i] !== s2[k]) { // if the characters don't match, increase transposition\r\n            t++;\r\n        }\r\n        k++; // iterate k index normally\r\n    }\r\n\r\n    // transpositions divided by 2\r\n    t = t / 2.0;\r\n\r\n    return ((m / s1.length) + (m / s2.length) + ((m - t) / m)) / 3.0;\r\n}\r\n\r\n// Computes the Winkler distance between two string -- intrepreted from:\r\n// http://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance\r\n// s1 is the first string to compare\r\n// s2 is the second string to compare\r\n// dj is the Jaro Distance (if you've already computed it), leave blank and the method handles it\r\nfunction JaroWinklerDistance(s1, s2, dj) {\r\n    if (s1 === s2) {\r\n        return 1;\r\n    } else {\r\n        var jaro = (typeof(dj) === 'undefined') ? distance(s1,s2) : dj;\r\n        var p = 0.1; // default scaling factor\r\n        var l = 0 // length of the matching prefix\r\n        while(s1[l] === s2[l] && l < 4) {\r\n            l++;\r\n        }\r\n\r\n        return jaro + l * p * (1 - jaro);\r\n    }\r\n}\r\nmodule.exports = JaroWinklerDistance;\r\n\r\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/distance/levenshtein_distance.js":"/*\nCopyright (c) 2012, Sid Nallu, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n/*\n * contribution by sidred123\n */\n\n/*\n * Compute the Levenshtein distance between two strings.\n * Algorithm based from Speech and Language Processing - Daniel Jurafsky and James H. Martin.\n */\n\nfunction LevenshteinDistance (source, target, options) {\n    options = options || {};\n    if(isNaN(options.insertion_cost)) options.insertion_cost = 1;\n    if(isNaN(options.deletion_cost)) options.deletion_cost = 1;\n    if(isNaN(options.substitution_cost)) options.substitution_cost = 1;\n\n    var sourceLength = source.length;\n    var targetLength = target.length;\n    var distanceMatrix = [[0]];\n\n    for (var row =  1; row <= sourceLength; row++) {\n        distanceMatrix[row] = [];\n        distanceMatrix[row][0] = distanceMatrix[row-1][0] + options.deletion_cost;\n    }\n\n    for (var column = 1; column <= targetLength; column++) {\n        distanceMatrix[0][column] = distanceMatrix[0][column-1] + options.insertion_cost;\n    }\n\n    for (var row = 1; row <= sourceLength; row++) {\n        for (var column = 1; column <= targetLength; column++) {\n            var costToInsert = distanceMatrix[row][column-1] + options.insertion_cost;\n            var costToDelete = distanceMatrix[row-1][column] + options.deletion_cost;\n\n            var sourceElement = source[row-1];\n            var targetElement = target[column-1];\n            var costToSubstitute = distanceMatrix[row-1][column-1];\n            if (sourceElement !== targetElement) {\n                costToSubstitute = costToSubstitute + options.substitution_cost;\n            }\n            distanceMatrix[row][column] = Math.min(costToInsert, costToDelete, costToSubstitute);\n        }\n    }\n    return distanceMatrix[sourceLength][targetLength];\n}\n\nmodule.exports = LevenshteinDistance;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/distance/dice_coefficient.js":"/*\nCopyright (c) 2011, John Crepezzi, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n// Get all of the pairs of letters for a string\nvar letterPairs = function (str) {\n  var numPairs = str.length - 1;\n  var pairs = new Array(numPairs);\n  for (var i = 0; i < numPairs; i++) {\n    pairs[i] = str.substring(i, i + 2);\n  }\n  return pairs;\n};\n\n// Get all of the pairs in all of the words for a string\nvar wordLetterPairs = function (str) {\n  var allPairs = [], pairs;\n  var words = str.split(/\\s+/);\n  for (var i = 0; i < words.length; i++) {\n    pairs = letterPairs(words[i]);\n    allPairs.push.apply(allPairs, pairs);\n  }\n  return allPairs;\n};\n\n// Perform some sanitization steps\nvar sanitize = function (str) {\n  return str.toLowerCase().replace(/^\\s+|\\s+$/g, '');\n};\n\n// Compare two strings, and spit out a number from 0-1\nvar compare = function (str1, str2) {\n  var sanitized_str1 = sanitize(str1);\n  var sanitized_str2 = sanitize(str2);\n  var pairs1 = wordLetterPairs(sanitized_str1);\n  var pairs2 = wordLetterPairs(sanitized_str2);\n  var intersection = 0, union = pairs1.length + pairs2.length;\n  if (union === 0) {\n      if (sanitized_str1 === sanitized_str2) {\n          return 1;\n      } else {\n          return 0;\n      }\n  } else {\n    var i, j, pair1, pair2;\n    for (i = 0; i < pairs1.length; i++) {\n      pair1 = pairs1[i];\n      for (j = 0; j < pairs2.length; j++) {\n        pair2 = pairs2[j];\n        if (pair1 == pair2) {\n          intersection ++;\n          delete pairs2[j];\n          break;\n        }\n      }\n    }\n    return 2 * intersection / union;\n  }\n};\n\nmodule.exports = compare;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/normalizers/normalizer.js":"/*\n Copyright (c) 2013, Kenneth Koch\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n\n/**\n * The english normalizer will create a string in which all contractions are expanded to their \n * full meaning (i.e. \"we'll\" becomes \"we will\"). \n *\n * It currently works off a conversion table and falls back to a set of rules.\n * Since it is applied first, the conversion table provides an \"override\" for the rules.\n **/\nvar replacer = require('../util/utils').replacer;\n\nvar conversionTable = {\n\t\"can't\":\"can not\",\n\t\"won't\":\"will not\",\n\t\"couldn't've\":\"could not have\",\n\t\"i'm\":\"I am\",\n\t\"how'd\":\"how did\"\n};\n\nvar rules = [\n\t{ regex: /([azAZ]*)n\\'[tT]/g, output: \"$1 not\" },\n\t{ regex: /([azAZ]*)\\'[sS]/g, output: \"$1 is\" },\n\t{ regex: /([azAZ]*)\\'[lL][lL]/g, output: \"$1 will\" },\n\t{ regex: /([azAZ]*)\\'[rR][eE]/g, output: \"$1 are\" },\n\t{ regex: /([azAZ]*)\\'[vV][eE]/g, output: \"$1 have\" },\n\t{ regex: /([azAZ]*)\\'[dD]/g, output: \"$1 would\" }\n];\n\n// Accepts a list of tokens to expand.\nvar normalize_tokens = function(tokens) {\n\tif(typeof tokens === \"string\") {\n\t\ttokens = [tokens];\n\t}\n        var results = [];\n\tvar rule_count = rules.length;\n\tvar num_tokens = tokens.length;\n        var i, token, r, rule;\n    \n        for (i = 0; i < num_tokens; i++) {\n            token = tokens[i];\n            // Check the conversion table\n            if (conversionTable[token.toLowerCase()]) {\n                results = results.concat(conversionTable[token.toLowerCase()].split(/\\W+/));\n            }\n            \n            // Apply the rules\n            else {\n                var matched = false;\n                for ( r = 0; r < rule_count; r++) {\n                    rule = rules[r];\n                    if (token.match(rule.regex)) {\n                        results = results.concat(token.replace(rule.regex, rule.output).split(/\\W+/));\n                        matched = true;\n                        break;\n                    }\n                }\n                if (!matched) {\n                    results.push(token);\n                }\n            }\n        }\n\n\treturn results;\n};\n\n\n\n\n\n// export the relevant stuff.\nexports.normalize_tokens = normalize_tokens;\n\n\n\n\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/normalizers/remove_diacritics.js":"/*\n Copyright (c) 2012, Alexy Maslennikov\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n\n/**\n * Script to remove diacritics. Original source was taken from\n * http://lehelk.com/2011/05/06/script-to-remove-diacritics/\n */\nvar diacriticsRemovalMap = [\n    {'base':'A', 'letters':/[\\u0041\\u24B6\\uFF21\\u00C0\\u00C1\\u00C2\\u1EA6\\u1EA4\\u1EAA\\u1EA8\\u00C3\\u0100\\u0102\\u1EB0\\u1EAE\\u1EB4\\u1EB2\\u0226\\u01E0\\u00C4\\u01DE\\u1EA2\\u00C5\\u01FA\\u01CD\\u0200\\u0202\\u1EA0\\u1EAC\\u1EB6\\u1E00\\u0104\\u023A\\u2C6F]/g},\n    {'base':'AA','letters':/[\\uA732]/g},\n    {'base':'AE','letters':/[\\u00C6\\u01FC\\u01E2]/g},\n    {'base':'AO','letters':/[\\uA734]/g},\n    {'base':'AU','letters':/[\\uA736]/g},\n    {'base':'AV','letters':/[\\uA738\\uA73A]/g},\n    {'base':'AY','letters':/[\\uA73C]/g},\n    {'base':'B', 'letters':/[\\u0042\\u24B7\\uFF22\\u1E02\\u1E04\\u1E06\\u0243\\u0182\\u0181]/g},\n    {'base':'C', 'letters':/[\\u0043\\u24B8\\uFF23\\u0106\\u0108\\u010A\\u010C\\u00C7\\u1E08\\u0187\\u023B\\uA73E]/g},\n    {'base':'D', 'letters':/[\\u0044\\u24B9\\uFF24\\u1E0A\\u010E\\u1E0C\\u1E10\\u1E12\\u1E0E\\u0110\\u018B\\u018A\\u0189\\uA779]/g},\n    {'base':'DZ','letters':/[\\u01F1\\u01C4]/g},\n    {'base':'Dz','letters':/[\\u01F2\\u01C5]/g},\n    {'base':'E', 'letters':/[\\u0045\\u24BA\\uFF25\\u00C8\\u00C9\\u00CA\\u1EC0\\u1EBE\\u1EC4\\u1EC2\\u1EBC\\u0112\\u1E14\\u1E16\\u0114\\u0116\\u00CB\\u1EBA\\u011A\\u0204\\u0206\\u1EB8\\u1EC6\\u0228\\u1E1C\\u0118\\u1E18\\u1E1A\\u0190\\u018E]/g},\n    {'base':'F', 'letters':/[\\u0046\\u24BB\\uFF26\\u1E1E\\u0191\\uA77B]/g},\n    {'base':'G', 'letters':/[\\u0047\\u24BC\\uFF27\\u01F4\\u011C\\u1E20\\u011E\\u0120\\u01E6\\u0122\\u01E4\\u0193\\uA7A0\\uA77D\\uA77E]/g},\n    {'base':'H', 'letters':/[\\u0048\\u24BD\\uFF28\\u0124\\u1E22\\u1E26\\u021E\\u1E24\\u1E28\\u1E2A\\u0126\\u2C67\\u2C75\\uA78D]/g},\n    {'base':'I', 'letters':/[\\u0049\\u24BE\\uFF29\\u00CC\\u00CD\\u00CE\\u0128\\u012A\\u012C\\u0130\\u00CF\\u1E2E\\u1EC8\\u01CF\\u0208\\u020A\\u1ECA\\u012E\\u1E2C\\u0197]/g},\n    {'base':'J', 'letters':/[\\u004A\\u24BF\\uFF2A\\u0134\\u0248]/g},\n    {'base':'K', 'letters':/[\\u004B\\u24C0\\uFF2B\\u1E30\\u01E8\\u1E32\\u0136\\u1E34\\u0198\\u2C69\\uA740\\uA742\\uA744\\uA7A2]/g},\n    {'base':'L', 'letters':/[\\u004C\\u24C1\\uFF2C\\u013F\\u0139\\u013D\\u1E36\\u1E38\\u013B\\u1E3C\\u1E3A\\u0141\\u023D\\u2C62\\u2C60\\uA748\\uA746\\uA780]/g},\n    {'base':'LJ','letters':/[\\u01C7]/g},\n    {'base':'Lj','letters':/[\\u01C8]/g},\n    {'base':'M', 'letters':/[\\u004D\\u24C2\\uFF2D\\u1E3E\\u1E40\\u1E42\\u2C6E\\u019C]/g},\n    {'base':'N', 'letters':/[\\u004E\\u24C3\\uFF2E\\u01F8\\u0143\\u00D1\\u1E44\\u0147\\u1E46\\u0145\\u1E4A\\u1E48\\u0220\\u019D\\uA790\\uA7A4]/g},\n    {'base':'NJ','letters':/[\\u01CA]/g},\n    {'base':'Nj','letters':/[\\u01CB]/g},\n    {'base':'O', 'letters':/[\\u004F\\u24C4\\uFF2F\\u00D2\\u00D3\\u00D4\\u1ED2\\u1ED0\\u1ED6\\u1ED4\\u00D5\\u1E4C\\u022C\\u1E4E\\u014C\\u1E50\\u1E52\\u014E\\u022E\\u0230\\u00D6\\u022A\\u1ECE\\u0150\\u01D1\\u020C\\u020E\\u01A0\\u1EDC\\u1EDA\\u1EE0\\u1EDE\\u1EE2\\u1ECC\\u1ED8\\u01EA\\u01EC\\u00D8\\u01FE\\u0186\\u019F\\uA74A\\uA74C]/g},\n    {'base':'OE','letters':/[\\u0152]/g},\n    {'base':'OI','letters':/[\\u01A2]/g},\n    {'base':'OO','letters':/[\\uA74E]/g},\n    {'base':'OU','letters':/[\\u0222]/g},\n    {'base':'P', 'letters':/[\\u0050\\u24C5\\uFF30\\u1E54\\u1E56\\u01A4\\u2C63\\uA750\\uA752\\uA754]/g},\n    {'base':'Q', 'letters':/[\\u0051\\u24C6\\uFF31\\uA756\\uA758\\u024A]/g},\n    {'base':'R', 'letters':/[\\u0052\\u24C7\\uFF32\\u0154\\u1E58\\u0158\\u0210\\u0212\\u1E5A\\u1E5C\\u0156\\u1E5E\\u024C\\u2C64\\uA75A\\uA7A6\\uA782]/g},\n    {'base':'S', 'letters':/[\\u0053\\u24C8\\uFF33\\u1E9E\\u015A\\u1E64\\u015C\\u1E60\\u0160\\u1E66\\u1E62\\u1E68\\u0218\\u015E\\u2C7E\\uA7A8\\uA784]/g},\n    {'base':'T', 'letters':/[\\u0054\\u24C9\\uFF34\\u1E6A\\u0164\\u1E6C\\u021A\\u0162\\u1E70\\u1E6E\\u0166\\u01AC\\u01AE\\u023E\\uA786]/g},\n    {'base':'TZ','letters':/[\\uA728]/g},\n    {'base':'U', 'letters':/[\\u0055\\u24CA\\uFF35\\u00D9\\u00DA\\u00DB\\u0168\\u1E78\\u016A\\u1E7A\\u016C\\u00DC\\u01DB\\u01D7\\u01D5\\u01D9\\u1EE6\\u016E\\u0170\\u01D3\\u0214\\u0216\\u01AF\\u1EEA\\u1EE8\\u1EEE\\u1EEC\\u1EF0\\u1EE4\\u1E72\\u0172\\u1E76\\u1E74\\u0244]/g},\n    {'base':'V', 'letters':/[\\u0056\\u24CB\\uFF36\\u1E7C\\u1E7E\\u01B2\\uA75E\\u0245]/g},\n    {'base':'VY','letters':/[\\uA760]/g},\n    {'base':'W', 'letters':/[\\u0057\\u24CC\\uFF37\\u1E80\\u1E82\\u0174\\u1E86\\u1E84\\u1E88\\u2C72]/g},\n    {'base':'X', 'letters':/[\\u0058\\u24CD\\uFF38\\u1E8A\\u1E8C]/g},\n    {'base':'Y', 'letters':/[\\u0059\\u24CE\\uFF39\\u1EF2\\u00DD\\u0176\\u1EF8\\u0232\\u1E8E\\u0178\\u1EF6\\u1EF4\\u01B3\\u024E\\u1EFE]/g},\n    {'base':'Z', 'letters':/[\\u005A\\u24CF\\uFF3A\\u0179\\u1E90\\u017B\\u017D\\u1E92\\u1E94\\u01B5\\u0224\\u2C7F\\u2C6B\\uA762]/g},\n    {'base':'a', 'letters':/[\\u0061\\u24D0\\uFF41\\u1E9A\\u00E0\\u00E1\\u00E2\\u1EA7\\u1EA5\\u1EAB\\u1EA9\\u00E3\\u0101\\u0103\\u1EB1\\u1EAF\\u1EB5\\u1EB3\\u0227\\u01E1\\u00E4\\u01DF\\u1EA3\\u00E5\\u01FB\\u01CE\\u0201\\u0203\\u1EA1\\u1EAD\\u1EB7\\u1E01\\u0105\\u2C65\\u0250]/g},\n    {'base':'aa','letters':/[\\uA733]/g},\n    {'base':'ae','letters':/[\\u00E6\\u01FD\\u01E3]/g},\n    {'base':'ao','letters':/[\\uA735]/g},\n    {'base':'au','letters':/[\\uA737]/g},\n    {'base':'av','letters':/[\\uA739\\uA73B]/g},\n    {'base':'ay','letters':/[\\uA73D]/g},\n    {'base':'b', 'letters':/[\\u0062\\u24D1\\uFF42\\u1E03\\u1E05\\u1E07\\u0180\\u0183\\u0253]/g},\n    {'base':'c', 'letters':/[\\u0063\\u24D2\\uFF43\\u0107\\u0109\\u010B\\u010D\\u00E7\\u1E09\\u0188\\u023C\\uA73F\\u2184]/g},\n    {'base':'d', 'letters':/[\\u0064\\u24D3\\uFF44\\u1E0B\\u010F\\u1E0D\\u1E11\\u1E13\\u1E0F\\u0111\\u018C\\u0256\\u0257\\uA77A]/g},\n    {'base':'dz','letters':/[\\u01F3\\u01C6]/g},\n    {'base':'e', 'letters':/[\\u0065\\u24D4\\uFF45\\u00E8\\u00E9\\u00EA\\u1EC1\\u1EBF\\u1EC5\\u1EC3\\u1EBD\\u0113\\u1E15\\u1E17\\u0115\\u0117\\u00EB\\u1EBB\\u011B\\u0205\\u0207\\u1EB9\\u1EC7\\u0229\\u1E1D\\u0119\\u1E19\\u1E1B\\u0247\\u025B\\u01DD]/g},\n    {'base':'f', 'letters':/[\\u0066\\u24D5\\uFF46\\u1E1F\\u0192\\uA77C]/g},\n    {'base':'g', 'letters':/[\\u0067\\u24D6\\uFF47\\u01F5\\u011D\\u1E21\\u011F\\u0121\\u01E7\\u0123\\u01E5\\u0260\\uA7A1\\u1D79\\uA77F]/g},\n    {'base':'h', 'letters':/[\\u0068\\u24D7\\uFF48\\u0125\\u1E23\\u1E27\\u021F\\u1E25\\u1E29\\u1E2B\\u1E96\\u0127\\u2C68\\u2C76\\u0265]/g},\n    {'base':'hv','letters':/[\\u0195]/g},\n    {'base':'i', 'letters':/[\\u0069\\u24D8\\uFF49\\u00EC\\u00ED\\u00EE\\u0129\\u012B\\u012D\\u00EF\\u1E2F\\u1EC9\\u01D0\\u0209\\u020B\\u1ECB\\u012F\\u1E2D\\u0268\\u0131]/g},\n    {'base':'j', 'letters':/[\\u006A\\u24D9\\uFF4A\\u0135\\u01F0\\u0249]/g},\n    {'base':'k', 'letters':/[\\u006B\\u24DA\\uFF4B\\u1E31\\u01E9\\u1E33\\u0137\\u1E35\\u0199\\u2C6A\\uA741\\uA743\\uA745\\uA7A3]/g},\n    {'base':'l', 'letters':/[\\u006C\\u24DB\\uFF4C\\u0140\\u013A\\u013E\\u1E37\\u1E39\\u013C\\u1E3D\\u1E3B\\u017F\\u0142\\u019A\\u026B\\u2C61\\uA749\\uA781\\uA747]/g},\n    {'base':'lj','letters':/[\\u01C9]/g},\n    {'base':'m', 'letters':/[\\u006D\\u24DC\\uFF4D\\u1E3F\\u1E41\\u1E43\\u0271\\u026F]/g},\n    {'base':'n', 'letters':/[\\u006E\\u24DD\\uFF4E\\u01F9\\u0144\\u00F1\\u1E45\\u0148\\u1E47\\u0146\\u1E4B\\u1E49\\u019E\\u0272\\u0149\\uA791\\uA7A5]/g},\n    {'base':'nj','letters':/[\\u01CC]/g},\n    {'base':'o', 'letters':/[\\u006F\\u24DE\\uFF4F\\u00F2\\u00F3\\u00F4\\u1ED3\\u1ED1\\u1ED7\\u1ED5\\u00F5\\u1E4D\\u022D\\u1E4F\\u014D\\u1E51\\u1E53\\u014F\\u022F\\u0231\\u00F6\\u022B\\u1ECF\\u0151\\u01D2\\u020D\\u020F\\u01A1\\u1EDD\\u1EDB\\u1EE1\\u1EDF\\u1EE3\\u1ECD\\u1ED9\\u01EB\\u01ED\\u00F8\\u01FF\\u0254\\uA74B\\uA74D\\u0275]/g},\n    {'base':'oe','letters':/[\\u0153]/g},\n    {'base':'oi','letters':/[\\u01A3]/g},\n    {'base':'ou','letters':/[\\u0223]/g},\n    {'base':'oo','letters':/[\\uA74F]/g},\n    {'base':'p','letters':/[\\u0070\\u24DF\\uFF50\\u1E55\\u1E57\\u01A5\\u1D7D\\uA751\\uA753\\uA755]/g},\n    {'base':'q','letters':/[\\u0071\\u24E0\\uFF51\\u024B\\uA757\\uA759]/g},\n    {'base':'r','letters':/[\\u0072\\u24E1\\uFF52\\u0155\\u1E59\\u0159\\u0211\\u0213\\u1E5B\\u1E5D\\u0157\\u1E5F\\u024D\\u027D\\uA75B\\uA7A7\\uA783]/g},\n    {'base':'s','letters':/[\\u0073\\u24E2\\uFF53\\u00DF\\u015B\\u1E65\\u015D\\u1E61\\u0161\\u1E67\\u1E63\\u1E69\\u0219\\u015F\\u023F\\uA7A9\\uA785\\u1E9B]/g},\n    {'base':'t','letters':/[\\u0074\\u24E3\\uFF54\\u1E6B\\u1E97\\u0165\\u1E6D\\u021B\\u0163\\u1E71\\u1E6F\\u0167\\u01AD\\u0288\\u2C66\\uA787]/g},\n    {'base':'tz','letters':/[\\uA729]/g},\n    {'base':'u','letters':/[\\u0075\\u24E4\\uFF55\\u00F9\\u00FA\\u00FB\\u0169\\u1E79\\u016B\\u1E7B\\u016D\\u00FC\\u01DC\\u01D8\\u01D6\\u01DA\\u1EE7\\u016F\\u0171\\u01D4\\u0215\\u0217\\u01B0\\u1EEB\\u1EE9\\u1EEF\\u1EED\\u1EF1\\u1EE5\\u1E73\\u0173\\u1E77\\u1E75\\u0289]/g},\n    {'base':'v','letters':/[\\u0076\\u24E5\\uFF56\\u1E7D\\u1E7F\\u028B\\uA75F\\u028C]/g},\n    {'base':'vy','letters':/[\\uA761]/g},\n    {'base':'w','letters':/[\\u0077\\u24E6\\uFF57\\u1E81\\u1E83\\u0175\\u1E87\\u1E85\\u1E98\\u1E89\\u2C73]/g},\n    {'base':'x','letters':/[\\u0078\\u24E7\\uFF58\\u1E8B\\u1E8D]/g},\n    {'base':'y','letters':/[\\u0079\\u24E8\\uFF59\\u1EF3\\u00FD\\u0177\\u1EF9\\u0233\\u1E8F\\u00FF\\u1EF7\\u1E99\\u1EF5\\u01B4\\u024F\\u1EFF]/g},\n    {'base':'z','letters':/[\\u007A\\u24E9\\uFF5A\\u017A\\u1E91\\u017C\\u017E\\u1E93\\u1E95\\u01B6\\u0225\\u0240\\u2C6C\\uA763]/g}\n];\n\n\nmodule.exports = function(str) {\n\tvar rules = diacriticsRemovalMap;\n\tfor (var i = 0; i < rules.length; i++) {\n\t\tstr = str.replace(rules[i].letters, rules[i].base);\n\t}\n\treturn str;\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/transliterators/ja/index.js":"/*\n Copyright (c) 2012, Guillaume Marty\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n */\n\n/**\n * A transliteration of Katakana & Hiragana to roman characters using the\n * modified Hepburn system.\n * Rules based on CLDR transform rule set `Katakana-Latin-BGN.xml` but with\n * several bugs fixed:\n *  * Missing ū\n *  * Missing tsu + voiced kana\n *  * typos on my~ transliterations\n *  * support for long vowel sign\n *  * support for final small tsu\n *  * support for u + small vowels\n *  * support for su/shi/ji + small vowels\n *  * support for tchi/tsu/te/to + small vowels\n *  * support for fu + small vowels\n *  * support for katakana middle dot\n *\n * \\@todo Take iteration marks into account.\n */\n\nvar replacer = require('../../util/utils').replacer;\n\nvar transliterationTable1 = {\n  'ウァ': 'wa', // KATAKANA LETTER U + SMALL A\n  'ウィ': 'wi', // KATAKANA LETTER U + SMALL I\n  'ウェ': 'we', // KATAKANA LETTER U + SMALL E\n  'ウォ': 'wo', // KATAKANA LETTER U + SMALL O\n  'ウー': 'ū', // KATAKANA LETTER VU + PROLONGED SOUND MARK\n\n  'ヴァ': 'va', // KATAKANA LETTER VU + SMALL A\n  'ヴィ': 'vi', // KATAKANA LETTER VU + SMALL I\n  'ヴェ': 've', // KATAKANA LETTER VU + SMALL E\n  'ヴォ': 'vo', // KATAKANA LETTER VU + SMALL O\n  'ヴュ': 'vyu', // KATAKANA LETTER VU + SMALL YU\n\n  'うぁ': 'wa', // HIRAGANA LETTER U + SMALL A\n  'うぃ': 'wi', // HIRAGANA LETTER U + SMALL I\n  'うぇ': 'we', // HIRAGANA LETTER U + SMALL E\n  'うぉ': 'wo', // HIRAGANA LETTER U + SMALL O\n  'うー': 'ū', // HIRAGANA LETTER VU + PROLONGED SOUND MARK\n\n  'ゔぁ': 'va', // HIRAGANA LETTER VU + SMALL A\n  'ゔぃ': 'vi', // HIRAGANA LETTER VU + SMALL I\n  'ゔぇ': 've', // HIRAGANA LETTER VU + SMALL E\n  'ゔぉ': 'vo', // HIRAGANA LETTER VU + SMALL O\n  'ゔゅ': 'vyu' // HIRAGANA LETTER VU + SMALL YU\n};\n\nvar transliterationTable2 = {\n  'イェ': 'ye', // KATAKANA LETTER I + SMALL E\n\n  'ア': 'a', // KATAKANA LETTER A\n  'イ': 'i', // KATAKANA LETTER I\n  'ウウ': 'ū', // KATAKANA LETTER U + U\n  'ウ': 'u', // KATAKANA LETTER U\n  'エ': 'e', // KATAKANA LETTER E\n  'オウ': 'ō', // KATAKANA LETTER O + U\n  'オ': 'o', // KATAKANA LETTER O\n\n  'クァ': 'kwa', // KATAKANA LETTER KU + SMALL A\n  'クィ': 'kwi', // KATAKANA LETTER KU + SMALL I\n  'クェ': 'kwe', // KATAKANA LETTER KU + SMALL E\n  'クォ': 'kwo', // KATAKANA LETTER KU + SMALL O\n\n  'カ': 'ka', // KATAKANA LETTER KA\n  'キョウ': 'kyō', // KATAKANA LETTER KI + SMALL YO + U\n  'キュウ': 'kyū', // KATAKANA LETTER KI + SMALL YU + U\n  'キャ': 'kya', // KATAKANA LETTER KI + SMALL YA\n  'キョ': 'kyo', // KATAKANA LETTER KI + SMALL YO\n  'キュ': 'kyu', // KATAKANA LETTER KI + SMALL YU\n  'キ': 'ki', // KATAKANA LETTER KI\n  'ク': 'ku', // KATAKANA LETTER KU\n  'ケ': 'ke', // KATAKANA LETTER KE\n  'コウ': 'kō', // KATAKANA LETTER KO + U\n  'コ': 'ko', // KATAKANA LETTER KO\n\n  'シェ': 'she', // KATAKANA LETTER SI + SMALL E\n  'スィ': 'si', // KATAKANA LETTER SU + SMALL I\n\n  'サ': 'sa', // KATAKANA LETTER SA\n  'ショウ': 'shō', // KATAKANA LETTER SI + SMALL YO + U\n  'シュウ': 'shū', // KATAKANA LETTER SI + SMALL YU + U\n  'シャ': 'sha', // KATAKANA LETTER SI + SMALL YA\n  'ショ': 'sho', // KATAKANA LETTER SI + SMALL YO\n  'シュ': 'shu', // KATAKANA LETTER SI + SMALL YU\n  'シ': 'shi', // KATAKANA LETTER SI\n  'スウ': 'sū', // KATAKANA LETTER SU + U\n  'ス': 'su', // KATAKANA LETTER SU\n  'セ': 'se', // KATAKANA LETTER SE\n  'ソウ': 'sō', // KATAKANA LETTER SO + U\n  'ソ': 'so', // KATAKANA LETTER SO\n\n  'チェ': 'che', // KATAKANA LETTER TI + SMALL E\n  'ツァ': 'tsa', // KATAKANA LETTER TU + SMALL A\n  'ツィ': 'tsi', // KATAKANA LETTER TU + SMALL I\n  'ツェ': 'tse', // KATAKANA LETTER TU + SMALL E\n  'ツォ': 'tso', // KATAKANA LETTER TU + SMALL O\n  'ティ': 'ti', // KATAKANA LETTER TE + SMALL I\n  'ディ': 'di', // KATAKANA LETTER DE + SMALL I\n  'テュ': 'tyu', // KATAKANA LETTER TE + SMALL YU\n  'デュ': 'dyu', // KATAKANA LETTER DE + SMALL YU\n  'トィ': 'twi', // KATAKANA LETTER TO + SMALL I\n  'トゥ': 'tu', // KATAKANA LETTER TO + SMALL U\n  'ドィ': 'dwi', // KATAKANA LETTER DO + SMALL I\n  'ドゥ': 'du', // KATAKANA LETTER DO + SMALL U\n\n  'タ': 'ta', // KATAKANA LETTER TA\n  'チョウ': 'chō', // KATAKANA LETTER TI + SMALL YO + U\n  'チュウ': 'chū', // KATAKANA LETTER TI + SMALL YU + U\n  'チャ': 'cha', // KATAKANA LETTER TI + SMALL YA\n  'チョ': 'cho', // KATAKANA LETTER TI + SMALL YO\n  'チュ': 'chu', // KATAKANA LETTER TI + SMALL YU\n  'チ': 'chi', // KATAKANA LETTER TI\n  'ツウ': 'tsū', // KATAKANA LETTER TU + U\n  'ツ': 'tsu', // KATAKANA LETTER TU\n  'テ': 'te', // KATAKANA LETTER TE\n  'トウ': 'tō', // KATAKANA LETTER TO + U\n  'ト': 'to', // KATAKANA LETTER TO\n\n  'ナ': 'na', // KATAKANA LETTER NA\n  'ニョウ': 'nyō', // KATAKANA LETTER NI + SMALL YO + U\n  'ニュウ': 'nyū', // KATAKANA LETTER NI + SMALL YU + U\n  'ニャ': 'nya', // KATAKANA LETTER NI + SMALL YA\n  'ニョ': 'nyo', // KATAKANA LETTER NI + SMALL YO\n  'ニュ': 'nyu', // KATAKANA LETTER NI + SMALL YU\n  'ニ': 'ni', // KATAKANA LETTER NI\n  'ヌウ': 'nū', // KATAKANA LETTER NU + U\n  'ヌ': 'nu', // KATAKANA LETTER NU\n  'ネ': 'ne', // KATAKANA LETTER NE\n  'ノウ': 'nō', // KATAKANA LETTER NO + U\n  'ノ': 'no', // KATAKANA LETTER NO\n\n  'ファ': 'fa', // KATAKANA LETTER HU + SMALL A\n  'フィ': 'fi', // KATAKANA LETTER HU + SMALL I\n  //'フゥ': 'fu', // KATAKANA LETTER HU + SMALL U\n  'フェ': 'fe', // KATAKANA LETTER HU + SMALL E\n  'フォ': 'fo', // KATAKANA LETTER HU + SMALL O\n  'フュ': 'fyu', // KATAKANA LETTER HU + SMALL YU\n  'ホェ': 'hwe', // KATAKANA LETTER HO + SMALL E\n\n  'ハ': 'ha', // KATAKANA LETTER HA\n  'ヒョウ': 'hyō', // KATAKANA LETTER HI + SMALL YO + U\n  'ヒュウ': 'hyū', // KATAKANA LETTER HI + SMALL YU + U\n  'ヒャ': 'hya', // KATAKANA LETTER HI + SMALL YA\n  'ヒョ': 'hyo', // KATAKANA LETTER HI + SMALL YO\n  'ヒュ': 'hyu', // KATAKANA LETTER HI + SMALL YU\n  'ヒ': 'hi', // KATAKANA LETTER HI\n  'フウ': 'fū', // KATAKANA LETTER HU + U\n  'フ': 'fu', // KATAKANA LETTER HU\n  'ヘ': 'he', // KATAKANA LETTER HE\n  'ホウ': 'hō', // KATAKANA LETTER HO + U\n  'ホ': 'ho', // KATAKANA LETTER HO\n\n  'マ': 'ma', // KATAKANA LETTER MA\n  'ミョウ': 'myō', // KATAKANA LETTER MI + SMALL YO + U\n  'ミュウ': 'myū', // KATAKANA LETTER MI + SMALL YU + U\n  'ミャ': 'mya', // KATAKANA LETTER MI + SMALL YA\n  'ミョ': 'myo', // KATAKANA LETTER MI + SMALL YO\n  'ミュ': 'myu', // KATAKANA LETTER MI + SMALL YU\n  'ミ': 'mi', // KATAKANA LETTER MI\n  'ムウ': 'mū', // KATAKANA LETTER MU + U\n  'ム': 'mu', // KATAKANA LETTER MU\n  'メ': 'me', // KATAKANA LETTER ME\n  'モウ': 'mō', // KATAKANA LETTER MO + U\n  'モ': 'mo', // KATAKANA LETTER MO\n\n  'ヤ': 'ya', // KATAKANA LETTER YA\n  'ユウ': 'yū', // KATAKANA LETTER YU + U\n  'ユ': 'yu', // KATAKANA LETTER YU\n  'ヨウ': 'yō', // KATAKANA LETTER YO + U\n  'ヨ': 'yo', // KATAKANA LETTER YO\n\n  'リェ': 'rye', // KATAKANA LETTER RI + SMALL E\n\n  'ラ': 'ra', // KATAKANA LETTER RA\n  'リョウ': 'ryō', // KATAKANA LETTER RI + SMALL YO + U\n  'リュウ': 'ryū', // KATAKANA LETTER RI + SMALL YU + U\n  'リャ': 'rya', // KATAKANA LETTER RI + SMALL YA\n  'リョ': 'ryo', // KATAKANA LETTER RI + SMALL YO\n  'リュ': 'ryu', // KATAKANA LETTER RI + SMALL YU\n  'リ': 'ri', // KATAKANA LETTER RI\n  'ルウ': 'rū', // KATAKANA LETTER RU + U\n  'ル': 'ru', // KATAKANA LETTER RU\n  'レ': 're', // KATAKANA LETTER RE\n  'ロウ': 'rō', // KATAKANA LETTER RO + U\n  'ロ': 'ro', // KATAKANA LETTER RO\n\n  'ワ': 'wa', // KATAKANA LETTER WA\n  'ヰ': 'i', // KATAKANA LETTER WI\n  'ヱ': 'e', // KATAKANA LETTER WE\n  'ヲ': 'o', // KATAKANA LETTER WO\n\n  'ン': 'n', // KATAKANA LETTER N\n\n  'グァ': 'gwa', // KATAKANA LETTER GU + SMALL A\n  'グィ': 'gwi', // KATAKANA LETTER GU + SMALL I\n  'グェ': 'gwe', // KATAKANA LETTER GU + SMALL E\n  'グォ': 'gwo', // KATAKANA LETTER GU + SMALL O\n\n  'ガ': 'ga', // KATAKANA LETTER GA\n  'ギョウ': 'gyō', // KATAKANA LETTER GI + SMALL YO + U\n  'ギュウ': 'gyū', // KATAKANA LETTER GI + SMALL YU + U\n  'ギャ': 'gya', // KATAKANA LETTER GI + SMALL YA\n  'ギョ': 'gyo', // KATAKANA LETTER GI + SMALL YO\n  'ギュ': 'gyu', // KATAKANA LETTER GI + SMALL YU\n  'ギ': 'gi', // KATAKANA LETTER GI\n  'グウ': 'gū', // KATAKANA LETTER GU + U\n  'グ': 'gu', // KATAKANA LETTER GU\n  'ゲ': 'ge', // KATAKANA LETTER GE\n  'ゴウ': 'gō', // KATAKANA LETTER GO + U\n  'ゴ': 'go', // KATAKANA LETTER GO\n\n  'ジェ': 'je', // KATAKANA LETTER ZI + SMALL E\n  'ズィ': 'zi', // KATAKANA LETTER ZU + SMALL I\n\n  'ザ': 'za', // KATAKANA LETTER ZA\n  'ジョウ': 'jō', // KATAKANA LETTER ZI + SMALL YO + U\n  'ジュウ': 'jū', // KATAKANA LETTER ZI + SMALL YU + U\n  'ジャ': 'ja', // KATAKANA LETTER ZI + SMALL YA\n  'ジョ': 'jo', // KATAKANA LETTER ZI + SMALL YO\n  'ジュ': 'ju', // KATAKANA LETTER ZI + SMALL YU\n  'ジ': 'ji', // KATAKANA LETTER ZI\n  'ズウ': 'zū', // KATAKANA LETTER ZU + U\n  'ズ': 'zu', // KATAKANA LETTER ZU\n  'ゼ': 'ze', // KATAKANA LETTER ZE\n  'ゾウ': 'zō', // KATAKANA LETTER ZO + U\n  'ゾ': 'zo', // KATAKANA LETTER ZO\n\n  'ダ': 'da', // KATAKANA LETTER DA\n  'ヂ': 'ji', // KATAKANA LETTER DI\n  'ヅウ': 'zū', // KATAKANA LETTER DU + U\n  'ヅ': 'zu', // KATAKANA LETTER DU\n  'デ': 'de', // KATAKANA LETTER DE\n  'ドウ': 'dō', // KATAKANA LETTER DO + U\n  'ド': 'do', // KATAKANA LETTER DO\n\n  'ブュ': 'byu', // KATAKANA LETTER BU + SMALL YU\n\n  'バ': 'ba', // KATAKANA LETTER BA\n  'ビョウ': 'byō', // KATAKANA LETTER BI + SMALL YO + U\n  'ビュウ': 'byū', // KATAKANA LETTER BI + SMALL YU + U\n  'ビャ': 'bya', // KATAKANA LETTER BI + SMALL YA\n  'ビョ': 'byo', // KATAKANA LETTER BI + SMALL YO\n  'ビュ': 'byu', // KATAKANA LETTER BI + SMALL YU\n  'ビ': 'bi', // KATAKANA LETTER BI\n  'ブウ': 'bū', // KATAKANA LETTER BU + U\n  'ブ': 'bu', // KATAKANA LETTER BU\n  'ベ': 'be', // KATAKANA LETTER BE\n  'ボウ': 'bō', // KATAKANA LETTER BO + U\n  'ボ': 'bo', // KATAKANA LETTER BO\n\n  'パ': 'pa', // KATAKANA LETTER PA\n  'ピョウ': 'pyō', // KATAKANA LETTER PI + SMALL YO + U\n  'ピュウ': 'pyū', // KATAKANA LETTER PI + SMALL YU + U\n  'ピャ': 'pya', // KATAKANA LETTER PI + SMALL YA\n  'ピョ': 'pyo', // KATAKANA LETTER PI + SMALL YO\n  'ピュ': 'pyu', // KATAKANA LETTER PI + SMALL YU\n  'ピ': 'pi', // KATAKANA LETTER PI\n  'プウ': 'pū', // KATAKANA LETTER PU + U\n  'プ': 'pu', // KATAKANA LETTER PU\n  'ペ': 'pe', // KATAKANA LETTER PE\n  'ポウ': 'pō', // KATAKANA LETTER PO + U\n  'ポ': 'po', // KATAKANA LETTER PO\n\n  'ヴ': 'v', // KATAKANA LETTER VU\n\n  '・': ' ', // KATAKANA MIDDLE DOT\n\n  'いぇ': 'ye', // HIRAGANA LETTER I + SMALL E\n\n  'あ': 'a', // HIRAGANA LETTER A\n  'い': 'i', // HIRAGANA LETTER I\n  'うう': 'ū', // HIRAGANA LETTER U + U\n  'う': 'u', // HIRAGANA LETTER U\n  'え': 'e', // HIRAGANA LETTER E\n  'おう': 'ō', // HIRAGANA LETTER O + U\n  'お': 'o', // HIRAGANA LETTER O\n\n  'くぁ': 'kwa', // HIRAGANA LETTER KU + SMALL A\n  'くぃ': 'kwi', // HIRAGANA LETTER KU + SMALL I\n  'くぇ': 'kwe', // HIRAGANA LETTER KU + SMALL E\n  'くぉ': 'kwo', // HIRAGANA LETTER KU + SMALL O\n\n  'か': 'ka', // HIRAGANA LETTER KA\n  'きょう': 'kyō', // HIRAGANA LETTER KI + SMALL YO + U\n  'きゅう': 'kyū', // HIRAGANA LETTER KI + SMALL YU + U\n  'きゃ': 'kya', // HIRAGANA LETTER KI + SMALL YA\n  'きょ': 'kyo', // HIRAGANA LETTER KI + SMALL YO\n  'きゅ': 'kyu', // HIRAGANA LETTER KI + SMALL YU\n  'き': 'ki', // HIRAGANA LETTER KI\n  'くう': 'kū', // HIRAGANA LETTER KU + U\n  'く': 'ku', // HIRAGANA LETTER KU\n  'け': 'ke', // HIRAGANA LETTER KE\n  'こう': 'kō', // HIRAGANA LETTER KO + U\n  'こ': 'ko', // HIRAGANA LETTER KO\n\n  'しぇ': 'she', // HIRAGANA LETTER SI + SMALL E\n  'すぃ': 'si', // HIRAGANA LETTER SU + SMALL I\n\n  'さ': 'sa', // HIRAGANA LETTER SA\n  'しょう': 'shō', // HIRAGANA LETTER SI + SMALL YO + U\n  'しゅう': 'shū', // HIRAGANA LETTER SI + SMALL YU + U\n  'しゃ': 'sha', // HIRAGANA LETTER SI + SMALL YA\n  'しょ': 'sho', // HIRAGANA LETTER SI + SMALL YO\n  'しゅ': 'shu', // HIRAGANA LETTER SI + SMALL YU\n  'し': 'shi', // HIRAGANA LETTER SI\n  'すう': 'sū', // HIRAGANA LETTER SU + U\n  'す': 'su', // HIRAGANA LETTER SU\n  'せ': 'se', // HIRAGANA LETTER SE\n  'そう': 'sō', // HIRAGANA LETTER SO + U\n  'そ': 'so', // HIRAGANA LETTER SO\n\n  'ちぇ': 'che', // HIRAGANA LETTER TI + SMALL E\n  'つぁ': 'tsa', // HIRAGANA LETTER TU + SMALL A\n  'つぃ': 'tsi', // HIRAGANA LETTER TU + SMALL I\n  'つぇ': 'tse', // HIRAGANA LETTER TU + SMALL E\n  'つぉ': 'tso', // HIRAGANA LETTER TU + SMALL O\n  'てぃ': 'ti', // HIRAGANA LETTER TE + SMALL I\n  'でぃ': 'di', // HIRAGANA LETTER DE + SMALL I\n  'てゅ': 'tyu', // HIRAGANA LETTER TE + SMALL YU\n  'でゅ': 'dyu', // HIRAGANA LETTER DE + SMALL YU\n  'とぃ': 'twi', // HIRAGANA LETTER TO + SMALL I\n  'とぅ': 'tu', // HIRAGANA LETTER TO + SMALL U\n  'どぃ': 'dwi', // HIRAGANA LETTER DO + SMALL I\n  'どぅ': 'du', // HIRAGANA LETTER DO + SMALL U\n\n  'た': 'ta', // HIRAGANA LETTER TA\n  'ちょう': 'chō', // HIRAGANA LETTER TI + SMALL YO + U\n  'ちゅう': 'chū', // HIRAGANA LETTER TI + SMALL YU + U\n  'ちゃ': 'cha', // HIRAGANA LETTER TI + SMALL YA\n  'ちょ': 'cho', // HIRAGANA LETTER TI + SMALL YO\n  'ちゅ': 'chu', // HIRAGANA LETTER TI + SMALL YU\n  'ち': 'chi', // HIRAGANA LETTER TI\n  'つう': 'tsū', // HIRAGANA LETTER TU + U\n  'つ': 'tsu', // HIRAGANA LETTER TU\n  'て': 'te', // HIRAGANA LETTER TE\n  'とう': 'tō', // HIRAGANA LETTER TO + U\n  'と': 'to', // HIRAGANA LETTER TO\n\n  'な': 'na', // HIRAGANA LETTER NA\n  'にょう': 'nyō', // HIRAGANA LETTER NI + SMALL YO + U\n  'にゅう': 'nyū', // HIRAGANA LETTER NI + SMALL YU + U\n  'にゃ': 'nya', // HIRAGANA LETTER NI + SMALL YA\n  'にょ': 'nyo', // HIRAGANA LETTER NI + SMALL YO\n  'にゅ': 'nyu', // HIRAGANA LETTER NI + SMALL YU\n  'に': 'ni', // HIRAGANA LETTER NI\n  'ぬう': 'nū', // HIRAGANA LETTER NU + U\n  'ぬ': 'nu', // HIRAGANA LETTER NU\n  'ね': 'ne', // HIRAGANA LETTER NE\n  'のう': 'nō', // HIRAGANA LETTER NO + U\n  'の': 'no', // HIRAGANA LETTER NO\n\n  'ふぁ': 'fa', // HIRAGANA LETTER HU + SMALL A\n  'ふぃ': 'fi', // HIRAGANA LETTER HU + SMALL I\n  //'ふぅ': 'fu', // HIRAGANA LETTER HU + SMALL U\n  'ふぇ': 'fe', // HIRAGANA LETTER HU + SMALL E\n  'ふぉ': 'fo', // HIRAGANA LETTER HU + SMALL O\n  'ふゅ': 'fyu', // HIRAGANA LETTER HU + SMALL YU\n  'ほぇ': 'hwe', // HIRAGANA LETTER HO + SMALL E\n\n  'は': 'ha', // HIRAGANA LETTER HA\n  'ひょう': 'hyō', // HIRAGANA LETTER HI + SMALL YO + U\n  'ひゅう': 'hyū', // HIRAGANA LETTER HI + SMALL YU + U\n  'ひゃ': 'hya', // HIRAGANA LETTER HI + SMALL YA\n  'ひょ': 'hyo', // HIRAGANA LETTER HI + SMALL YO\n  'ひゅ': 'hyu', // HIRAGANA LETTER HI + SMALL YU\n  'ひ': 'hi', // HIRAGANA LETTER HI\n  'ふう': 'fū', // HIRAGANA LETTER HU + U\n  'ふ': 'fu', // HIRAGANA LETTER HU\n  'へ': 'he', // HIRAGANA LETTER HE\n  'ほう': 'hō', // HIRAGANA LETTER HO + U\n  'ほ': 'ho', // HIRAGANA LETTER HO\n\n  'ま': 'ma', // HIRAGANA LETTER MA\n  'みょう': 'myō', // HIRAGANA LETTER MI + SMALL YO + U\n  'みゅう': 'myū', // HIRAGANA LETTER MI + SMALL YU + U\n  'みゃ': 'mya', // HIRAGANA LETTER MI + SMALL YA\n  'みょ': 'myo', // HIRAGANA LETTER MI + SMALL YO\n  'みゅ': 'myu', // HIRAGANA LETTER MI + SMALL YU\n  'み': 'mi', // HIRAGANA LETTER MI\n  'むう': 'mū', // HIRAGANA LETTER MU + U\n  'む': 'mu', // HIRAGANA LETTER MU\n  'め': 'me', // HIRAGANA LETTER ME\n  'もう': 'mō', // HIRAGANA LETTER MO + U\n  'も': 'mo', // HIRAGANA LETTER MO\n\n  'や': 'ya', // HIRAGANA LETTER YA\n  'ゆう': 'yū', // HIRAGANA LETTER YU + U\n  'ゆ': 'yu', // HIRAGANA LETTER YU\n  'よう': 'yō', // HIRAGANA LETTER YO + U\n  'よ': 'yo', // HIRAGANA LETTER YO\n\n  'りぇ': 'rye', // HIRAGANA LETTER RI + SMALL E\n\n  'ら': 'ra', // HIRAGANA LETTER RA\n  'りょう': 'ryō', // HIRAGANA LETTER RI + SMALL YO + U\n  'りゅう': 'ryū', // HIRAGANA LETTER RI + SMALL YU + U\n  'りゃ': 'rya', // HIRAGANA LETTER RI + SMALL YA\n  'りょ': 'ryo', // HIRAGANA LETTER RI + SMALL YO\n  'りゅ': 'ryu', // HIRAGANA LETTER RI + SMALL YU\n  'り': 'ri', // HIRAGANA LETTER RI\n  'るう': 'rū', // HIRAGANA LETTER RU + U\n  'る': 'ru', // HIRAGANA LETTER RU\n  'れ': 're', // HIRAGANA LETTER RE\n  'ろう': 'rō', // HIRAGANA LETTER RO + U\n  'ろ': 'ro', // HIRAGANA LETTER RO\n\n  'わ': 'wa', // HIRAGANA LETTER WA\n  'ゐ': 'i', // HIRAGANA LETTER WI\n  'ゑ': 'e', // HIRAGANA LETTER WE\n  'を': 'o', // HIRAGANA LETTER WO\n\n  'ん': 'n', // HIRAGANA LETTER N\n\n  'ぐぁ': 'gwa', // HIRAGANA LETTER GU + SMALL A\n  'ぐぃ': 'gwi', // HIRAGANA LETTER GU + SMALL I\n  'ぐぇ': 'gwe', // HIRAGANA LETTER GU + SMALL E\n  'ぐぉ': 'gwo', // HIRAGANA LETTER GU + SMALL O\n\n  'が': 'ga', // HIRAGANA LETTER GA\n  'ぎょう': 'gyō', // HIRAGANA LETTER GI + SMALL YO + U\n  'ぎゅう': 'gyū', // HIRAGANA LETTER GI + SMALL YU + U\n  'ぎゃ': 'gya', // HIRAGANA LETTER GI + SMALL YA\n  'ぎょ': 'gyo', // HIRAGANA LETTER GI + SMALL YO\n  'ぎゅ': 'gyu', // HIRAGANA LETTER GI + SMALL YU\n  'ぎ': 'gi', // HIRAGANA LETTER GI\n  'ぐう': 'gū', // HIRAGANA LETTER GU + U\n  'ぐ': 'gu', // HIRAGANA LETTER GU\n  'げ': 'ge', // HIRAGANA LETTER GE\n  'ごう': 'gō', // HIRAGANA LETTER GO + U\n  'ご': 'go', // HIRAGANA LETTER GO\n\n  'じぇ': 'je', // HIRAGANA LETTER ZI + SMALL E\n  'ずぃ': 'zi', // HIRAGANA LETTER ZU + SMALL I\n\n  'ざ': 'za', // HIRAGANA LETTER ZA\n  'じょう': 'jō', // HIRAGANA LETTER ZI + SMALL YO + U\n  'じゅう': 'jū', // HIRAGANA LETTER ZI + SMALL YU + U\n  'じゃ': 'ja', // HIRAGANA LETTER ZI + SMALL YA\n  'じょ': 'jo', // HIRAGANA LETTER ZI + SMALL YO\n  'じゅ': 'ju', // HIRAGANA LETTER ZI + SMALL YU\n  'じ': 'ji', // HIRAGANA LETTER ZI\n  'ずう': 'zū', // HIRAGANA LETTER ZU + U\n  'ず': 'zu', // HIRAGANA LETTER ZU\n  'ぜ': 'ze', // HIRAGANA LETTER ZE\n  'ぞう': 'zō', // HIRAGANA LETTER ZO + U\n  'ぞ': 'zo', // HIRAGANA LETTER ZO\n\n  'だ': 'da', // HIRAGANA LETTER DA\n  'ぢ': 'ji', // HIRAGANA LETTER DI\n  'づう': 'zū', // HIRAGANA LETTER DU + U\n  'づ': 'zu', // HIRAGANA LETTER DU\n  'で': 'de', // HIRAGANA LETTER DE\n  'どう': 'dō', // HIRAGANA LETTER DO + U\n  'ど': 'do', // HIRAGANA LETTER DO\n\n  'ぶゅ': 'byu', // HIRAGANA LETTER BU + SMALL YU\n\n  'ば': 'ba', // HIRAGANA LETTER BA\n  'びょう': 'byō', // HIRAGANA LETTER BI + SMALL YO + U\n  'びゅう': 'byū', // HIRAGANA LETTER BI + SMALL YU + U\n  'びゃ': 'bya', // HIRAGANA LETTER BI + SMALL YA\n  'びょ': 'byo', // HIRAGANA LETTER BI + SMALL YO\n  'びゅ': 'byu', // HIRAGANA LETTER BI + SMALL YU\n  'び': 'bi', // HIRAGANA LETTER BI\n  'ぶう': 'bū', // HIRAGANA LETTER BU + U\n  'ぶ': 'bu', // HIRAGANA LETTER BU\n  'べ': 'be', // HIRAGANA LETTER BE\n  'ぼう': 'bō', // HIRAGANA LETTER BO + U\n  'ぼ': 'bo', // HIRAGANA LETTER BO\n\n  'ぱ': 'pa', // HIRAGANA LETTER PA\n  'ぴょう': 'pyō', // HIRAGANA LETTER PI + SMALL YO + U\n  'ぴゅう': 'pyū', // HIRAGANA LETTER PI + SMALL YU + U\n  'ぴゃ': 'pya', // HIRAGANA LETTER PI + SMALL YA\n  'ぴょ': 'pyo', // HIRAGANA LETTER PI + SMALL YO\n  'ぴゅ': 'pyu', // HIRAGANA LETTER PI + SMALL YU\n  'ぴ': 'pi', // HIRAGANA LETTER PI\n  'ぷう': 'pū', // HIRAGANA LETTER PU + U\n  'ぷ': 'pu', // HIRAGANA LETTER PU\n  'ぺ': 'pe', // HIRAGANA LETTER PE\n  'ぽう': 'pō', // HIRAGANA LETTER PO + U\n  'ぽ': 'po', // HIRAGANA LETTER PO\n\n  'ゔ': 'v' // HIRAGANA LETTER VU\n};\n\nvar transliterationTable3 = {\n  'aァ': 'ā',\n  'aぁ': 'ā',\n  'iィー': 'ī',\n  'iィ': 'ī',\n  'iぃー': 'ī',\n  'iぃ': 'ī',\n  'aー': 'ā',\n  'iー': 'ī',\n  'uー': 'ū',\n  'eー': 'ē',\n  'oー': 'ō',\n\n  // Fallback for small vowels\n  'ァ': 'a',\n  'ィ': 'i',\n  'ゥ': 'u',\n  'ェ': 'e',\n  'ォ': 'o',\n  'ぁ': 'a',\n  'ぃ': 'i',\n  'ぅ': 'u',\n  'ぇ': 'e',\n  'ぉ': 'o'\n};\n\nvar replace1 = replacer(transliterationTable1);\nvar replace2 = replacer(transliterationTable2);\nvar replace3 = replacer(transliterationTable3);\n\nmodule.exports = function(str) {\n  str = replace1(str);\n\n  str = str\n    .replace(/ッ(?=[ン])/g, 'n')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[ん])/g, 'n')// HIRAGANA LETTER SMALL TU\n    .replace(/ン(?=[バビブベボパピプペポマミムメモ])/g, 'm')// KATAKANA LETTER N\n    .replace(/ん(?=[ばびぶべぼぱぴぷぺぽまみむめも])/g, 'm')// HIRAGANA LETTER N\n    .replace(/ン(?=[ヤユヨアイウエオ])/g, \"n'\")// KATAKANA LETTER N\n    .replace(/ん(?=[やゆよあいうえお])/g, \"n'\");// HIRAGANA LETTER N\n  str = str\n    .replace(/ッ(?=[カキクケコ])/g, 'k')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[かきくけこ])/g, 'k')// HIRAGANA LETTER SMALL TU\n    .replace(/ッ(?=[ガギグゲゴ])/g, 'g')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[がぎぐげご])/g, 'g')// HIRAGANA LETTER SMALL TU\n    .replace(/ッ(?=[サシスセソ])/g, 's')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[さしすせそ])/g, 's')// HIRAGANA LETTER SMALL TU\n    .replace(/ッ(?=[ザズゼゾ])/g, 'z')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[ざずぜぞ])/g, 'z')// HIRAGANA LETTER SMALL TU\n    .replace(/ッ(?=[ジ])/g, 'j')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[じ])/g, 'j')// HIRAGANA LETTER SMALL TU\n    .replace(/ッ(?=[タチツテト])/g, 't')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[たちつてと])/g, 't')// HIRAGANA LETTER SMALL TU\n    .replace(/ッ(?=[ダヂヅデド])/g, 't')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[だぢづでど])/g, 't')// HIRAGANA LETTER SMALL TU\n    .replace(/ッ(?=[ハヒヘホ])/g, 'h')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[はひへほ])/g, 'h')// HIRAGANA LETTER SMALL TU\n    .replace(/ッ(?=[フ])/g, 'f')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[ふ])/g, 'f')// HIRAGANA LETTER SMALL TU\n    .replace(/ッ(?=[バビブベボ])/g, 'b')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[ばびぶべぼ])/g, 'b')// HIRAGANA LETTER SMALL TU\n    .replace(/ッ(?=[パピプペポ])/g, 'p')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[ぱぴぷぺぽ])/g, 'p')// HIRAGANA LETTER SMALL TU\n    .replace(/ッ(?=[ラリルレロ])/g, 'r')// KATAKANA LETTER SMALL TU\n    .replace(/っ(?=[らりるれろ])/g, 'r');// HIRAGANA LETTER SMALL TU\n\n  str = replace2(str);\n  str = replace3(str);\n\n  str = str\n    .replace(/(ッ|っ)\\B/g, 't');// FINAL KATAKANA LETTER SMALL TU\n\n  return str;\n};\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/brill_pos_tagger/lib/Brill_POS_Tagger.js":"/*\n    Brill's POS Tagger\n    Copyright (C) 2016 Hugo W.L. ter Doest\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n*/\n\nvar fs = require(\"fs\");\n\nvar TF_Parser = require('./TF_Parser');\n\n// Tags a sentence, sentence is an array of words\n// Returns an array of tagged words; a tagged words is an array consisting of\n// the word itself followed by its lexical category\nBrill_POS_Tagger.prototype.tag = function(sentence) {\n  var taggedSentence = new Array(sentence.length);\n  \n  var that = this;\n  sentence.forEach(function(word, index) {\n    taggedSentence[index] = [];\n    taggedSentence[index][0] = word;\n    var categories = that.lexicon.tagWord(word);\n    taggedSentence[index][1] = categories[0];\n  });\n\n  // Apply transformation rules\n  for (var i = 0, size = sentence.length; i < size; i++) {\n    this.ruleSet.rules.forEach(function(rule) {\n      rule.apply(taggedSentence, i);\n    });\n  }\n  return(taggedSentence);\n};\n\nfunction Brill_POS_Tagger(lexicon, ruleSet) {\n  this.lexicon = lexicon;\n  this.ruleSet = ruleSet;\n}\n\nmodule.exports = Brill_POS_Tagger;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/brill_pos_tagger/lib/TF_Parser.js":"module.exports = (function() {\n  /*\n   * Generated by PEG.js 0.8.0.\n   *\n   * http://pegjs.majda.cz/\n   */\n\n  function peg$subclass(child, parent) {\n    function ctor() { this.constructor = child; }\n    ctor.prototype = parent.prototype;\n    child.prototype = new ctor();\n  }\n\n  function SyntaxError(message, expected, found, offset, line, column) {\n    this.message  = message;\n    this.expected = expected;\n    this.found    = found;\n    this.offset   = offset;\n    this.line     = line;\n    this.column   = column;\n\n    this.name     = \"SyntaxError\";\n  }\n\n  peg$subclass(SyntaxError, Error);\n\n  function parse(input) {\n    var options = arguments.length > 1 ? arguments[1] : {},\n\n        peg$FAILED = {},\n\n        peg$startRuleFunctions = { transformation_rules: peg$parsetransformation_rules },\n        peg$startRuleFunction  = peg$parsetransformation_rules,\n\n        peg$c0 = [],\n        peg$c1 = peg$FAILED,\n        peg$c2 = function(rules) {\n          var result = [];\n\n          for (var i = 0; i < rules.length; i++) {\n            result.push(rules[i][1]);\n          }\n          return(result);\n        },\n        peg$c3 = null,\n        peg$c4 = function(c1, c2, pred, par1, par2) {\n          // Construct rule\n          var result = new TransformationRule(c1, c2, pred, par1, par2);\n          return(result);\n        },\n        peg$c5 = /^[a-zA-Z_0-9_\\-.,()]/,\n        peg$c6 = { type: \"class\", value: \"[a-zA-Z_0-9_\\\\-.,()]\", description: \"[a-zA-Z_0-9_\\\\-.,()]\" },\n        peg$c7 = function(characters) {\n           var s = \"\";\n           for (var i = 0; i < characters.length; i++) {\n             s += characters[i];\n           }\n           return(s);\n          },\n        peg$c8 = \"*\",\n        peg$c9 = { type: \"literal\", value: \"*\", description: \"\\\"*\\\"\" },\n        peg$c10 = function(wc) {\n           return(wc)\n          },\n        peg$c11 = \"\\r\\n\",\n        peg$c12 = { type: \"literal\", value: \"\\r\\n\", description: \"\\\"\\\\r\\\\n\\\"\" },\n        peg$c13 = \"\\n\",\n        peg$c14 = { type: \"literal\", value: \"\\n\", description: \"\\\"\\\\n\\\"\" },\n        peg$c15 = \"\\r\",\n        peg$c16 = { type: \"literal\", value: \"\\r\", description: \"\\\"\\\\r\\\"\" },\n        peg$c17 = \"//\",\n        peg$c18 = { type: \"literal\", value: \"//\", description: \"\\\"//\\\"\" },\n        peg$c19 = void 0,\n        peg$c20 = { type: \"any\", description: \"any character\" },\n        peg$c21 = \" \",\n        peg$c22 = { type: \"literal\", value: \" \", description: \"\\\" \\\"\" },\n        peg$c23 = \"\\t\",\n        peg$c24 = { type: \"literal\", value: \"\\t\", description: \"\\\"\\\\t\\\"\" },\n\n        peg$currPos          = 0,\n        peg$reportedPos      = 0,\n        peg$cachedPos        = 0,\n        peg$cachedPosDetails = { line: 1, column: 1, seenCR: false },\n        peg$maxFailPos       = 0,\n        peg$maxFailExpected  = [],\n        peg$silentFails      = 0,\n\n        peg$result;\n\n    if (\"startRule\" in options) {\n      if (!(options.startRule in peg$startRuleFunctions)) {\n        throw new Error(\"Can't start parsing from rule \\\"\" + options.startRule + \"\\\".\");\n      }\n\n      peg$startRuleFunction = peg$startRuleFunctions[options.startRule];\n    }\n\n    function text() {\n      return input.substring(peg$reportedPos, peg$currPos);\n    }\n\n    function offset() {\n      return peg$reportedPos;\n    }\n\n    function line() {\n      return peg$computePosDetails(peg$reportedPos).line;\n    }\n\n    function column() {\n      return peg$computePosDetails(peg$reportedPos).column;\n    }\n\n    function expected(description) {\n      throw peg$buildException(\n        null,\n        [{ type: \"other\", description: description }],\n        peg$reportedPos\n      );\n    }\n\n    function error(message) {\n      throw peg$buildException(message, null, peg$reportedPos);\n    }\n\n    function peg$computePosDetails(pos) {\n      function advance(details, startPos, endPos) {\n        var p, ch;\n\n        for (p = startPos; p < endPos; p++) {\n          ch = input.charAt(p);\n          if (ch === \"\\n\") {\n            if (!details.seenCR) { details.line++; }\n            details.column = 1;\n            details.seenCR = false;\n          } else if (ch === \"\\r\" || ch === \"\\u2028\" || ch === \"\\u2029\") {\n            details.line++;\n            details.column = 1;\n            details.seenCR = true;\n          } else {\n            details.column++;\n            details.seenCR = false;\n          }\n        }\n      }\n\n      if (peg$cachedPos !== pos) {\n        if (peg$cachedPos > pos) {\n          peg$cachedPos = 0;\n          peg$cachedPosDetails = { line: 1, column: 1, seenCR: false };\n        }\n        advance(peg$cachedPosDetails, peg$cachedPos, pos);\n        peg$cachedPos = pos;\n      }\n\n      return peg$cachedPosDetails;\n    }\n\n    function peg$fail(expected) {\n      if (peg$currPos < peg$maxFailPos) { return; }\n\n      if (peg$currPos > peg$maxFailPos) {\n        peg$maxFailPos = peg$currPos;\n        peg$maxFailExpected = [];\n      }\n\n      peg$maxFailExpected.push(expected);\n    }\n\n    function peg$buildException(message, expected, pos) {\n      function cleanupExpected(expected) {\n        var i = 1;\n\n        expected.sort(function(a, b) {\n          if (a.description < b.description) {\n            return -1;\n          } else if (a.description > b.description) {\n            return 1;\n          } else {\n            return 0;\n          }\n        });\n\n        while (i < expected.length) {\n          if (expected[i - 1] === expected[i]) {\n            expected.splice(i, 1);\n          } else {\n            i++;\n          }\n        }\n      }\n\n      function buildMessage(expected, found) {\n        function stringEscape(s) {\n          function hex(ch) { return ch.charCodeAt(0).toString(16).toUpperCase(); }\n\n          return s\n            .replace(/\\\\/g,   '\\\\\\\\')\n            .replace(/\"/g,    '\\\\\"')\n            .replace(/\\x08/g, '\\\\b')\n            .replace(/\\t/g,   '\\\\t')\n            .replace(/\\n/g,   '\\\\n')\n            .replace(/\\f/g,   '\\\\f')\n            .replace(/\\r/g,   '\\\\r')\n            .replace(/[\\x00-\\x07\\x0B\\x0E\\x0F]/g, function(ch) { return '\\\\x0' + hex(ch); })\n            .replace(/[\\x10-\\x1F\\x80-\\xFF]/g,    function(ch) { return '\\\\x'  + hex(ch); })\n            .replace(/[\\u0180-\\u0FFF]/g,         function(ch) { return '\\\\u0' + hex(ch); })\n            .replace(/[\\u1080-\\uFFFF]/g,         function(ch) { return '\\\\u'  + hex(ch); });\n        }\n\n        var expectedDescs = new Array(expected.length),\n            expectedDesc, foundDesc, i;\n\n        for (i = 0; i < expected.length; i++) {\n          expectedDescs[i] = expected[i].description;\n        }\n\n        expectedDesc = expected.length > 1\n          ? expectedDescs.slice(0, -1).join(\", \")\n              + \" or \"\n              + expectedDescs[expected.length - 1]\n          : expectedDescs[0];\n\n        foundDesc = found ? \"\\\"\" + stringEscape(found) + \"\\\"\" : \"end of input\";\n\n        return \"Expected \" + expectedDesc + \" but \" + foundDesc + \" found.\";\n      }\n\n      var posDetails = peg$computePosDetails(pos),\n          found      = pos < input.length ? input.charAt(pos) : null;\n\n      if (expected !== null) {\n        cleanupExpected(expected);\n      }\n\n      return new SyntaxError(\n        message !== null ? message : buildMessage(expected, found),\n        expected,\n        found,\n        pos,\n        posDetails.line,\n        posDetails.column\n      );\n    }\n\n    function peg$parsetransformation_rules() {\n      var s0, s1, s2, s3, s4, s5;\n\n      s0 = peg$currPos;\n      s1 = [];\n      s2 = peg$currPos;\n      s3 = peg$parseS();\n      if (s3 !== peg$FAILED) {\n        s4 = peg$parsetransformation_rule();\n        if (s4 !== peg$FAILED) {\n          s5 = peg$parseS();\n          if (s5 !== peg$FAILED) {\n            s3 = [s3, s4, s5];\n            s2 = s3;\n          } else {\n            peg$currPos = s2;\n            s2 = peg$c1;\n          }\n        } else {\n          peg$currPos = s2;\n          s2 = peg$c1;\n        }\n      } else {\n        peg$currPos = s2;\n        s2 = peg$c1;\n      }\n      if (s2 !== peg$FAILED) {\n        while (s2 !== peg$FAILED) {\n          s1.push(s2);\n          s2 = peg$currPos;\n          s3 = peg$parseS();\n          if (s3 !== peg$FAILED) {\n            s4 = peg$parsetransformation_rule();\n            if (s4 !== peg$FAILED) {\n              s5 = peg$parseS();\n              if (s5 !== peg$FAILED) {\n                s3 = [s3, s4, s5];\n                s2 = s3;\n              } else {\n                peg$currPos = s2;\n                s2 = peg$c1;\n              }\n            } else {\n              peg$currPos = s2;\n              s2 = peg$c1;\n            }\n          } else {\n            peg$currPos = s2;\n            s2 = peg$c1;\n          }\n        }\n      } else {\n        s1 = peg$c1;\n      }\n      if (s1 !== peg$FAILED) {\n        peg$reportedPos = s0;\n        s1 = peg$c2(s1);\n      }\n      s0 = s1;\n\n      return s0;\n    }\n\n    function peg$parsetransformation_rule() {\n      var s0, s1, s2, s3, s4, s5;\n\n      s0 = peg$currPos;\n      s1 = peg$parsecategory1();\n      if (s1 !== peg$FAILED) {\n        s2 = peg$parseidentifier();\n        if (s2 !== peg$FAILED) {\n          s3 = peg$parseidentifier();\n          if (s3 !== peg$FAILED) {\n            s4 = peg$parseidentifier();\n            if (s4 !== peg$FAILED) {\n              s5 = peg$parseidentifier();\n              if (s5 === peg$FAILED) {\n                s5 = peg$c3;\n              }\n              if (s5 !== peg$FAILED) {\n                peg$reportedPos = s0;\n                s1 = peg$c4(s1, s2, s3, s4, s5);\n                s0 = s1;\n              } else {\n                peg$currPos = s0;\n                s0 = peg$c1;\n              }\n            } else {\n              peg$currPos = s0;\n              s0 = peg$c1;\n            }\n          } else {\n            peg$currPos = s0;\n            s0 = peg$c1;\n          }\n        } else {\n          peg$currPos = s0;\n          s0 = peg$c1;\n        }\n      } else {\n        peg$currPos = s0;\n        s0 = peg$c1;\n      }\n\n      return s0;\n    }\n\n    function peg$parsecategory1() {\n      var s0;\n\n      s0 = peg$parsewild_card();\n      if (s0 === peg$FAILED) {\n        s0 = peg$parseidentifier();\n      }\n\n      return s0;\n    }\n\n    function peg$parseidentifier() {\n      var s0, s1, s2;\n\n      s0 = peg$currPos;\n      s1 = [];\n      if (peg$c5.test(input.charAt(peg$currPos))) {\n        s2 = input.charAt(peg$currPos);\n        peg$currPos++;\n      } else {\n        s2 = peg$FAILED;\n        if (peg$silentFails === 0) { peg$fail(peg$c6); }\n      }\n      if (s2 !== peg$FAILED) {\n        while (s2 !== peg$FAILED) {\n          s1.push(s2);\n          if (peg$c5.test(input.charAt(peg$currPos))) {\n            s2 = input.charAt(peg$currPos);\n            peg$currPos++;\n          } else {\n            s2 = peg$FAILED;\n            if (peg$silentFails === 0) { peg$fail(peg$c6); }\n          }\n        }\n      } else {\n        s1 = peg$c1;\n      }\n      if (s1 !== peg$FAILED) {\n        s2 = peg$parseS_no_eol();\n        if (s2 !== peg$FAILED) {\n          peg$reportedPos = s0;\n          s1 = peg$c7(s1);\n          s0 = s1;\n        } else {\n          peg$currPos = s0;\n          s0 = peg$c1;\n        }\n      } else {\n        peg$currPos = s0;\n        s0 = peg$c1;\n      }\n\n      return s0;\n    }\n\n    function peg$parsewild_card() {\n      var s0, s1, s2;\n\n      s0 = peg$currPos;\n      if (input.charCodeAt(peg$currPos) === 42) {\n        s1 = peg$c8;\n        peg$currPos++;\n      } else {\n        s1 = peg$FAILED;\n        if (peg$silentFails === 0) { peg$fail(peg$c9); }\n      }\n      if (s1 !== peg$FAILED) {\n        s2 = peg$parseS_no_eol();\n        if (s2 !== peg$FAILED) {\n          peg$reportedPos = s0;\n          s1 = peg$c10(s1);\n          s0 = s1;\n        } else {\n          peg$currPos = s0;\n          s0 = peg$c1;\n        }\n      } else {\n        peg$currPos = s0;\n        s0 = peg$c1;\n      }\n\n      return s0;\n    }\n\n    function peg$parseEOL() {\n      var s0;\n\n      if (input.substr(peg$currPos, 2) === peg$c11) {\n        s0 = peg$c11;\n        peg$currPos += 2;\n      } else {\n        s0 = peg$FAILED;\n        if (peg$silentFails === 0) { peg$fail(peg$c12); }\n      }\n      if (s0 === peg$FAILED) {\n        if (input.charCodeAt(peg$currPos) === 10) {\n          s0 = peg$c13;\n          peg$currPos++;\n        } else {\n          s0 = peg$FAILED;\n          if (peg$silentFails === 0) { peg$fail(peg$c14); }\n        }\n        if (s0 === peg$FAILED) {\n          if (input.charCodeAt(peg$currPos) === 13) {\n            s0 = peg$c15;\n            peg$currPos++;\n          } else {\n            s0 = peg$FAILED;\n            if (peg$silentFails === 0) { peg$fail(peg$c16); }\n          }\n        }\n      }\n\n      return s0;\n    }\n\n    function peg$parseComment() {\n      var s0, s1, s2, s3, s4, s5;\n\n      s0 = peg$currPos;\n      if (input.substr(peg$currPos, 2) === peg$c17) {\n        s1 = peg$c17;\n        peg$currPos += 2;\n      } else {\n        s1 = peg$FAILED;\n        if (peg$silentFails === 0) { peg$fail(peg$c18); }\n      }\n      if (s1 !== peg$FAILED) {\n        s2 = [];\n        s3 = peg$currPos;\n        s4 = peg$currPos;\n        peg$silentFails++;\n        s5 = peg$parseEOL();\n        peg$silentFails--;\n        if (s5 === peg$FAILED) {\n          s4 = peg$c19;\n        } else {\n          peg$currPos = s4;\n          s4 = peg$c1;\n        }\n        if (s4 !== peg$FAILED) {\n          if (input.length > peg$currPos) {\n            s5 = input.charAt(peg$currPos);\n            peg$currPos++;\n          } else {\n            s5 = peg$FAILED;\n            if (peg$silentFails === 0) { peg$fail(peg$c20); }\n          }\n          if (s5 !== peg$FAILED) {\n            s4 = [s4, s5];\n            s3 = s4;\n          } else {\n            peg$currPos = s3;\n            s3 = peg$c1;\n          }\n        } else {\n          peg$currPos = s3;\n          s3 = peg$c1;\n        }\n        while (s3 !== peg$FAILED) {\n          s2.push(s3);\n          s3 = peg$currPos;\n          s4 = peg$currPos;\n          peg$silentFails++;\n          s5 = peg$parseEOL();\n          peg$silentFails--;\n          if (s5 === peg$FAILED) {\n            s4 = peg$c19;\n          } else {\n            peg$currPos = s4;\n            s4 = peg$c1;\n          }\n          if (s4 !== peg$FAILED) {\n            if (input.length > peg$currPos) {\n              s5 = input.charAt(peg$currPos);\n              peg$currPos++;\n            } else {\n              s5 = peg$FAILED;\n              if (peg$silentFails === 0) { peg$fail(peg$c20); }\n            }\n            if (s5 !== peg$FAILED) {\n              s4 = [s4, s5];\n              s3 = s4;\n            } else {\n              peg$currPos = s3;\n              s3 = peg$c1;\n            }\n          } else {\n            peg$currPos = s3;\n            s3 = peg$c1;\n          }\n        }\n        if (s2 !== peg$FAILED) {\n          s3 = peg$parseEOL();\n          if (s3 === peg$FAILED) {\n            s3 = peg$parseEOI();\n          }\n          if (s3 !== peg$FAILED) {\n            s1 = [s1, s2, s3];\n            s0 = s1;\n          } else {\n            peg$currPos = s0;\n            s0 = peg$c1;\n          }\n        } else {\n          peg$currPos = s0;\n          s0 = peg$c1;\n        }\n      } else {\n        peg$currPos = s0;\n        s0 = peg$c1;\n      }\n\n      return s0;\n    }\n\n    function peg$parseS() {\n      var s0, s1;\n\n      s0 = [];\n      if (input.charCodeAt(peg$currPos) === 32) {\n        s1 = peg$c21;\n        peg$currPos++;\n      } else {\n        s1 = peg$FAILED;\n        if (peg$silentFails === 0) { peg$fail(peg$c22); }\n      }\n      if (s1 === peg$FAILED) {\n        if (input.charCodeAt(peg$currPos) === 9) {\n          s1 = peg$c23;\n          peg$currPos++;\n        } else {\n          s1 = peg$FAILED;\n          if (peg$silentFails === 0) { peg$fail(peg$c24); }\n        }\n        if (s1 === peg$FAILED) {\n          s1 = peg$parseEOL();\n          if (s1 === peg$FAILED) {\n            s1 = peg$parseComment();\n          }\n        }\n      }\n      while (s1 !== peg$FAILED) {\n        s0.push(s1);\n        if (input.charCodeAt(peg$currPos) === 32) {\n          s1 = peg$c21;\n          peg$currPos++;\n        } else {\n          s1 = peg$FAILED;\n          if (peg$silentFails === 0) { peg$fail(peg$c22); }\n        }\n        if (s1 === peg$FAILED) {\n          if (input.charCodeAt(peg$currPos) === 9) {\n            s1 = peg$c23;\n            peg$currPos++;\n          } else {\n            s1 = peg$FAILED;\n            if (peg$silentFails === 0) { peg$fail(peg$c24); }\n          }\n          if (s1 === peg$FAILED) {\n            s1 = peg$parseEOL();\n            if (s1 === peg$FAILED) {\n              s1 = peg$parseComment();\n            }\n          }\n        }\n      }\n\n      return s0;\n    }\n\n    function peg$parseS_no_eol() {\n      var s0, s1;\n\n      s0 = [];\n      if (input.charCodeAt(peg$currPos) === 32) {\n        s1 = peg$c21;\n        peg$currPos++;\n      } else {\n        s1 = peg$FAILED;\n        if (peg$silentFails === 0) { peg$fail(peg$c22); }\n      }\n      if (s1 === peg$FAILED) {\n        if (input.charCodeAt(peg$currPos) === 9) {\n          s1 = peg$c23;\n          peg$currPos++;\n        } else {\n          s1 = peg$FAILED;\n          if (peg$silentFails === 0) { peg$fail(peg$c24); }\n        }\n        if (s1 === peg$FAILED) {\n          s1 = peg$parseComment();\n        }\n      }\n      while (s1 !== peg$FAILED) {\n        s0.push(s1);\n        if (input.charCodeAt(peg$currPos) === 32) {\n          s1 = peg$c21;\n          peg$currPos++;\n        } else {\n          s1 = peg$FAILED;\n          if (peg$silentFails === 0) { peg$fail(peg$c22); }\n        }\n        if (s1 === peg$FAILED) {\n          if (input.charCodeAt(peg$currPos) === 9) {\n            s1 = peg$c23;\n            peg$currPos++;\n          } else {\n            s1 = peg$FAILED;\n            if (peg$silentFails === 0) { peg$fail(peg$c24); }\n          }\n          if (s1 === peg$FAILED) {\n            s1 = peg$parseComment();\n          }\n        }\n      }\n\n      return s0;\n    }\n\n    function peg$parseEOI() {\n      var s0, s1;\n\n      s0 = peg$currPos;\n      peg$silentFails++;\n      if (input.length > peg$currPos) {\n        s1 = input.charAt(peg$currPos);\n        peg$currPos++;\n      } else {\n        s1 = peg$FAILED;\n        if (peg$silentFails === 0) { peg$fail(peg$c20); }\n      }\n      peg$silentFails--;\n      if (s1 === peg$FAILED) {\n        s0 = peg$c19;\n      } else {\n        peg$currPos = s0;\n        s0 = peg$c1;\n      }\n\n      return s0;\n    }\n\n\n      var TransformationRule = require(\"./TransformationRule\");\n\n\n    peg$result = peg$startRuleFunction();\n\n    if (peg$result !== peg$FAILED && peg$currPos === input.length) {\n      return peg$result;\n    } else {\n      if (peg$result !== peg$FAILED && peg$currPos < input.length) {\n        peg$fail({ type: \"end\", description: \"end of input\" });\n      }\n\n      throw peg$buildException(null, peg$maxFailExpected, peg$maxFailPos);\n    }\n  }\n\n  return {\n    SyntaxError: SyntaxError,\n    parse:       parse\n  };\n})();\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/brill_pos_tagger/lib/Lexicon.js":"/*\n   Lexicon class\n   Copyright (C) 2016 Hugo W.L. ter Doest\n\n   This program is free software: you can redistribute it and/or modify\n   it under the terms of the GNU General Public License as published by\n   the Free Software Foundation, either version 3 of the License, or\n   (at your option) any later version.\n\n   This program is distributed in the hope that it will be useful,\n   but WITHOUT ANY WARRANTY; without even the implied warranty of\n   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n   GNU General Public License for more details.\n\n   You should have received a copy of the GNU General Public License\n   along with this program.  If not, see <http://www.gnu.org/licenses/>.\n*/\n\nvar fs = require('fs');\n\n// Parses a lexicon in JSON or text format\nfunction Lexicon(filename, defaultCategory) {\n  this.defaultCategory = defaultCategory;\n  var that = this;\n\n  // Read lexicon\n  try {\n    var data = fs.readFileSync(filename, 'utf8');\n    if (data[0] === \"{\") {\n      // Lexicon is in JSON format\n      that.lexicon = JSON.parse(data);\n    }\n    else {\n      // Lexicon is plain text\n      that.parseLexicon(data);\n    }\n    // console.log('Brill_POS_Tagger.read_lexicon: number of lexicon entries read: ' + Object.keys(that.lexicon).length);\n  }\n  catch(error) {\n    console.error(error);\n  }\n}\n\n// Parses a lexicon in text format: word cat1 cat2 ... catn\nLexicon.prototype.parseLexicon = function(data) {\n  // Split into an array of non-empty lines\n  var arrayOfLines = data.match(/[^\\r\\n]+/g);\n  this.lexicon = {};\n  var that = this;\n  arrayOfLines.forEach(function(line) {\n    // Split line by whitespace\n    var elements = line.trim().split(/\\s+/);\n    if (elements.length > 0) {\n      that.lexicon[elements[0]] = elements.slice(1);\n    }\n  });\n};\n\n// Returns a list of categories for word\nLexicon.prototype.tagWord = function(word) {\n  var categories = this.lexicon[word];\n  if (!categories) {\n    categories = this.lexicon[word.toLowerCase()];\n  }\n  if (!categories) {\n    // If not found assign default_category\n    categories = [this.defaultCategory];\n  }\n  return(categories);\n};\n\nmodule.exports = Lexicon;\n","/home/travis/build/npmtest/node-npmtest-natural/node_modules/natural/lib/natural/brill_pos_tagger/lib/RuleSet.js":"/*\n   Set of transformation rules\n   Copyright (C) 2016 Hugo W.L. ter Doest\n\n   This program is free software: you can redistribute it and/or modify\n   it under the terms of the GNU General Public License as published by\n   the Free Software Foundation, either version 3 of the License, or\n   (at your option) any later version.\n\n   This program is distributed in the hope that it will be useful,\n   but WITHOUT ANY WARRANTY; without even the implied warranty of\n   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n   GNU General Public License for more details.\n\n   You should have received a copy of the GNU General Public License\n   along with this program.  If not, see <http://www.gnu.org/licenses/>.\n*/\n\nvar fs = require(\"fs\");\nvar TF_Parser = require('./TF_Parser');\n\nfunction RuleSet(filename) {\n  var that = this;\n\n  // Read transformation rules\n  try {\n    var data = fs.readFileSync(filename, 'utf8');\n    this.rules = TF_Parser.parse(data);\n    // console.log(this.rules);\n    // console.log('Brill_POS_Tagger.read_transformation_rules: number of transformation rules read: ' + this.rules.length);\n  }\n  catch(error) {\n    console.error(error);\n  }\n}\n\nmodule.exports = RuleSet;\n"}